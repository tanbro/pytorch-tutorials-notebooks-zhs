



<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
      
      
        <meta name="lang:clipboard.copy" content="复制">
      
        <meta name="lang:clipboard.copied" content="已复制">
      
        <meta name="lang:search.language" content="ja">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="没有找到符合条件的结果">
      
        <meta name="lang:search.result.one" content="找到 1 个符合条件的结果">
      
        <meta name="lang:search.result.other" content="# 个符合条件的结果">
      
        <meta name="lang:search.tokenizer" content="[\uff0c\u3002]+">
      
      <link rel="shortcut icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.1.2">
    
    
      
        <title>聊天机器人教程 - PyTorch tutorials 中文翻译笔记</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/application.3020aac5.css">
      
      
    
    
      <script src="../../assets/javascripts/modernizr.01ccdecf.js"></script>
    
    
      
    
    <link rel="stylesheet" href="../../assets/fonts/material-icons.css">
    
    
    
      
    
    
  </head>
  
    <body dir="ltr">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="__github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#_1" tabindex="1" class="md-skip">
        跳转至
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../.." title="PyTorch tutorials 中文翻译笔记" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              PyTorch tutorials 中文翻译笔记
            </span>
            <span class="md-header-nav__topic">
              聊天机器人教程
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            键入以开始搜索
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/tanbro/pytorch-tutorials-notebooks-zhs/" title="前往 Github 仓库" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    GitHub
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../.." title="PyTorch tutorials 中文翻译笔记" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    PyTorch tutorials 中文翻译笔记
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/tanbro/pytorch-tutorials-notebooks-zhs/" title="前往 Github 仓库" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../.." title="README" class="md-nav__link">
      README
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      入门
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        入门
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2-1" type="checkbox" id="nav-2-1">
    
    <label class="md-nav__link" for="nav-2-1">
      60分钟闪电战
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-2-1">
        60分钟闪电战
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../blitz/tensor_tutorial/" title="什么是PyTorch？" class="md-nav__link">
      什么是PyTorch？
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../blitz/autograd_tutorial/" title="Autograd：自动微分" class="md-nav__link">
      Autograd：自动微分
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../blitz/neural_networks_tutorial/" title="神经网络" class="md-nav__link">
      神经网络
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../blitz/cifar10_tutorial/" title="训练分类器" class="md-nav__link">
      训练分类器
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../blitz/data_parallel_tutorial/" title="数据并行" class="md-nav__link">
      数据并行
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../data_loading_tutorial/" title="数据加载和处理教程" class="md-nav__link">
      数据加载和处理教程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../transfer_learning_tutorial/" title="迁移学习教程" class="md-nav__link">
      迁移学习教程
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3" checked>
    
    <label class="md-nav__link" for="nav-3">
      文本
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        文本
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        聊天机器人教程
      </label>
    
    <a href="./" title="聊天机器人教程" class="md-nav__link md-nav__link--active">
      聊天机器人教程
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" title="准备工作" class="md-nav__link">
    准备工作
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" title="数据加载与预处理" class="md-nav__link">
    数据加载与预处理
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_4" title="创建格式化数据文件" class="md-nav__link">
    创建格式化数据文件
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" title="数据加载和修建减" class="md-nav__link">
    数据加载和修建减
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_6" title="为模型准备数据" class="md-nav__link">
    为模型准备数据
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_7" title="定义模型" class="md-nav__link">
    定义模型
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#seq2seq" title="Seq2Seq 模型" class="md-nav__link">
    Seq2Seq 模型
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_8" title="编码器" class="md-nav__link">
    编码器
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" title="解码器" class="md-nav__link">
    解码器
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_10" title="定义训练过程" class="md-nav__link">
    定义训练过程
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_11" title="损失掩码" class="md-nav__link">
    损失掩码
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_12" title="单次训练迭代" class="md-nav__link">
    单次训练迭代
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#define-evaluation" title="Define Evaluation" class="md-nav__link">
    Define Evaluation
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#run-model" title="Run Model" class="md-nav__link">
    Run Model
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" title="准备工作" class="md-nav__link">
    准备工作
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" title="数据加载与预处理" class="md-nav__link">
    数据加载与预处理
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_4" title="创建格式化数据文件" class="md-nav__link">
    创建格式化数据文件
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" title="数据加载和修建减" class="md-nav__link">
    数据加载和修建减
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_6" title="为模型准备数据" class="md-nav__link">
    为模型准备数据
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_7" title="定义模型" class="md-nav__link">
    定义模型
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#seq2seq" title="Seq2Seq 模型" class="md-nav__link">
    Seq2Seq 模型
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_8" title="编码器" class="md-nav__link">
    编码器
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" title="解码器" class="md-nav__link">
    解码器
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_10" title="定义训练过程" class="md-nav__link">
    定义训练过程
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_11" title="损失掩码" class="md-nav__link">
    损失掩码
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_12" title="单次训练迭代" class="md-nav__link">
    单次训练迭代
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#define-evaluation" title="Define Evaluation" class="md-nav__link">
    Define Evaluation
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#run-model" title="Run Model" class="md-nav__link">
    Run Model
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/tanbro/pytorch-tutorials-notebooks-zhs/edit/master/docs/beginner/chatbot_tutorial.md" title="编辑此页" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="_1">聊天机器人教程</h1>
<p><strong>作者</strong> <a href="https://github.com/MatthewInkawhich">Matthew Inkawhich</a></p>
<p>在本教程中，我们将探索一个有趣的序列到序列(Seq2Seq)模型的用例。我们将使用<a href="https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html">Cornell Movie-Dialogs Corpus</a>的电影脚本训练一个简单的聊天机器人。</p>
<p>对话模型是人工智能研究的热门话题。
聊天机器人在包括客户服务应用和在线帮助台在内的各种场景都用应用。
这些机器人通常使由基于索引的模型驱动的，它们响应特定的问题，输出预定义的响应。在像公司IT帮助台这样高度受限的领域中，这些模型可能是住够了，不过对于一半用例来说，他们是不够健壮的。
教一台机器与人类在多个领域内进行有意义的对话是一个远未解决的研究性问题。
在最近的深度学习模型热潮中，像Google<a href="https://arxiv.org/abs/1506.05869">Neural Conversational Model</a>这样的强大的生成模型的出现，标志着多领域生成对话模型的一大进步。
this tutorial, we will implement this kind of model in PyTorch.
在这个教程中，我们将用<code>PyTorch</code>实现这种模型。</p>
<p><img alt="bot" src="https://pytorch.org/tutorials/_images/bot.png" /></p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="gp">&gt;</span> hello?
<span class="go">Bot: hello .</span>
<span class="gp">&gt;</span> where am I?
<span class="go">Bot: you re in a hospital .</span>
<span class="gp">&gt;</span> who are you?
<span class="go">Bot: i m a lawyer .</span>
<span class="gp">&gt;</span> how are you doing?
<span class="go">Bot: i m fine .</span>
<span class="gp">&gt;</span> are you my friend?
<span class="go">Bot: no .</span>
<span class="gp">&gt;</span> you<span class="err">&#39;</span>re under arrest
<span class="go">Bot: i m trying to help you !</span>
<span class="gp">&gt;</span> i<span class="err">&#39;</span>m just kidding
<span class="go">Bot: i m sorry .</span>
<span class="gp">&gt;</span> where are you from?
<span class="go">Bot: san francisco .</span>
<span class="gp">&gt;</span> it<span class="err">&#39;</span>s <span class="nb">time</span> <span class="k">for</span> me to leave
<span class="go">Bot: i know .</span>
<span class="gp">&gt;</span> goodbye
<span class="go">Bot: goodbye .</span>
</pre></div>
</td></tr></table>

<p><strong>教程要点：</strong></p>
<ul>
<li>加载和预处理<a href="https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html">Cornell Movie-Dialogs Corpus</a>数据集</li>
<li>使用<a href="https://arxiv.org/abs/1508.04025">Luong attention mechanism(s)</a>实现一个序列到序列模型</li>
<li>使用小批次联合训练编码器和解码器模型</li>
<li>实现贪婪搜索解码模块</li>
<li>与训练后的聊天机器人互动</li>
</ul>
<p><strong>致谢</strong></p>
<p>本教程借用以下来源的代码：</p>
<ol>
<li>
<p>Yuan-Kuei Wu 的 pytorch-chatbot 实现:
   https://github.com/ywk991112/pytorch-chatbot</p>
</li>
<li>
<p>Sean Robertson 的 practical-pytorch seq2seq-translation 例子:
   https://github.com/spro/practical-pytorch/tree/master/seq2seq-translation</p>
</li>
<li>
<p>FloydHub 的 Cornell Movie Corpus 预处理代码:
   https://github.com/floydhub/textutil-preprocess-cornell-movie-corpus</p>
</li>
</ol>
<h2 id="_2">准备工作</h2>
<p>首先，从<a href="https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html">https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html</a>下载ZIP文件解压缩到当前目录的<code>data</code>子目录中。</p>
<p>此后，我们导入一些必要的包。</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">absolute_import</span><span class="p">,</span> <span class="n">division</span><span class="p">,</span> <span class="n">print_function</span><span class="p">,</span> <span class="n">unicode_literals</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.jit</span> <span class="kn">import</span> <span class="n">script</span><span class="p">,</span> <span class="n">trace</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="kn">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">unicodedata</span>
<span class="kn">import</span> <span class="nn">codecs</span>
<span class="kn">from</span> <span class="nn">io</span> <span class="kn">import</span> <span class="nb">open</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">math</span>


<span class="n">USE_CUDA</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">USE_CUDA</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>cuda
</pre></div>
</td></tr></table>

<h2 id="_3">数据加载与预处理</h2>
<p>下一步，将我们之前下载的数据重新格式化，并把数据加载到我们所要使用的结构中。</p>
<p><a href="https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html">Cornell Movie-Dialogs Corpus</a>
是一个丰富的电影角色对话数据集：</p>
<ul>
<li>来自10,292对电影角色的220,579个对话</li>
<li>来自617部电影的9,035个角色</li>
<li>总共304,713句话</li>
</ul>
<p>这个数据集庞大且多样，其语言形式、时间段、情感都有很大变化。我们希望这种多样性使我们的模型能够适应多种形式的输入和询问。</p>
<p>首先，我们看几行数据文件，了解其原始格式。</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">corpus_name</span> <span class="o">=</span> <span class="s2">&quot;cornell movie-dialogs corpus&quot;</span>
<span class="n">corpus</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">corpus_name</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">printLines</span><span class="p">(</span><span class="nb">file</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="nb">file</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;iso-8859-1&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">datafile</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">datafile</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>

<span class="n">printLines</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="s2">&quot;movie_lines.txt&quot;</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!

L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!

L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.

L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?

L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let&#39;s go.

L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow

L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you&#39;re gonna need to learn how to lie.

L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No

L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I&#39;m kidding.  You know how sometimes you just become this &quot;persona&quot;?  And you don&#39;t know how to quit?

L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?
</pre></div>
</td></tr></table>

<h3 id="_4">创建格式化数据文件</h3>
<p>为方便起见，我们将创建一个格式良好的数据文件，其中每一行包含一个以制表符分隔的<em>询问语句</em>和一个<em>响应语句</em>对。</p>
<p>以下函数用于分析 <em>movie_lines.txt</em> 数据文件的原始行数据</p>
<ul>
<li><code>loadLines</code> 将每一行分割成具有多个字段(lineID, characterID, movieID, character, text)的字典</li>
<li><code>loadConversations</code> 将来自 <code>loadLines</code> 的，包含多个字段的行，根据 <em>movie_conversations.txt</em> 组成对话。</li>
<li><code>extractSentencePairs</code> 从对话中提取句子对</li>
</ul>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Splits each line of the file into a dictionary of fields</span>
<span class="k">def</span> <span class="nf">loadLines</span><span class="p">(</span><span class="n">fileName</span><span class="p">,</span> <span class="n">fields</span><span class="p">):</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fileName</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;iso-8859-1&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">values</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; +++$+++ &quot;</span><span class="p">)</span>
            <span class="c1"># Extract fields</span>
            <span class="n">lineObj</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">field</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">fields</span><span class="p">):</span>
                <span class="n">lineObj</span><span class="p">[</span><span class="n">field</span><span class="p">]</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">lines</span><span class="p">[</span><span class="n">lineObj</span><span class="p">[</span><span class="s1">&#39;lineID&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="n">lineObj</span>
    <span class="k">return</span> <span class="n">lines</span>


<span class="c1"># Groups fields of lines from `loadLines` into conversations based on *movie_conversations.txt*</span>
<span class="k">def</span> <span class="nf">loadConversations</span><span class="p">(</span><span class="n">fileName</span><span class="p">,</span> <span class="n">lines</span><span class="p">,</span> <span class="n">fields</span><span class="p">):</span>
    <span class="n">conversations</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fileName</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;iso-8859-1&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">values</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; +++$+++ &quot;</span><span class="p">)</span>
            <span class="c1"># Extract fields</span>
            <span class="n">convObj</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">field</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">fields</span><span class="p">):</span>
                <span class="n">convObj</span><span class="p">[</span><span class="n">field</span><span class="p">]</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="c1"># Convert string to list (convObj[&quot;utteranceIDs&quot;] == &quot;[&#39;L598485&#39;, &#39;L598486&#39;, ...]&quot;)</span>
            <span class="n">lineIds</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">convObj</span><span class="p">[</span><span class="s2">&quot;utteranceIDs&quot;</span><span class="p">])</span>
            <span class="c1"># Reassemble lines</span>
            <span class="n">convObj</span><span class="p">[</span><span class="s2">&quot;lines&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">lineId</span> <span class="ow">in</span> <span class="n">lineIds</span><span class="p">:</span>
                <span class="n">convObj</span><span class="p">[</span><span class="s2">&quot;lines&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lines</span><span class="p">[</span><span class="n">lineId</span><span class="p">])</span>
            <span class="n">conversations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">convObj</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">conversations</span>


<span class="c1"># Extracts pairs of sentences from conversations</span>
<span class="k">def</span> <span class="nf">extractSentencePairs</span><span class="p">(</span><span class="n">conversations</span><span class="p">):</span>
    <span class="n">qa_pairs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">conversation</span> <span class="ow">in</span> <span class="n">conversations</span><span class="p">:</span>
        <span class="c1"># Iterate over all the lines of the conversation</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">conversation</span><span class="p">[</span><span class="s2">&quot;lines&quot;</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>  <span class="c1"># We ignore the last line (no answer for it)</span>
            <span class="n">inputLine</span> <span class="o">=</span> <span class="n">conversation</span><span class="p">[</span><span class="s2">&quot;lines&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="n">targetLine</span> <span class="o">=</span> <span class="n">conversation</span><span class="p">[</span><span class="s2">&quot;lines&quot;</span><span class="p">][</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">][</span><span class="s2">&quot;text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="c1"># Filter wrong samples (if one of the lists is empty)</span>
            <span class="k">if</span> <span class="n">inputLine</span> <span class="ow">and</span> <span class="n">targetLine</span><span class="p">:</span>
                <span class="n">qa_pairs</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">inputLine</span><span class="p">,</span> <span class="n">targetLine</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">qa_pairs</span>
</pre></div>
</td></tr></table>

<p>现在，调用这些函数，并创建文件，文件名是 <em>formatted_movie_lines.txt</em> 。</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Define path to new file</span>
<span class="n">datafile</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="s2">&quot;formatted_movie_lines.txt&quot;</span><span class="p">)</span>

<span class="n">delimiter</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span>
<span class="c1"># Unescape the delimiter</span>
<span class="n">delimiter</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">codecs</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">delimiter</span><span class="p">,</span> <span class="s2">&quot;unicode_escape&quot;</span><span class="p">))</span>

<span class="c1"># Initialize lines dict, conversations list, and field ids</span>
<span class="n">lines</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">conversations</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">MOVIE_LINES_FIELDS</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;lineID&quot;</span><span class="p">,</span> <span class="s2">&quot;characterID&quot;</span><span class="p">,</span> <span class="s2">&quot;movieID&quot;</span><span class="p">,</span> <span class="s2">&quot;character&quot;</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">]</span>
<span class="n">MOVIE_CONVERSATIONS_FIELDS</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;character1ID&quot;</span><span class="p">,</span> <span class="s2">&quot;character2ID&quot;</span><span class="p">,</span> <span class="s2">&quot;movieID&quot;</span><span class="p">,</span> <span class="s2">&quot;utteranceIDs&quot;</span><span class="p">]</span>

<span class="c1"># Load lines and process conversations</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Processing corpus...&quot;</span><span class="p">)</span>
<span class="n">lines</span> <span class="o">=</span> <span class="n">loadLines</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="s2">&quot;movie_lines.txt&quot;</span><span class="p">),</span> <span class="n">MOVIE_LINES_FIELDS</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Loading conversations...&quot;</span><span class="p">)</span>
<span class="n">conversations</span> <span class="o">=</span> <span class="n">loadConversations</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="s2">&quot;movie_conversations.txt&quot;</span><span class="p">),</span>
                                  <span class="n">lines</span><span class="p">,</span> <span class="n">MOVIE_CONVERSATIONS_FIELDS</span><span class="p">)</span>

<span class="c1"># Write new csv file</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Writing newly formatted file...&quot;</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">datafile</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">outputfile</span><span class="p">:</span>
    <span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">writer</span><span class="p">(</span><span class="n">outputfile</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="n">delimiter</span><span class="p">,</span> <span class="n">lineterminator</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">extractSentencePairs</span><span class="p">(</span><span class="n">conversations</span><span class="p">):</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">pair</span><span class="p">)</span>

<span class="c1"># Print a sample of lines</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Sample lines from file:&quot;</span><span class="p">)</span>
<span class="n">printLines</span><span class="p">(</span><span class="n">datafile</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>Processing corpus...

Loading conversations...

Writing newly formatted file...

Sample lines from file:
Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.   Well, I thought we&#39;d start with pronunciation, if that&#39;s okay with you.

Well, I thought we&#39;d start with pronunciation, if that&#39;s okay with you. Not the hacking and gagging and spitting part.  Please.

Not the hacking and gagging and spitting part.  Please. Okay... then how &#39;bout we try out some French cuisine.  Saturday?  Night?

You&#39;re asking me out.  That&#39;s so cute. What&#39;s your name again?  Forget it.

No, no, it&#39;s my fault -- we didn&#39;t have a proper introduction ---   Cameron.

Cameron.    The thing is, Cameron -- I&#39;m at the mercy of a particularly hideous breed of loser.  My sister.  I can&#39;t date until she does.

The thing is, Cameron -- I&#39;m at the mercy of a particularly hideous breed of loser.  My sister.  I can&#39;t date until she does.   Seems like she could get a date easy enough...

Why?    Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.

Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.   That&#39;s a shame.

Gosh, if only we could find Kat a boyfriend...  Let me see what I can do.
</pre></div>
</td></tr></table>

<h3 id="_5">数据加载和修建减</h3>
<p>我们的下一个任务是创建词汇表并将询问/响应句子对加载到内存中。</p>
<p>注意我们处理的是<strong>词</strong>序列，它们没有隐式映射到离散数值空间。因此，我们必须创建一个将我们在数据集中遇到的每个唯一词映射到索引值的映射(Mapping)。</p>
<p>为此，我们定义一个<code>Voc</code>类，它保存从词到索引值的映射，以及从索引值到词的反向映射，唯一词的数量，总词数。
这个类提供了像词表添加词的方法(<code>addWord</code>)，添加句子中所有词的方法(<code>addSentence</code>)，以及削减不常见词的方法(<code>trim</code>)。
More on trimming later.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Default word tokens</span>
<span class="n">PAD_token</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Used for padding short sentences</span>
<span class="n">SOS_token</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># Start-of-sentence token</span>
<span class="n">EOS_token</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># End-of-sentence token</span>

<span class="k">class</span> <span class="nc">Voc</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trimmed</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index2word</span> <span class="o">=</span> <span class="p">{</span><span class="n">PAD_token</span><span class="p">:</span> <span class="s2">&quot;PAD&quot;</span><span class="p">,</span> <span class="n">SOS_token</span><span class="p">:</span> <span class="s2">&quot;SOS&quot;</span><span class="p">,</span> <span class="n">EOS_token</span><span class="p">:</span> <span class="s2">&quot;EOS&quot;</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_words</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># Count SOS, EOS, PAD</span>

    <span class="k">def</span> <span class="nf">addSentence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentence</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">addWord</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">addWord</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_words</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">index2word</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_words</span><span class="p">]</span> <span class="o">=</span> <span class="n">word</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_words</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1"># Remove words below a certain count threshold</span>
    <span class="k">def</span> <span class="nf">trim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">min_count</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trimmed</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trimmed</span> <span class="o">=</span> <span class="bp">True</span>

        <span class="n">keep_words</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">v</span> <span class="o">&gt;=</span> <span class="n">min_count</span><span class="p">:</span>
                <span class="n">keep_words</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>

        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;keep_words {} / {} = {:.4f}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">keep_words</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">keep_words</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">)</span>
        <span class="p">))</span>

        <span class="c1"># Reinitialize dictionaries</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index2word</span> <span class="o">=</span> <span class="p">{</span><span class="n">PAD_token</span><span class="p">:</span> <span class="s2">&quot;PAD&quot;</span><span class="p">,</span> <span class="n">SOS_token</span><span class="p">:</span> <span class="s2">&quot;SOS&quot;</span><span class="p">,</span> <span class="n">EOS_token</span><span class="p">:</span> <span class="s2">&quot;EOS&quot;</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_words</span> <span class="o">=</span> <span class="mi">3</span> <span class="c1"># Count default tokens</span>

        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">keep_words</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">addWord</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>现在，可以开始装配词表和询问/回复句子对。在准备好使用这些数据之前，我们还得执行一些预处理。</p>
<ul>
<li>首先，我们必须使用<code>unicodeToAscii</code>将字符串从Unicode转为ASCII。</li>
<li>其次，我们应该把所有字母转为小写，并且裁剪掉所有的除基本标点符号之外的所有非字母字符(<code>normalizeString</code>)。</li>
<li>最后，为了训练更快的收敛，我们将过滤掉(<code>filterPairs</code>)长度大于<code>MAX_LENGTH</code>阈值的句子。</li>
</ul>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">MAX_LENGTH</span> <span class="o">=</span> <span class="mi">10</span>  <span class="c1"># Maximum sentence length to consider</span>

<span class="c1"># Turn a Unicode string to plain ASCII, thanks to</span>
<span class="c1"># https://stackoverflow.com/a/518232/2809427</span>
<span class="k">def</span> <span class="nf">unicodeToAscii</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="k">return</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">unicodedata</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="s1">&#39;NFD&#39;</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">unicodedata</span><span class="o">.</span><span class="n">category</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">!=</span> <span class="s1">&#39;Mn&#39;</span>
    <span class="p">)</span>

<span class="c1"># Lowercase, trim, and remove non-letter characters</span>
<span class="k">def</span> <span class="nf">normalizeString</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">unicodeToAscii</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;([.!?])&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot; \1&quot;</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;[^a-zA-Z.!?]+&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\s+&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">s</span>

<span class="c1"># Read query/response pairs and return a voc object</span>
<span class="k">def</span> <span class="nf">readVocs</span><span class="p">(</span><span class="n">datafile</span><span class="p">,</span> <span class="n">corpus_name</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Reading lines...&quot;</span><span class="p">)</span>
    <span class="c1"># Read the file and split into lines</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">datafile</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="o">.</span>\
        <span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="c1"># Split every line into pairs and normalize</span>
    <span class="n">pairs</span> <span class="o">=</span> <span class="p">[[</span><span class="n">normalizeString</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">l</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)]</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">]</span>
    <span class="n">voc</span> <span class="o">=</span> <span class="n">Voc</span><span class="p">(</span><span class="n">corpus_name</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">voc</span><span class="p">,</span> <span class="n">pairs</span>

<span class="c1"># Returns True if both sentences in a pair &#39;p&#39; are under the MAX_LENGTH threshold</span>
<span class="k">def</span> <span class="nf">filterPair</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
    <span class="c1"># Input sequences need to preserve the last word for EOS token</span>
    <span class="k">return</span> <span class="nb">all</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">))</span> <span class="o">&lt;</span> <span class="n">MAX_LENGTH</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">p</span><span class="p">)</span>

<span class="c1"># Filter pairs using filterPair condition</span>
<span class="k">def</span> <span class="nf">filterPairs</span><span class="p">(</span><span class="n">pairs</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">pair</span> <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">pairs</span> <span class="k">if</span> <span class="n">filterPair</span><span class="p">(</span><span class="n">pair</span><span class="p">)]</span>

<span class="c1"># Using the functions defined above, return a populated voc object and pairs list</span>
<span class="k">def</span> <span class="nf">loadPrepareData</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">corpus_name</span><span class="p">,</span> <span class="n">datafile</span><span class="p">,</span> <span class="n">save_dir</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Start preparing training data ...&quot;</span><span class="p">)</span>
    <span class="n">voc</span><span class="p">,</span> <span class="n">pairs</span> <span class="o">=</span> <span class="n">readVocs</span><span class="p">(</span><span class="n">datafile</span><span class="p">,</span> <span class="n">corpus_name</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Read {!s} sentence pairs&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pairs</span><span class="p">)))</span>
    <span class="n">pairs</span> <span class="o">=</span> <span class="n">filterPairs</span><span class="p">(</span><span class="n">pairs</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Trimmed to {!s} sentence pairs&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pairs</span><span class="p">)))</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Counting words...&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">pairs</span><span class="p">:</span>
        <span class="n">voc</span><span class="o">.</span><span class="n">addSentence</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">voc</span><span class="o">.</span><span class="n">addSentence</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Counted words:&quot;</span><span class="p">,</span> <span class="n">voc</span><span class="o">.</span><span class="n">num_words</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">voc</span><span class="p">,</span> <span class="n">pairs</span>


<span class="c1"># Load/Assemble voc and pairs</span>
<span class="n">save_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="s2">&quot;save&quot;</span><span class="p">)</span>
<span class="n">voc</span><span class="p">,</span> <span class="n">pairs</span> <span class="o">=</span> <span class="n">loadPrepareData</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">corpus_name</span><span class="p">,</span> <span class="n">datafile</span><span class="p">,</span> <span class="n">save_dir</span><span class="p">)</span>
<span class="c1"># Print some pairs to validate</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">pairs:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">pairs</span><span class="p">[:</span><span class="mi">10</span><span class="p">]:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">pair</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>Start preparing training data ...
Reading lines...
Read 221282 sentence pairs
Trimmed to 64217 sentence pairs
Counting words...
Counted words: 17996

pairs:
[&#39;there .&#39;, &#39;where ?&#39;]
[&#39;you have my word . as a gentleman&#39;, &#39;you re sweet .&#39;]
[&#39;hi .&#39;, &#39;looks like things worked out tonight huh ?&#39;]
[&#39;you know chastity ?&#39;, &#39;i believe we share an art instructor&#39;]
[&#39;have fun tonight ?&#39;, &#39;tons&#39;]
[&#39;well no . . .&#39;, &#39;then that s all you had to say .&#39;]
[&#39;then that s all you had to say .&#39;, &#39;but&#39;]
[&#39;but&#39;, &#39;you always been this selfish ?&#39;]
[&#39;do you listen to this crap ?&#39;, &#39;what crap ?&#39;]
[&#39;what good stuff ?&#39;, &#39;the real you .&#39;]
</pre></div>
</td></tr></table>

<p>另一种有利于在训练期间实现更快收敛的策略是修剪掉我们词汇表中很少使用的单词。减小特征空间也会缓和模型逼近的难度。我们将通过两个步骤完成此操作：</p>
<ol>
<li>
<p>用<code>voc.trim</code>修剪掉数量小于<code>MIN_COUNT</code>阈值的词。</p>
</li>
<li>
<p>过滤掉含有被修剪词的句子对。</p>
</li>
</ol>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">MIN_COUNT</span> <span class="o">=</span> <span class="mi">3</span>    <span class="c1"># Minimum word count threshold for trimming</span>

<span class="k">def</span> <span class="nf">trimRareWords</span><span class="p">(</span><span class="n">voc</span><span class="p">,</span> <span class="n">pairs</span><span class="p">,</span> <span class="n">MIN_COUNT</span><span class="p">):</span>
    <span class="c1"># Trim words used under the MIN_COUNT from the voc</span>
    <span class="n">voc</span><span class="o">.</span><span class="n">trim</span><span class="p">(</span><span class="n">MIN_COUNT</span><span class="p">)</span>
    <span class="c1"># Filter out pairs with trimmed words</span>
    <span class="n">keep_pairs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">pairs</span><span class="p">:</span>
        <span class="n">input_sentence</span> <span class="o">=</span> <span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">output_sentence</span> <span class="o">=</span> <span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">keep_input</span> <span class="o">=</span> <span class="bp">True</span>
        <span class="n">keep_output</span> <span class="o">=</span> <span class="bp">True</span>
        <span class="c1"># Check input sentence</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">input_sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">voc</span><span class="o">.</span><span class="n">word2index</span><span class="p">:</span>
                <span class="n">keep_input</span> <span class="o">=</span> <span class="bp">False</span>
                <span class="k">break</span>
        <span class="c1"># Check output sentence</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">output_sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">voc</span><span class="o">.</span><span class="n">word2index</span><span class="p">:</span>
                <span class="n">keep_output</span> <span class="o">=</span> <span class="bp">False</span>
                <span class="k">break</span>

        <span class="c1"># Only keep pairs that do not contain trimmed word(s) in their input or output sentence</span>
        <span class="k">if</span> <span class="n">keep_input</span> <span class="ow">and</span> <span class="n">keep_output</span><span class="p">:</span>
            <span class="n">keep_pairs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pair</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Trimmed from {} pairs to {}, {:.4f} of total&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pairs</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">keep_pairs</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">keep_pairs</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">pairs</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">keep_pairs</span>


<span class="c1"># Trim voc and pairs</span>
<span class="n">pairs</span> <span class="o">=</span> <span class="n">trimRareWords</span><span class="p">(</span><span class="n">voc</span><span class="p">,</span> <span class="n">pairs</span><span class="p">,</span> <span class="n">MIN_COUNT</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>keep_words 7820 / 17993 = 0.4346
Trimmed from 64217 pairs to 53120, 0.8272 of total
</pre></div>
</td></tr></table>

<h2 id="_6">为模型准备数据</h2>
<p>尽管我们已经投入很大精力来准备和整理数据，把它们放到了漂亮的词表对象和句子对列表，但我们的模型最终需要的的输入却是Tensor的张量数字。
可以在<a href="../intermediate/seq2seq_translation_tutorial">Seq2Seq翻译教程</a>中找到为模型准备预处理数据的方法。
在那个教程中，我们使用的批次值为1，这意味着我们所要做的就是将句子对中的单词转换为词汇表中对应的索引值，并将其提供给模型。</p>
<p>另外，如果你对加速培训和/或想要利用GPU并行化功能感兴趣，则需要使用小批量培训。</p>
<p>使用小批量也意味着我们必须注意批量中句子长度的变化。
为了容纳同一批次中不同大小的句子，我们要让批量输入张量的形状 <em>(max_length，batch_size)</em> 中的短于 <em>max_length</em> 的句子在 <em>EOS_token</em> 之后用零填充。</p>
<p>如果我们只是简单地通过将单词转换为其索引值(<code>indexesFromSentence</code>)和零填充的方法将英语句子转换为张量，张量的形状将是 <em>(batch_size，max_length)</em> ，并且在第一维上的索引将在所有时间步骤中返回完整序列。
但是，我们需要能够沿着时间、跨批次、在所有序列上进行索引。
因此，我们将输入批处理的形状转置为 <em>(max_length，batch_size)</em> ，以便跨第一维的索引返回批中所有句子的时间步长。
我们在<code>zeroPadding</code>函数中隐式处理这个转置。</p>
<p><img alt="batches" src="https://pytorch.org/tutorials/_images/seq2seq_batches.png" /></p>
<p>函数<code>inputVar</code>处理句子到张量的转换过程，最终创建一个形状正确的零填充张量。
它还返回批次中每个序列的长度(<code>lengths</code>)的张量，它稍后会被传给编码器。</p>
<p>函数<code>outputVar</code>的执行过程与<code>inputVar</code>类似，但是不返回长度（<code>lenghts</code>）张量，而是返回二进制的掩码张量和目标句子的最大长度。
二进制掩码与输出目标张量具有同样的形状，但是其中的每个 <em>PAD_token</em> 元素都为0，其它所有元素都为1。</p>
<p><code>batch2TrainData</code>简单的使用一堆句子对并使用上述函数返回输入和目标张量。</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">indexesFromSentence</span><span class="p">(</span><span class="n">voc</span><span class="p">,</span> <span class="n">sentence</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">voc</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[</span><span class="n">EOS_token</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">zeroPadding</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">fillvalue</span><span class="o">=</span><span class="n">PAD_token</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">zip_longest</span><span class="p">(</span><span class="o">*</span><span class="n">l</span><span class="p">,</span> <span class="n">fillvalue</span><span class="o">=</span><span class="n">fillvalue</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">binaryMatrix</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">PAD_token</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">seq</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">l</span><span class="p">):</span>
        <span class="n">m</span><span class="o">.</span><span class="n">append</span><span class="p">([])</span>
        <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">seq</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">token</span> <span class="o">==</span> <span class="n">PAD_token</span><span class="p">:</span>
                <span class="n">m</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">m</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">m</span>

<span class="c1"># Returns padded input sequence tensor and lengths</span>
<span class="k">def</span> <span class="nf">inputVar</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">voc</span><span class="p">):</span>
    <span class="n">indexes_batch</span> <span class="o">=</span> <span class="p">[</span><span class="n">indexesFromSentence</span><span class="p">(</span><span class="n">voc</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">l</span><span class="p">]</span>
    <span class="n">lengths</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">indexes</span><span class="p">)</span> <span class="k">for</span> <span class="n">indexes</span> <span class="ow">in</span> <span class="n">indexes_batch</span><span class="p">])</span>
    <span class="n">padList</span> <span class="o">=</span> <span class="n">zeroPadding</span><span class="p">(</span><span class="n">indexes_batch</span><span class="p">)</span>
    <span class="n">padVar</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">padList</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">padVar</span><span class="p">,</span> <span class="n">lengths</span>

<span class="c1"># Returns padded target sequence tensor, padding mask, and max target length</span>
<span class="k">def</span> <span class="nf">outputVar</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">voc</span><span class="p">):</span>
    <span class="n">indexes_batch</span> <span class="o">=</span> <span class="p">[</span><span class="n">indexesFromSentence</span><span class="p">(</span><span class="n">voc</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">l</span><span class="p">]</span>
    <span class="n">max_target_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">indexes</span><span class="p">)</span> <span class="k">for</span> <span class="n">indexes</span> <span class="ow">in</span> <span class="n">indexes_batch</span><span class="p">])</span>
    <span class="n">padList</span> <span class="o">=</span> <span class="n">zeroPadding</span><span class="p">(</span><span class="n">indexes_batch</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">binaryMatrix</span><span class="p">(</span><span class="n">padList</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ByteTensor</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
    <span class="n">padVar</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">padList</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">padVar</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">max_target_len</span>

<span class="c1"># Returns all items for a given batch of pairs</span>
<span class="k">def</span> <span class="nf">batch2TrainData</span><span class="p">(</span><span class="n">voc</span><span class="p">,</span> <span class="n">pair_batch</span><span class="p">):</span>
    <span class="n">pair_batch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)),</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">input_batch</span><span class="p">,</span> <span class="n">output_batch</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">pair_batch</span><span class="p">:</span>
        <span class="n">input_batch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">output_batch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">inp</span><span class="p">,</span> <span class="n">lengths</span> <span class="o">=</span> <span class="n">inputVar</span><span class="p">(</span><span class="n">input_batch</span><span class="p">,</span> <span class="n">voc</span><span class="p">)</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">max_target_len</span> <span class="o">=</span> <span class="n">outputVar</span><span class="p">(</span><span class="n">output_batch</span><span class="p">,</span> <span class="n">voc</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">inp</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">max_target_len</span>


<span class="c1"># Example for validation</span>
<span class="n">small_batch_size</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">batches</span> <span class="o">=</span> <span class="n">batch2TrainData</span><span class="p">(</span><span class="n">voc</span><span class="p">,</span> <span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">pairs</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">small_batch_size</span><span class="p">)])</span>
<span class="n">input_variable</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">target_variable</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">max_target_len</span> <span class="o">=</span> <span class="n">batches</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;input_variable:&quot;</span><span class="p">,</span> <span class="n">input_variable</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;lengths:&quot;</span><span class="p">,</span> <span class="n">lengths</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;target_variable:&quot;</span><span class="p">,</span> <span class="n">target_variable</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;mask:&quot;</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;max_target_len:&quot;</span><span class="p">,</span> <span class="n">max_target_len</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">input_variable</span><span class="o">:</span> <span class="n">tensor</span><span class="o">([[</span> <span class="mi">101</span><span class="o">,</span>  <span class="mi">218</span><span class="o">,</span>  <span class="mi">197</span><span class="o">,</span>  <span class="mi">147</span><span class="o">,</span>  <span class="mi">278</span><span class="o">],</span>
        <span class="o">[</span>  <span class="mi">37</span><span class="o">,</span>  <span class="mi">208</span><span class="o">,</span>  <span class="mi">117</span><span class="o">,</span> <span class="mi">1125</span><span class="o">,</span>   <span class="mi">50</span><span class="o">],</span>
        <span class="o">[</span> <span class="mi">659</span><span class="o">,</span>  <span class="mi">180</span><span class="o">,</span>    <span class="mi">7</span><span class="o">,</span>    <span class="mi">7</span><span class="o">,</span>    <span class="mi">6</span><span class="o">],</span>
        <span class="o">[</span> <span class="mi">660</span><span class="o">,</span>  <span class="mi">211</span><span class="o">,</span>   <span class="mi">18</span><span class="o">,</span> <span class="mi">2623</span><span class="o">,</span>    <span class="mi">2</span><span class="o">],</span>
        <span class="o">[</span><span class="mi">2270</span><span class="o">,</span>   <span class="mi">18</span><span class="o">,</span>  <span class="mi">386</span><span class="o">,</span>    <span class="mi">4</span><span class="o">,</span>    <span class="mi">0</span><span class="o">],</span>
        <span class="o">[</span> <span class="mi">177</span><span class="o">,</span>    <span class="mi">4</span><span class="o">,</span>    <span class="mi">6</span><span class="o">,</span>    <span class="mi">2</span><span class="o">,</span>    <span class="mi">0</span><span class="o">],</span>
        <span class="o">[</span><span class="mi">4256</span><span class="o">,</span>    <span class="mi">2</span><span class="o">,</span>    <span class="mi">2</span><span class="o">,</span>    <span class="mi">0</span><span class="o">,</span>    <span class="mi">0</span><span class="o">],</span>
        <span class="o">[</span>   <span class="mi">4</span><span class="o">,</span>    <span class="mi">0</span><span class="o">,</span>    <span class="mi">0</span><span class="o">,</span>    <span class="mi">0</span><span class="o">,</span>    <span class="mi">0</span><span class="o">],</span>
        <span class="o">[</span>   <span class="mi">2</span><span class="o">,</span>    <span class="mi">0</span><span class="o">,</span>    <span class="mi">0</span><span class="o">,</span>    <span class="mi">0</span><span class="o">,</span>    <span class="mi">0</span><span class="o">]])</span>
<span class="n">lengths</span><span class="o">:</span> <span class="n">tensor</span><span class="o">([</span><span class="mi">9</span><span class="o">,</span> <span class="mi">7</span><span class="o">,</span> <span class="mi">7</span><span class="o">,</span> <span class="mi">6</span><span class="o">,</span> <span class="mi">4</span><span class="o">])</span>
<span class="n">target_variable</span><span class="o">:</span> <span class="n">tensor</span><span class="o">([[</span> <span class="mi">124</span><span class="o">,</span> <span class="mi">2069</span><span class="o">,</span>  <span class="mi">680</span><span class="o">,</span>  <span class="mi">147</span><span class="o">,</span> <span class="mi">1644</span><span class="o">],</span>
        <span class="o">[</span>   <span class="mi">7</span><span class="o">,</span> <span class="mi">1826</span><span class="o">,</span>   <span class="mi">56</span><span class="o">,</span>   <span class="mi">92</span><span class="o">,</span>   <span class="mi">12</span><span class="o">],</span>
        <span class="o">[</span>  <span class="mi">89</span><span class="o">,</span>   <span class="mi">98</span><span class="o">,</span>  <span class="mi">827</span><span class="o">,</span>    <span class="mi">7</span><span class="o">,</span> <span class="mi">1581</span><span class="o">],</span>
        <span class="o">[</span>  <span class="mi">12</span><span class="o">,</span> <span class="mi">2807</span><span class="o">,</span>   <span class="mi">25</span><span class="o">,</span> <span class="mi">1247</span><span class="o">,</span>    <span class="mi">4</span><span class="o">],</span>
        <span class="o">[</span>  <span class="mi">79</span><span class="o">,</span> <span class="mi">2240</span><span class="o">,</span>   <span class="mi">47</span><span class="o">,</span>    <span class="mi">6</span><span class="o">,</span>    <span class="mi">2</span><span class="o">],</span>
        <span class="o">[</span><span class="mi">2008</span><span class="o">,</span>    <span class="mi">4</span><span class="o">,</span>   <span class="mi">66</span><span class="o">,</span>    <span class="mi">2</span><span class="o">,</span>    <span class="mi">0</span><span class="o">],</span>
        <span class="o">[</span>  <span class="mi">98</span><span class="o">,</span>    <span class="mi">2</span><span class="o">,</span>    <span class="mi">2</span><span class="o">,</span>    <span class="mi">0</span><span class="o">,</span>    <span class="mi">0</span><span class="o">],</span>
        <span class="o">[</span><span class="mi">4102</span><span class="o">,</span>    <span class="mi">0</span><span class="o">,</span>    <span class="mi">0</span><span class="o">,</span>    <span class="mi">0</span><span class="o">,</span>    <span class="mi">0</span><span class="o">],</span>
        <span class="o">[</span>   <span class="mi">4</span><span class="o">,</span>    <span class="mi">0</span><span class="o">,</span>    <span class="mi">0</span><span class="o">,</span>    <span class="mi">0</span><span class="o">,</span>    <span class="mi">0</span><span class="o">],</span>
        <span class="o">[</span>   <span class="mi">2</span><span class="o">,</span>    <span class="mi">0</span><span class="o">,</span>    <span class="mi">0</span><span class="o">,</span>    <span class="mi">0</span><span class="o">,</span>    <span class="mi">0</span><span class="o">]])</span>
<span class="n">mask</span><span class="o">:</span> <span class="n">tensor</span><span class="o">([[</span><span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">],</span>
        <span class="o">[</span><span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">],</span>
        <span class="o">[</span><span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">],</span>
        <span class="o">[</span><span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">],</span>
        <span class="o">[</span><span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">],</span>
        <span class="o">[</span><span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">0</span><span class="o">],</span>
        <span class="o">[</span><span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="mi">0</span><span class="o">],</span>
        <span class="o">[</span><span class="mi">1</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="mi">0</span><span class="o">],</span>
        <span class="o">[</span><span class="mi">1</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="mi">0</span><span class="o">],</span>
        <span class="o">[</span><span class="mi">1</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="mi">0</span><span class="o">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="na">uint8</span><span class="o">)</span>
<span class="n">max_target_len</span><span class="o">:</span> <span class="mi">10</span>
</pre></div>
</td></tr></table>

<h2 id="_7">定义模型</h2>
<h3 id="seq2seq">Seq2Seq 模型</h3>
<p>我们这个聊天机器人的大脑是序列到序列（seq2seq）模型。seq2seq模型的目标是将可变长度序列作为输入，并使用固定大小的模型将可变长度序列作为输出返回。</p>
<p><a href="https://arxiv.org/abs/1409.3215">Sutskever 等人</a> 发现通过使用两个独立的递归神经网络(RNN)，我们可以完成这项任务。</p>
<p>第一个RNN扮演<strong>编码器</strong>的角色，它将可变长度输入序列编码成固定长度的上下文向量。
理论上，这个上下文向量（RNN的最终隐藏层）将包含关于输入给机器人的询问句的语义信息。</p>
<p>第二个RNN是<strong>解码器</strong>，它采用输入词和上下文向量，并返回序列中后续词的猜测值，以及用于下次迭代的隐藏层。</p>
<p><img alt="model" src="https://jeddy92.github.io/images/ts_intro/seq2seq_ts.png" /></p>
<p>图片来源：<a href="https://jeddy92.github.io/JEddy92.github.io/ts_seq2seq_intro/">https://jeddy92.github.io/JEddy92.github.io/ts_seq2seq_intro/</a></p>
<h4 id="_8">编码器</h4>
<p>编码器RNN一次迭代输入句子的一个标记(token)，每个时间步骤输出一个“输出”向量和一个“隐藏状态”向量。
然后将隐藏状态向量传递给下一个时间步骤，同时记录输出向量。
编码器将其在序列中的每个点看到的上下文转换为高维空间中的一组点，解码器将使用这组点来为给定任务生成有意义的输出。</p>
<p>我们这个编码器的的核心是多层门控单元(GRU)，由<a href="https://arxiv.org/pdf/1406.1078v3.pdf">Cho 等人</a>于2014年发明。
我们将使用GRU的一种变种——双向GRU，它使用两种独立的RNN：一个以正常的顺序接收输入序列，另一个以反方向接收输入序列。
在同一时间步骤中对每个网络的输出求和。
使用双向GRU讲给我们带来对过去和未来上下文进行编码的优势。</p>
<p>双向RNN:</p>
<p><img alt="rnn_bidir" src="https://colah.github.io/posts/2015-09-NN-Types-FP/img/RNN-bidirectional.png" /></p>
<p>图片来源：<a href="https://colah.github.io/posts/2015-09-NN-Types-FP/">https://colah.github.io/posts/2015-09-NN-Types-FP/</a></p>
<p>注意，一个<code>embedding</code>层用于在任意大小的特征空间中编码我们的单词索引。
对于我们的模型，这个层会将每个词映射到大小为<em>hidden_size</em>的特征空间。
训练后，这些值应该编码了近义词之间的语义相似度。</p>
<p>Finally, if passing a padded batch of sequences to an RNN module, we
must pack and unpack padding around the RNN pass using
最有，如果要填充后的一批序列传入RNN模块，我们必须围绕RNN进行打包和解包，这些方法分别是：
- <code>nn.utils.rnn.pack_padded_sequence</code>
- <code>nn.utils.rnn.pad_packed_sequence</code></p>
<p><strong>计算图：</strong></p>
<ol>
<li>将词的索引值转为嵌入</li>
<li>为RNN模块打包填充后的序列批次</li>
<li>通过GRU前向传递</li>
<li>解包填充</li>
<li>双向GRU输出求和</li>
<li>返回输出和最终隐藏状态</li>
</ol>
<p><strong>输入：</strong></p>
<ul>
<li><code>input_seq</code>: 输入句子批次；形状=<em>(max_length,batch_size)</em></li>
<li><code>input_lengths</code>: 由批次中每个句子的长度的所构成的列表；形状=<em>(batch_size)</em></li>
<li><code>hidden</code>: 隐藏状态；形状=<em>(n_layers x num_directions, batch_size, hidden_size)</em></li>
</ul>
<p><strong>输出：</strong></p>
<ul>
<li><code>outputs</code>: 从GRN最终隐藏层的输出特征；形状=<em>(max_length, batch_size, hidden_size)</em></li>
<li><code>hidden</code>: 从GRU更新的隐藏状态；形状=<em>(n_layers x num_directions, batch_size, hidden_size)</em></li>
</ul>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">EncoderRNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">embedding</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">EncoderRNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">embedding</span>

        <span class="c1"># Initialize GRU; the input_size and hidden_size params are both set to &#39;hidden_size&#39;</span>
        <span class="c1">#   because our input size is a word embedding with number of features == hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span>
                          <span class="n">dropout</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span> <span class="k">if</span> <span class="n">n_layers</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">dropout</span><span class="p">),</span> <span class="n">bidirectional</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_seq</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="n">hidden</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="c1"># Convert word indexes to embeddings</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">input_seq</span><span class="p">)</span>
        <span class="c1"># Pack padded batch of sequences for RNN module</span>
        <span class="n">packed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pack_padded_sequence</span><span class="p">(</span><span class="n">embedded</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">)</span>
        <span class="c1"># Forward pass through GRU</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">packed</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
        <span class="c1"># Unpack padding</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pad_packed_sequence</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
        <span class="c1"># Sum bidirectional GRU outputs</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">]</span> <span class="o">+</span> <span class="n">outputs</span><span class="p">[:,</span> <span class="p">:</span> <span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">:]</span>
        <span class="c1"># Return output and final hidden state</span>
        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">hidden</span>
</pre></div>
</td></tr></table>

<h4 id="_9">解码器</h4>
<p>解码器RNN以一个接一个标记(token-by-token)的形式生成回复句子。
它使用编码器的上下文向量和内置隐藏状态生成序列中的后续词。
它持续的生成词，直到输出<em>EOS_token</em>——表示句子的结束。
寻常的Seq2Seq解码器常常遇到的一个问题就是，如果我们依赖于上下文向量来编码整个输入的语义，那么我们很可能丢失信息。</p>
<p>在处理长输入序列的时候尤其如此，这极大的限制了我们这个解码器的能力。
为了解决这个问题，<a href="https://arxiv.org/abs/1409.0473">Bahdanau 等人</a>创建了“注意力机制”，允许解码器只关注输入序列的某些部分，而不是在每一步都使用整个固定的上下文。</p>
<p>在上层，用解码器的当前隐藏状态和编码器的输出计算注意力。
输出注意力权重和输入序列具有相同的形状，这让我们可以将它和编码器输出相乘，得到编码器输出中的要被加以注意力的部分的加权和。</p>
<p><a href="https://github.com/spro">Sean Robertson</a> 的图示很好的描述了这点：</p>
<p><img alt="attn2" src="https://pytorch.org/tutorials/_images/attn2.png" /></p>
<p><a href="https://arxiv.org/abs/1508.04025">Luong 等人</a>创建了“全局注意力”来改进<a href="https://arxiv.org/abs/1409.0473">Bahdanau 等人</a>的基础工作。
“全局注意力”最关键的不同之处在于：它会考虑所有的编码器隐藏状态，而不是<a href="https://arxiv.org/abs/1409.0473">Bahdanau 等人</a>的只考虑当前时间步骤中的编码器隐藏状态的“局部注意力”方式。
另一个不同之处在于，使用“全局注意力”，我们仅仅使用当前时间步骤的编码器的隐藏状态来计算注意力的权重或能量值。
<a href="https://arxiv.org/abs/1409.0473">Bahdanau 等人</a>的注意力计算需要了解上一个时间步骤中编码器的状态。
Also, Luong et al. provides various methods to calculate the
attention energies between the encoder output and decoder output which
are called “score functions”:
此外，<a href="https://arxiv.org/abs/1508.04025">Luong 等人</a>提供了用于计算编码器输出和解码器输出之间的注意力的的多种方法，他们被成为“得分函数”（score functions）：</p>
<p><img alt="scores" src="https://pytorch.org/tutorials/_images/scores.png" /></p>
<p>其中，
- <span><span class="MathJax_Preview">h_t</span><script type="math/tex">h_t</script></span> 为当前目标解码器状的态
- <span><span class="MathJax_Preview">\bar{h}_s</span><script type="math/tex">\bar{h}_s</script></span> 为所有编码器的状态</p>
<p>总体而言，全局注意力机制可以通过下图来总结。
注意我们将在被称作<code>Attn</code>的分离的<code>nn.Module</code>中实现“注意力层”。
这个模块的输出是一个 softmax 标准化权重张量，其形状是 <em>(batch_size, 1, max_length)</em> 。</p>
<p><img alt="global_attn" src="https://pytorch.org/tutorials/_images/global_attn.png" /></p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Luong attention layer</span>
<span class="k">class</span> <span class="nc">Attn</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Attn</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="n">method</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;dot&#39;</span><span class="p">,</span> <span class="s1">&#39;general&#39;</span><span class="p">,</span> <span class="s1">&#39;concat&#39;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">method</span><span class="p">,</span> <span class="s2">&quot;is not an appropriate attention method.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;general&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;concat&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">dot_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_output</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">hidden</span> <span class="o">*</span> <span class="n">encoder_output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">general_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_output</span><span class="p">):</span>
        <span class="n">energy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">encoder_output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">hidden</span> <span class="o">*</span> <span class="n">energy</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">concat_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_output</span><span class="p">):</span>
        <span class="n">energy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">hidden</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">encoder_output</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">encoder_output</span><span class="p">),</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">tanh</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">*</span> <span class="n">energy</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">):</span>
        <span class="c1"># Calculate the attention weights (energies) based on the given method</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;general&#39;</span><span class="p">:</span>
            <span class="n">attn_energies</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">general_score</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;concat&#39;</span><span class="p">:</span>
            <span class="n">attn_energies</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">concat_score</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;dot&#39;</span><span class="p">:</span>
            <span class="n">attn_energies</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dot_score</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>

        <span class="c1"># Transpose max_length and batch_size dimensions</span>
        <span class="n">attn_energies</span> <span class="o">=</span> <span class="n">attn_energies</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>

        <span class="c1"># Return the softmax normalized probability scores (with added dimension)</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attn_energies</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>现在，我们已经定义了注意力子模块，可以实现实际的解码器模块了。
对于解码器，我们将手动的在每个时间步骤中提供批数据。
这意味着我们的嵌入词张量和GRU输出的形状都是 <em>(1, batch_size, hidden_size)</em> 。</p>
<p><strong>计算图：</strong></p>
<ol>
<li>获得当前输入词的强如嵌入。</li>
<li>单向GRU前向。</li>
<li>有第二步的GRU输出计算注意力权重。</li>
<li>注意力权重与编码器输出相乘，得到“加权和”(weighted sum)上下文向量。</li>
<li>使用 Luong 等人的方法将加权上下文向量和GRU输出相加。</li>
<li>使用 Luong 等人的方法(不用 softmax)预测后续词。</li>
<li>返回输出和最终隐藏层。</li>
</ol>
<p><strong>输入：</strong></p>
<ul>
<li><code>input_step</code>: 输入序列批的一个时间步骤 (一个词)；形状=<em>(1, batch_size)</em></li>
<li><code>last_hidden</code>:  GRU的最终隐藏层；形状=(n_layers x num_directions, batch_size, hidden_size)*</li>
<li><code>encoder_outputs</code>: 编码器的模型输出; 性转=<em>(max_length, batch_size, hidden_size)</em></li>
</ul>
<p><strong>输出：</strong></p>
<ul>
<li><code>输出</code>: softmax 正规化张量，给出了被解码序列中每个词是正确的后续词的概率; 形状=<em>(batch_size, voc.num_words)</em></li>
<li><code>hidden</code>: GRU的最终隐藏状态; 形状=<em>(n_layers x num_directions, batch_size, hidden_size)</em></li>
</ul>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">LuongAttnDecoderRNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attn_model</span><span class="p">,</span> <span class="n">embedding</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LuongAttnDecoderRNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Keep for reference</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn_model</span> <span class="o">=</span> <span class="n">attn_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="n">output_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>

        <span class="c1"># Define layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">embedding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span> <span class="k">if</span> <span class="n">n_layers</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">dropout</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">concat</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">Attn</span><span class="p">(</span><span class="n">attn_model</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_step</span><span class="p">,</span> <span class="n">last_hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">):</span>
        <span class="c1"># Note: we run this one step (word) at a time</span>
        <span class="c1"># Get embedding of current input word</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">input_step</span><span class="p">)</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_dropout</span><span class="p">(</span><span class="n">embedded</span><span class="p">)</span>
        <span class="c1"># Forward through unidirectional GRU</span>
        <span class="n">rnn_output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">embedded</span><span class="p">,</span> <span class="n">last_hidden</span><span class="p">)</span>
        <span class="c1"># Calculate attention weights from the current GRU output</span>
        <span class="n">attn_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">rnn_output</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>
        <span class="c1"># Multiply attention weights to encoder outputs to get new &quot;weighted sum&quot; context vector</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">attn_weights</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="c1"># Concatenate weighted context vector and GRU output using Luong eq. 5</span>
        <span class="n">rnn_output</span> <span class="o">=</span> <span class="n">rnn_output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">concat_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">rnn_output</span><span class="p">,</span> <span class="n">context</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">concat_output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">concat_input</span><span class="p">))</span>
        <span class="c1"># Predict next word using Luong eq. 6</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">concat_output</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># Return output and final hidden state</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span>
</pre></div>
</td></tr></table>

<h2 id="_10">定义训练过程</h2>
<h3 id="_11">损失掩码</h3>
<p>由于我们处理的是批量填充序列，因此在计算损失时我们不能简单地仅考虑张量的全部元素。
而是通过定义<code>maskNLLLoss</code>损失函数，基于解码器输出张量，目标张量和描述目标张量填充的二进制掩码张量，来计算损失。
该损失函数计算了对应于掩码向量中<em>1</em>的元素的负对数相似度。</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">maskNLLLoss</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
    <span class="n">nTotal</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">crossEntropy</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">target</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">crossEntropy</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">nTotal</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</pre></div>
</td></tr></table>

<h3 id="_12">单次训练迭代</h3>
<p>函数 <code>train</code> 包含一个单次训练迭代（单个输入批次）算法。</p>
<p>我们用一些巧妙的技巧来促进收敛：</p>
<ul>
<li>
<p>第一个技巧是使用<strong>教师强制</strong>。
  这意味着某些情况下，通过设置<code>teacher_forcing_ratio</code>，我们使用当前目标词，而不是使用解码器的当前猜测结果，作为解码器的后续输入。
  这项技术是训练解码器的轮子，有助于更有效的训练。
  教师强制会导致模型在推理期间不稳定，这是因为解码器在训练中没有足够的机会真正的制作它自己的输出序列。
  所有，我们必须注意地如何设置<code>teacher_forcing_ratio</code>，不要被快速收敛欺骗。</p>
</li>
<li>
<p>我们要实现的第二个技巧是<strong>梯度剪切</strong>。
  这是一种用于对抗“梯度爆炸”的常用技术。
  本质上，通过剪切或者最大阈值，我们防止梯度爆炸性增长和溢出(NaN)，或者在成本函数中从悬崖跌落。</p>
</li>
</ul>
<p><img alt="grad_clip" src="https://pytorch.org/tutorials/_images/grad_clip.png" /></p>
<p>图像来源: <a href="https://www.deeplearningbook.org/">Goodfellow 等人 <em>Deep Learning</em>. 2016.</a></p>
<p><strong>运算顺序：</strong></p>
<ol>
<li>通过编码器向前传递整个输入批次。</li>
<li>将解码器输入初始化为<code>SOS_token</code>和编码器最终隐藏层的隐藏状态。</li>
<li>在每个时间步骤中，通过解码器向前传递输入批的序列。</li>
<li>如果用到了教师强制：把下一个解码器输入作为当前目标；其它：用下一个解码器输入作为当前解码器输出。</li>
<li>计算和累积损失。</li>
<li>进行反向传播</li>
<li>剪切梯度。</li>
<li>更新编码器和解码器模型的参数。</li>
</ol>
<p>!!! note &ldquo;注意&rdquo;:
  只需将 PyTorch RNN 模块(<code>RNN</code>, <code>LSTM</code>, <code>GRU</code>)的整个输入序列（或批次的序列）传入，它们就可以被用于任何其它类似的非递归层。
  我们在<code>encoder</code>中这样使用<code>GUR</code>层。
  实际情况是，在底层，每一个时间步骤上都有一个交互过程迭代计算隐藏状态。</p>
<p>另外，也可以每个时间步骤运行这些模型。
  在这种情况下，我们在训练过程里手动循环遍历序列，就像对<code>decoder</code>模型做的那样。
  只要维护好这些模块正确的概念模型，实现序列模型就可以非常简单。</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">input_variable</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">target_variable</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">max_target_len</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">embedding</span><span class="p">,</span>
          <span class="n">encoder_optimizer</span><span class="p">,</span> <span class="n">decoder_optimizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">clip</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="n">MAX_LENGTH</span><span class="p">):</span>

    <span class="c1"># Zero gradients</span>
    <span class="n">encoder_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">decoder_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="c1"># Set device options</span>
    <span class="n">input_variable</span> <span class="o">=</span> <span class="n">input_variable</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">lengths</span> <span class="o">=</span> <span class="n">lengths</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">target_variable</span> <span class="o">=</span> <span class="n">target_variable</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Initialize variables</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">print_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_totals</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Forward pass through encoder</span>
    <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">encoder_hidden</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_variable</span><span class="p">,</span> <span class="n">lengths</span><span class="p">)</span>

    <span class="c1"># Create initial decoder input (start with SOS tokens for each sentence)</span>
    <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="n">SOS_token</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)]])</span>
    <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">decoder_input</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Set initial decoder hidden state to the encoder&#39;s final hidden state</span>
    <span class="n">decoder_hidden</span> <span class="o">=</span> <span class="n">encoder_hidden</span><span class="p">[:</span><span class="n">decoder</span><span class="o">.</span><span class="n">n_layers</span><span class="p">]</span>

    <span class="c1"># Determine if we are using teacher forcing this iteration</span>
    <span class="n">use_teacher_forcing</span> <span class="o">=</span> <span class="bp">True</span> <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">teacher_forcing_ratio</span> <span class="k">else</span> <span class="bp">False</span>

    <span class="c1"># Forward batch of sequences through decoder one time step at a time</span>
    <span class="k">if</span> <span class="n">use_teacher_forcing</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_target_len</span><span class="p">):</span>
            <span class="n">decoder_output</span><span class="p">,</span> <span class="n">decoder_hidden</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span>
                <span class="n">decoder_input</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span>
            <span class="p">)</span>
            <span class="c1"># Teacher forcing: next input is current target</span>
            <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">target_variable</span><span class="p">[</span><span class="n">t</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="c1"># Calculate and accumulate loss</span>
            <span class="n">mask_loss</span><span class="p">,</span> <span class="n">nTotal</span> <span class="o">=</span> <span class="n">maskNLLLoss</span><span class="p">(</span><span class="n">decoder_output</span><span class="p">,</span> <span class="n">target_variable</span><span class="p">[</span><span class="n">t</span><span class="p">],</span> <span class="n">mask</span><span class="p">[</span><span class="n">t</span><span class="p">])</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">mask_loss</span>
            <span class="n">print_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mask_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">nTotal</span><span class="p">)</span>
            <span class="n">n_totals</span> <span class="o">+=</span> <span class="n">nTotal</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_target_len</span><span class="p">):</span>
            <span class="n">decoder_output</span><span class="p">,</span> <span class="n">decoder_hidden</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span>
                <span class="n">decoder_input</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span>
            <span class="p">)</span>
            <span class="c1"># No teacher forcing: next input is decoder&#39;s own current output</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">topi</span> <span class="o">=</span> <span class="n">decoder_output</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="n">topi</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)]])</span>
            <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">decoder_input</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="c1"># Calculate and accumulate loss</span>
            <span class="n">mask_loss</span><span class="p">,</span> <span class="n">nTotal</span> <span class="o">=</span> <span class="n">maskNLLLoss</span><span class="p">(</span><span class="n">decoder_output</span><span class="p">,</span> <span class="n">target_variable</span><span class="p">[</span><span class="n">t</span><span class="p">],</span> <span class="n">mask</span><span class="p">[</span><span class="n">t</span><span class="p">])</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">mask_loss</span>
            <span class="n">print_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mask_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">nTotal</span><span class="p">)</span>
            <span class="n">n_totals</span> <span class="o">+=</span> <span class="n">nTotal</span>

    <span class="c1"># Perform backpropatation</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="c1"># Clip gradients: gradients are modified in place</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">clip</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">decoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">clip</span><span class="p">)</span>

    <span class="c1"># Adjust model weights</span>
    <span class="n">encoder_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">decoder_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">print_losses</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_totals</span>
</pre></div>
</td></tr></table>

<p>Training iterations
~~~~~~~~~~~~~~~~~~~</p>
<p>It is finally time to tie the full training procedure together with the
data. The <code>trainIters</code> function is responsible for running
<code>n_iterations</code> of training given the passed models, optimizers, data,
etc. This function is quite self explanatory, as we have done the heavy
lifting with the <code>train</code> function.</p>
<p>One thing to note is that when we save our model, we save a tarball
containing the encoder and decoder state_dicts (parameters), the
optimizers’ state_dicts, the loss, the iteration, etc. Saving the model
in this way will give us the ultimate flexibility with the checkpoint.
After loading a checkpoint, we will be able to use the model parameters
to run inference, or we can continue training right where we left off.</p>
<p>```python
def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="err">#</span> <span class="nt">Load</span> <span class="nt">batches</span> <span class="nt">for</span> <span class="nt">each</span> <span class="nt">iteration</span>
<span class="nt">training_batches</span> <span class="o">=</span> <span class="cp">[</span><span class="nx">batch2TrainData</span><span class="p">(</span><span class="nx">voc</span><span class="p">,</span> <span class="err">[</span><span class="nx">random.choice</span><span class="p">(</span><span class="nx">pairs</span><span class="p">)</span> <span class="nx">for</span> <span class="n">_</span> <span class="k">in</span> <span class="nb">range</span><span class="p">(</span><span class="nx">batch_size</span><span class="p">)</span><span class="cp">]</span><span class="o">)</span>
                  <span class="nt">for</span> <span class="nt">_</span> <span class="nt">in</span> <span class="nt">range</span><span class="o">(</span><span class="nt">n_iteration</span><span class="o">)]</span>

<span class="err">#</span> <span class="nt">Initializations</span>
<span class="nt">print</span><span class="o">(</span><span class="s1">&#39;Initializing ...&#39;</span><span class="o">)</span>
<span class="nt">start_iteration</span> <span class="o">=</span> <span class="nt">1</span>
<span class="nt">print_loss</span> <span class="o">=</span> <span class="nt">0</span>
<span class="nt">if</span> <span class="nt">loadFilename</span><span class="o">:</span>
    <span class="nt">start_iteration</span> <span class="o">=</span> <span class="nt">checkpoint</span><span class="cp">[</span><span class="s1">&#39;iteration&#39;</span><span class="cp">]</span> <span class="o">+</span> <span class="nt">1</span>

<span class="err">#</span> <span class="nt">Training</span> <span class="nt">loop</span>
<span class="nt">print</span><span class="o">(</span><span class="s2">&quot;Training...&quot;</span><span class="o">)</span>
<span class="nt">for</span> <span class="nt">iteration</span> <span class="nt">in</span> <span class="nt">range</span><span class="o">(</span><span class="nt">start_iteration</span><span class="o">,</span> <span class="nt">n_iteration</span> <span class="o">+</span> <span class="nt">1</span><span class="o">):</span>
    <span class="nt">training_batch</span> <span class="o">=</span> <span class="nt">training_batches</span><span class="cp">[</span><span class="nx">iteration</span> <span class="o">-</span> <span class="mi">1</span><span class="cp">]</span>
    <span class="err">#</span> <span class="nt">Extract</span> <span class="nt">fields</span> <span class="nt">from</span> <span class="nt">batch</span>
    <span class="nt">input_variable</span><span class="o">,</span> <span class="nt">lengths</span><span class="o">,</span> <span class="nt">target_variable</span><span class="o">,</span> <span class="nt">mask</span><span class="o">,</span> <span class="nt">max_target_len</span> <span class="o">=</span> <span class="nt">training_batch</span>

    <span class="err">#</span> <span class="nt">Run</span> <span class="nt">a</span> <span class="nt">training</span> <span class="nt">iteration</span> <span class="nt">with</span> <span class="nt">batch</span>
    <span class="nt">loss</span> <span class="o">=</span> <span class="nt">train</span><span class="o">(</span><span class="nt">input_variable</span><span class="o">,</span> <span class="nt">lengths</span><span class="o">,</span> <span class="nt">target_variable</span><span class="o">,</span> <span class="nt">mask</span><span class="o">,</span> <span class="nt">max_target_len</span><span class="o">,</span> <span class="nt">encoder</span><span class="o">,</span>
                 <span class="nt">decoder</span><span class="o">,</span> <span class="nt">embedding</span><span class="o">,</span> <span class="nt">encoder_optimizer</span><span class="o">,</span> <span class="nt">decoder_optimizer</span><span class="o">,</span> <span class="nt">batch_size</span><span class="o">,</span> <span class="nt">clip</span><span class="o">)</span>
    <span class="nt">print_loss</span> <span class="o">+=</span> <span class="nt">loss</span>

    <span class="err">#</span> <span class="nt">Print</span> <span class="nt">progress</span>
    <span class="nt">if</span> <span class="nt">iteration</span> <span class="o">%</span> <span class="nt">print_every</span> <span class="o">==</span> <span class="nt">0</span><span class="o">:</span>
        <span class="nt">print_loss_avg</span> <span class="o">=</span> <span class="nt">print_loss</span> <span class="o">/</span> <span class="nt">print_every</span>
        <span class="nt">print</span><span class="o">(</span><span class="s2">&quot;Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}&quot;</span><span class="p">.</span><span class="nc">format</span><span class="o">(</span><span class="nt">iteration</span><span class="o">,</span> <span class="nt">iteration</span> <span class="o">/</span> <span class="nt">n_iteration</span> <span class="o">*</span> <span class="nt">100</span><span class="o">,</span> <span class="nt">print_loss_avg</span><span class="o">))</span>
        <span class="nt">print_loss</span> <span class="o">=</span> <span class="nt">0</span>

    <span class="err">#</span> <span class="nt">Save</span> <span class="nt">checkpoint</span>
    <span class="nt">if</span> <span class="o">(</span><span class="nt">iteration</span> <span class="o">%</span> <span class="nt">save_every</span> <span class="o">==</span> <span class="nt">0</span><span class="o">):</span>
        <span class="nt">directory</span> <span class="o">=</span> <span class="nt">os</span><span class="p">.</span><span class="nc">path</span><span class="p">.</span><span class="nc">join</span><span class="o">(</span><span class="nt">save_dir</span><span class="o">,</span> <span class="nt">model_name</span><span class="o">,</span> <span class="nt">corpus_name</span><span class="o">,</span> <span class="s1">&#39;{}-{}_{}&#39;</span><span class="p">.</span><span class="nc">format</span><span class="o">(</span><span class="nt">encoder_n_layers</span><span class="o">,</span> <span class="nt">decoder_n_layers</span><span class="o">,</span> <span class="nt">hidden_size</span><span class="o">))</span>
        <span class="nt">if</span> <span class="nt">not</span> <span class="nt">os</span><span class="p">.</span><span class="nc">path</span><span class="p">.</span><span class="nc">exists</span><span class="o">(</span><span class="nt">directory</span><span class="o">):</span>
            <span class="nt">os</span><span class="p">.</span><span class="nc">makedirs</span><span class="o">(</span><span class="nt">directory</span><span class="o">)</span>
        <span class="nt">torch</span><span class="p">.</span><span class="nc">save</span><span class="o">(</span><span class="p">{</span>
            <span class="err">&#39;iteration&#39;:</span> <span class="err">iteration,</span>
            <span class="err">&#39;en&#39;:</span> <span class="err">encoder.state_dict(),</span>
            <span class="err">&#39;de&#39;:</span> <span class="err">decoder.state_dict(),</span>
            <span class="err">&#39;en_opt&#39;:</span> <span class="err">encoder_optimizer.state_dict(),</span>
            <span class="err">&#39;de_opt&#39;:</span> <span class="err">decoder_optimizer.state_dict(),</span>
            <span class="err">&#39;loss&#39;:</span> <span class="err">loss,</span>
            <span class="err">&#39;voc_dict&#39;:</span> <span class="err">voc.__dict__,</span>
            <span class="err">&#39;embedding&#39;:</span> <span class="err">embedding.state_dict()</span>
        <span class="p">}</span><span class="o">,</span> <span class="nt">os</span><span class="p">.</span><span class="nc">path</span><span class="p">.</span><span class="nc">join</span><span class="o">(</span><span class="nt">directory</span><span class="o">,</span> <span class="s1">&#39;{}_{}.tar&#39;</span><span class="p">.</span><span class="nc">format</span><span class="o">(</span><span class="nt">iteration</span><span class="o">,</span> <span class="s1">&#39;checkpoint&#39;</span><span class="o">)))</span>
</pre></div>
</td></tr></table>

<p>```</p>
<h2 id="define-evaluation">Define Evaluation</h2>
<p>After training a model, we want to be able to talk to the bot ourselves.
First, we must define how we want the model to decode the encoded input.</p>
<p>Greedy decoding
~~~~~~~~~~~~~~~</p>
<p>Greedy decoding is the decoding method that we use during training when
we are <strong>NOT</strong> using teacher forcing. In other words, for each time
step, we simply choose the word from <code>decoder_output</code> with the highest
softmax value. This decoding method is optimal on a single time-step
level.</p>
<p>To facilite the greedy decoding operation, we define a
<code>GreedySearchDecoder</code> class. When run, an object of this class takes
an input sequence (<code>input_seq</code>) of shape <em>(input_seq length, 1)</em>, a
scalar input length (<code>input_length</code>) tensor, and a <code>max_length</code> to
bound the response sentence length. The input sentence is evaluated
using the following computational graph:</p>
<p><strong>Computation Graph:</strong></p>
<p>1) Forward input through encoder model.
   2) Prepare encoder&rsquo;s final hidden layer to be first hidden input to the decoder.
   3) Initialize decoder&rsquo;s first input as SOS_token.
   4) Initialize tensors to append decoded words to.
   5) Iteratively decode one word token at a time:
       a) Forward pass through decoder.
       b) Obtain most likely word token and its softmax score.
       c) Record token and score.
       d) Prepare current token to be next decoder input.
   6) Return collections of word tokens and scores.</p>
<p>```python
class GreedySearchDecoder(nn.Module):
    def <strong>init</strong>(self, encoder, decoder):
        super(GreedySearchDecoder, self).<strong>init</strong>()
        self.encoder = encoder
        self.decoder = decoder</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>def forward(self, input_seq, input_length, max_length):
    # Forward input through encoder model
    encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)
    # Prepare encoder&#39;s final hidden layer to be first hidden input to the decoder
    decoder_hidden = encoder_hidden[:decoder.n_layers]
    # Initialize decoder input with SOS_token
    decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token
    # Initialize tensors to append decoded words to
    all_tokens = torch.zeros([0], device=device, dtype=torch.long)
    all_scores = torch.zeros([0], device=device)
    # Iteratively decode one word token at a time
    for _ in range(max_length):
        # Forward pass through decoder
        decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)
        # Obtain most likely word token and its softmax score
        decoder_scores, decoder_input = torch.max(decoder_output, dim=1)
        # Record token and score
        all_tokens = torch.cat((all_tokens, decoder_input), dim=0)
        all_scores = torch.cat((all_scores, decoder_scores), dim=0)
        # Prepare current token to be next decoder input (add a dimension)
        decoder_input = torch.unsqueeze(decoder_input, 0)
    # Return collections of word tokens and scores
    return all_tokens, all_scores
</pre></div>
</td></tr></table>

<p>```</p>
<p>Evaluate my text
~~~~~~~~~~~~~~~~</p>
<p>Now that we have our decoding method defined, we can write functions for
evaluating a string input sentence. The <code>evaluate</code> function manages
the low-level process of handling the input sentence. We first format
the sentence as an input batch of word indexes with <em>batch_size==1</em>. We
do this by converting the words of the sentence to their corresponding
indexes, and transposing the dimensions to prepare the tensor for our
models. We also create a <code>lengths</code> tensor which contains the length of
our input sentence. In this case, <code>lengths</code> is scalar because we are
only evaluating one sentence at a time (batch_size==1). Next, we obtain
the decoded response sentence tensor using our <code>GreedySearchDecoder</code>
object (<code>searcher</code>). Finally, we convert the response’s indexes to
words and return the list of decoded words.</p>
<p><code>evaluateInput</code> acts as the user interface for our chatbot. When
called, an input text field will spawn in which we can enter our query
sentence. After typing our input sentence and pressing <em>Enter</em>, our text
is normalized in the same way as our training data, and is ultimately
fed to the <code>evaluate</code> function to obtain a decoded output sentence. We
loop this process, so we can keep chatting with our bot until we enter
either “q” or “quit”.</p>
<p>Finally, if a sentence is entered that contains a word that is not in
the vocabulary, we handle this gracefully by printing an error message
and prompting the user to enter another sentence.</p>
<p>```python
def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):
    ### Format input sentence as a batch
    # words -&gt; indexes
    indexes_batch = [indexesFromSentence(voc, sentence)]
    # Create lengths tensor
    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])
    # Transpose dimensions of batch to match models&rsquo; expectations
    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)
    # Use appropriate device
    input_batch = input_batch.to(device)
    lengths = lengths.to(device)
    # Decode sentence with searcher
    tokens, scores = searcher(input_batch, lengths, max_length)
    # indexes -&gt; words
    decoded_words = [voc.index2word[token.item()] for token in tokens]
    return decoded_words</p>
<p>def evaluateInput(encoder, decoder, searcher, voc):
    input_sentence = &lsquo;&rsquo;
    while(1):
        try:
            # Get input sentence
            input_sentence = input(&lsquo;&gt; &lsquo;)
            # Check if it is quit case
            if input_sentence == &lsquo;q&rsquo; or input_sentence == &lsquo;quit&rsquo;: break
            # Normalize sentence
            input_sentence = normalizeString(input_sentence)
            # Evaluate sentence
            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)
            # Format and print response sentence
            output_words[:] = [x for x in output_words if not (x == &lsquo;EOS&rsquo; or x == &lsquo;PAD&rsquo;)]
            print(&lsquo;Bot:&rsquo;, &lsquo; &lsquo;.join(output_words))</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>    except KeyError:
        print(&quot;Error: Encountered unknown word.&quot;)
</pre></div>
</td></tr></table>

<p>```</p>
<h2 id="run-model">Run Model</h2>
<p>Finally, it is time to run our model!</p>
<p>Regardless of whether we want to train or test the chatbot model, we
must initialize the individual encoder and decoder models. In the
following block, we set our desired configurations, choose to start from
scratch or set a checkpoint to load from, and build and initialize the
models. Feel free to play with different model configurations to
optimize performance.</p>
<p>```python</p>
<h1 id="configure-models">Configure models</h1>
<p>model_name = &lsquo;cb_model&rsquo;
attn_model = &lsquo;dot&rsquo;</p>
<h1 id="attn_model-general">attn_model = &lsquo;general&rsquo;</h1>
<h1 id="attn_model-concat">attn_model = &lsquo;concat&rsquo;</h1>
<p>hidden_size = 500
encoder_n_layers = 2
decoder_n_layers = 2
dropout = 0.1
batch_size = 64</p>
<h1 id="set-checkpoint-to-load-from-set-to-none-if-starting-from-scratch">Set checkpoint to load from; set to None if starting from scratch</h1>
<p>loadFilename = None
checkpoint_iter = 4000</p>
<h1 id="loadfilename-ospathjoinsave_dir-model_name-corpus_name">loadFilename = os.path.join(save_dir, model_name, corpus_name,</h1>
<h1 id="-_formatencoder_n_layers-decoder_n_layers-hidden_size">&rsquo;{}-{}_{}&rsquo;.format(encoder_n_layers, decoder_n_layers, hidden_size),</h1>
<h1 id="_checkpointtarformatcheckpoint_iter">&rsquo;{}_checkpoint.tar&rsquo;.format(checkpoint_iter))</h1>
<h1 id="load-model-if-a-loadfilename-is-provided">Load model if a loadFilename is provided</h1>
<p>if loadFilename:
    # If loading on same machine the model was trained on
    checkpoint = torch.load(loadFilename)
    # If loading a model trained on GPU to CPU
    #checkpoint = torch.load(loadFilename, map_location=torch.device(&lsquo;cpu&rsquo;))
    encoder_sd = checkpoint[&lsquo;en&rsquo;]
    decoder_sd = checkpoint[&lsquo;de&rsquo;]
    encoder_optimizer_sd = checkpoint[&lsquo;en_opt&rsquo;]
    decoder_optimizer_sd = checkpoint[&lsquo;de_opt&rsquo;]
    embedding_sd = checkpoint[&lsquo;embedding&rsquo;]
    voc.<strong>dict</strong> = checkpoint[&lsquo;voc_dict&rsquo;]</p>
<p>print(&lsquo;Building encoder and decoder &hellip;&rsquo;)</p>
<h1 id="initialize-word-embeddings">Initialize word embeddings</h1>
<p>embedding = nn.Embedding(voc.num_words, hidden_size)
if loadFilename:
    embedding.load_state_dict(embedding_sd)</p>
<h1 id="initialize-encoder-decoder-models">Initialize encoder &amp; decoder models</h1>
<p>encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)
decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)
if loadFilename:
    encoder.load_state_dict(encoder_sd)
    decoder.load_state_dict(decoder_sd)</p>
<h1 id="use-appropriate-device">Use appropriate device</h1>
<p>encoder = encoder.to(device)
decoder = decoder.to(device)
print(&lsquo;Models built and ready to go!&rsquo;)
```</p>
<p>Run Training
~~~~~~~~~~~~</p>
<p>Run the following block if you want to train the model.</p>
<p>First we set training parameters, then we initialize our optimizers, and
finally we call the <code>trainIters</code> function to run our training
iterations.</p>
<p>```python</p>
<h1 id="configure-trainingoptimization">Configure training/optimization</h1>
<p>clip = 50.0
teacher_forcing_ratio = 1.0
learning_rate = 0.0001
decoder_learning_ratio = 5.0
n_iteration = 4000
print_every = 1
save_every = 500</p>
<h1 id="ensure-dropout-layers-are-in-train-mode">Ensure dropout layers are in train mode</h1>
<p>encoder.train()
decoder.train()</p>
<h1 id="initialize-optimizers">Initialize optimizers</h1>
<p>print(&lsquo;Building optimizers &hellip;&rsquo;)
encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)
decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)
if loadFilename:
    encoder_optimizer.load_state_dict(encoder_optimizer_sd)
    decoder_optimizer.load_state_dict(decoder_optimizer_sd)</p>
<h1 id="run-training-iterations">Run training iterations</h1>
<p>print(&ldquo;Starting Training!&rdquo;)
trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,
           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,
           print_every, save_every, clip, corpus_name, loadFilename)
```</p>
<p>Run Evaluation
~~~~~~~~~~~~~~</p>
<p>To chat with your model, run the following block.</p>
<p>```python</p>
<h1 id="set-dropout-layers-to-eval-mode">Set dropout layers to eval mode</h1>
<p>encoder.eval()
decoder.eval()</p>
<h1 id="initialize-search-module">Initialize search module</h1>
<p>searcher = GreedySearchDecoder(encoder, decoder)</p>
<h1 id="begin-chatting-uncomment-and-run-the-following-line-to-begin">Begin chatting (uncomment and run the following line to begin)</h1>
<h1 id="evaluateinputencoder-decoder-searcher-voc">evaluateInput(encoder, decoder, searcher, voc)</h1>
<p>```</p>
<h2 id="conclusion">Conclusion</h2>
<p>That’s all for this one, folks. Congratulations, you now know the
fundamentals to building a generative chatbot model! If you’re
interested, you can try tailoring the chatbot’s behavior by tweaking the
model and training parameters and customizing the data that you train
the model on.</p>
<p>Check out the other tutorials for more cool deep learning applications
in PyTorch!</p>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../transfer_learning_tutorial/" title="迁移学习教程" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  后退
                </span>
                迁移学习教程
              </span>
            </div>
          </a>
        
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/application.267712eb.js"></script>
      
        
        
          
          <script src="../../assets/javascripts/lunr/lunr.stemmer.support.js"></script>
          
            
              
                <script src="../../assets/javascripts/lunr/tinyseg.js"></script>
              
              
                <script src="../../assets/javascripts/lunr/lunr.ja.js"></script>
              
            
          
          
        
      
      <script>app.initialize({version:"1.0.4",url:{base:"../.."}})</script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>