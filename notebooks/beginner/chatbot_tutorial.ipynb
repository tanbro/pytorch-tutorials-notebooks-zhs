{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 聊天机器人教程\n",
    "\n",
    "**作者：** [Matthew Inkawhich](https://github.com/MatthewInkawhich)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本教程中，我们将探索一个有趣的序列到序列(Seq2Seq)模型的用例。我们将使用 [Cornell Movie-Dialogs Corpus](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html) 的电影脚本训练一个简单的聊天机器人。\n",
    "\n",
    "对话模型是人工智能研究的热门话题。\n",
    "聊天机器人在包括客户服务应用和在线帮助台在内的各种场景都用应用。\n",
    "这些机器人通常使由基于索引的模型驱动的，它们响应特定的问题，输出预定义的响应。在像公司IT帮助台这样高度受限的领域中，这些模型可能是住够了，不过在通常的状况下，他们是不够健壮的。\n",
    "教一台机器与人类在多个领域内进行有意义的对话是一个远未解决的研究性问题。\n",
    "在最近的深度学习模型热潮中，像 [Google Neural Conversational Model](https://arxiv.org/abs/1506.05869) 这样的强大的生成模型的出现，标志着多领域生成对话模型的一大进步。\n",
    "在这个教程中，我们将用`PyTorch`实现这种模型。\n",
    "\n",
    "![bot](https://pytorch.org/tutorials/_images/bot.png)\n",
    "\n",
    "```console\n",
    "> hello?\n",
    "Bot: hello .\n",
    "> where am I?\n",
    "Bot: you re in a hospital .\n",
    "> who are you?\n",
    "Bot: i m a lawyer .\n",
    "> how are you doing?\n",
    "Bot: i m fine .\n",
    "> are you my friend?\n",
    "Bot: no .\n",
    "> you're under arrest\n",
    "Bot: i m trying to help you !\n",
    "> i'm just kidding\n",
    "Bot: i m sorry .\n",
    "> where are you from?\n",
    "Bot: san francisco .\n",
    "> it's time for me to leave\n",
    "Bot: i know .\n",
    "> goodbye\n",
    "Bot: goodbye .\n",
    "```\n",
    "\n",
    "**教程要点：**\n",
    "\n",
    "- 加载和预处理 [Cornell Movie-Dialogs Corpus](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html) 数据集\n",
    "- 使用 [Luong attention mechanism(s)](https://arxiv.org/abs/1508.04025) 实现一个序列到序列模型\n",
    "- 使用小批次联合训练编码器和解码器模型\n",
    "- 实现贪婪搜索解码模块\n",
    "- 与训练后的聊天机器人互动\n",
    "\n",
    "**致谢：**\n",
    "\n",
    "本教程借用以下来源的代码：\n",
    "\n",
    "1. Yuan-Kuei Wu 的 pytorch-chatbot 实现: <https://github.com/ywk991112/pytorch-chatbot>\n",
    "1. Sean Robertson 的 practical-pytorch seq2seq-translation 例子: <https://github.com/spro/practical-pytorch/tree/master/seq2seq-translation>\n",
    "1. FloydHub 的 Cornell Movie Corpus 预处理代码: <https://github.com/floydhub/textutil-preprocess-cornell-movie-corpus>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备工作\n",
    "\n",
    "首先，从<https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html>下载ZIP文件解压缩到当前目录的`data`子目录中。\n",
    "\n",
    "然后，我们进行一些必要的引用。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import torch\n",
    "from torch.jit import script, trace\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "from io import open\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 数据加载与预处理\n",
    "\n",
    "下一步，将我们之前下载的数据重新格式化，并把数据加载到我们所要使用的结构中。\n",
    "\n",
    "[Cornell Movie-Dialogs Corpus](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html)\n",
    "是一个内容丰富的电影角色对话数据集：\n",
    "\n",
    "- 来自10,292对电影角色的220,579个对话\n",
    "- 来自617部电影的9,035个角色\n",
    "- 总共304,713句话\n",
    "\n",
    "这个数据集庞大且多样，其语言形式、时间段、情感都有很大变化。我们希望这种多样性使我们的模型能够适应多种形式的输入和询问。\n",
    "\n",
    "首先，我们看几行数据文件，了解其原始格式。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n",
      "\n",
      "L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\n",
      "\n",
      "L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\n",
      "\n",
      "L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\n",
      "\n",
      "L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\n",
      "\n",
      "L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\n",
      "\n",
      "L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\n",
      "\n",
      "L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\n",
      "\n",
      "L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I'm kidding.  You know how sometimes you just become this \"persona\"?  And you don't know how to quit?\n",
      "\n",
      "L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus_name = \"cornell movie-dialogs corpus\"\n",
    "corpus = os.path.join(\"data\", corpus_name)\n",
    "\n",
    "def printLines(file, n=10):\n",
    "    with open(file, encoding='iso-8859-1') as datafile:\n",
    "        for i, line in enumerate(datafile):\n",
    "            if i < n:\n",
    "                print(line)\n",
    "\n",
    "printLines(os.path.join(corpus, \"movie_lines.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### 创建格式化数据文件\n",
    "\n",
    "为方便起见，我们将创建一个格式良好的数据文件，其中每一行包含一个以制表符分隔的*询问语句*和一个*响应语句*对。\n",
    "\n",
    "以下函数用于分析 *movie_lines.txt* 数据文件的原始行数据\n",
    "\n",
    "- `loadLines` 将每一行分割成具有多个字段(lineID, characterID, movieID, character, text)的字典\n",
    "- `loadConversations` 将来自 `loadLines` 的，包含多个字段的行，根据 *movie_conversations.txt* 组成对话。\n",
    "- `extractSentencePairs` 从对话中提取“询问-回答”句子对\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Splits each line of the file into a dictionary of fields\n",
    "def loadLines(fileName, fields):\n",
    "    lines = {}\n",
    "    with open(fileName, encoding='iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            values = line.split(\" +++$+++ \")\n",
    "            # Extract fields\n",
    "            lineObj = {}\n",
    "            for i, field in enumerate(fields):\n",
    "                lineObj[field] = values[i]\n",
    "            lines[lineObj['lineID']] = lineObj\n",
    "    return lines\n",
    "\n",
    "\n",
    "# Groups fields of lines from `loadLines` into conversations based on *movie_conversations.txt*\n",
    "def loadConversations(fileName, lines, fields):\n",
    "    conversations = []\n",
    "    with open(fileName, encoding='iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            values = line.split(\" +++$+++ \")\n",
    "            # Extract fields\n",
    "            convObj = {}\n",
    "            for i, field in enumerate(fields):\n",
    "                convObj[field] = values[i]\n",
    "            # Convert string to list (convObj[\"utteranceIDs\"] == \"['L598485', 'L598486', ...]\")\n",
    "            lineIds = eval(convObj[\"utteranceIDs\"])\n",
    "            # Reassemble lines\n",
    "            convObj[\"lines\"] = []\n",
    "            for lineId in lineIds:\n",
    "                convObj[\"lines\"].append(lines[lineId])\n",
    "            conversations.append(convObj)\n",
    "    return conversations\n",
    "\n",
    "\n",
    "# Extracts pairs of sentences from conversations\n",
    "def extractSentencePairs(conversations):\n",
    "    qa_pairs = []\n",
    "    for conversation in conversations:\n",
    "        # Iterate over all the lines of the conversation\n",
    "        for i in range(len(conversation[\"lines\"]) - 1):  # We ignore the last line (no answer for it)\n",
    "            inputLine = conversation[\"lines\"][i][\"text\"].strip()\n",
    "            targetLine = conversation[\"lines\"][i+1][\"text\"].strip()\n",
    "            # Filter wrong samples (if one of the lists is empty)\n",
    "            if inputLine and targetLine:\n",
    "                qa_pairs.append([inputLine, targetLine])\n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，调用这些函数，并创建文件，文件名是 *formatted_movie_lines.txt* 。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus...\n",
      "\n",
      "Loading conversations...\n",
      "\n",
      "Writing newly formatted file...\n",
      "\n",
      "Sample lines from file:\n",
      "Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\tWell, I thought we'd start with pronunciation, if that's okay with you.\n",
      "\n",
      "Well, I thought we'd start with pronunciation, if that's okay with you.\tNot the hacking and gagging and spitting part.  Please.\n",
      "\n",
      "Not the hacking and gagging and spitting part.  Please.\tOkay... then how 'bout we try out some French cuisine.  Saturday?  Night?\n",
      "\n",
      "You're asking me out.  That's so cute. What's your name again?\tForget it.\n",
      "\n",
      "No, no, it's my fault -- we didn't have a proper introduction ---\tCameron.\n",
      "\n",
      "Cameron.\tThe thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\n",
      "\n",
      "The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\tSeems like she could get a date easy enough...\n",
      "\n",
      "Why?\tUnsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\n",
      "\n",
      "Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\tThat's a shame.\n",
      "\n",
      "Gosh, if only we could find Kat a boyfriend...\tLet me see what I can do.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define path to new file\n",
    "datafile = os.path.join(corpus, \"formatted_movie_lines.txt\")\n",
    "\n",
    "delimiter = '\\t'\n",
    "# Unescape the delimiter\n",
    "delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n",
    "\n",
    "# Initialize lines dict, conversations list, and field ids\n",
    "lines = {}\n",
    "conversations = []\n",
    "MOVIE_LINES_FIELDS = [\"lineID\", \"characterID\", \"movieID\", \"character\", \"text\"]\n",
    "MOVIE_CONVERSATIONS_FIELDS = [\"character1ID\", \"character2ID\", \"movieID\", \"utteranceIDs\"]\n",
    "\n",
    "# Load lines and process conversations\n",
    "print(\"\\nProcessing corpus...\")\n",
    "lines = loadLines(os.path.join(corpus, \"movie_lines.txt\"), MOVIE_LINES_FIELDS)\n",
    "print(\"\\nLoading conversations...\")\n",
    "conversations = loadConversations(os.path.join(corpus, \"movie_conversations.txt\"),\n",
    "                                  lines, MOVIE_CONVERSATIONS_FIELDS)\n",
    "\n",
    "# Write new csv file\n",
    "print(\"\\nWriting newly formatted file...\")\n",
    "with open(datafile, 'w', encoding='utf-8') as outputfile:\n",
    "    writer = csv.writer(outputfile, delimiter=delimiter, lineterminator='\\n')\n",
    "    for pair in extractSentencePairs(conversations):\n",
    "        writer.writerow(pair)\n",
    "\n",
    "# Print a sample of lines\n",
    "print(\"\\nSample lines from file:\")\n",
    "printLines(datafile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据加载和修剪\n",
    "\n",
    "我们的下一个任务是创建词汇表并将询问/响应句子对加载到内存中。\n",
    "\n",
    "注意我们处理的是**词**序列，它们没有隐式映射到离散数值空间。因此，我们必须创建一个将我们在数据集中遇到的每个唯一词映射到索引值的映射(Mapping)。\n",
    "\n",
    "为此，我们定义一个`Voc`类，它保存从词到索引值的映射，以及从索引值到词的反向映射，唯一词的数量，总词数。\n",
    "这个类提供了像词表添加词的方法(`addWord`)，添加句子中所有词的方法(`addSentence`)，以及削减不常见词的方法(`trim`)。\n",
    "More on trimming later.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Default word tokens\n",
    "PAD_token = 0  # Used for padding short sentences\n",
    "SOS_token = 1  # Start-of-sentence token\n",
    "EOS_token = 2  # End-of-sentence token\n",
    "\n",
    "class Voc:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3  # Count SOS, EOS, PAD\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    # Remove words below a certain count threshold\n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed:\n",
    "            return\n",
    "        self.trimmed = True\n",
    "\n",
    "        keep_words = []\n",
    "\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "\n",
    "        print('keep_words {} / {} = {:.4f}'.format(\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "\n",
    "        # Reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3 # Count default tokens\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.addWord(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，可以开始装配词表和询问/回复句子对。在准备好使用这些数据之前，我们还得执行一些预处理。\n",
    "\n",
    "- 首先，我们必须使用 `unicodeToAscii` 将字符串从 Unicode 转为 ASCII 。\n",
    "- 其次，我们应该把所有字母转为小写，并且裁剪掉所有的除基本标点符号之外的所有非字母字符(`normalizeString`)。\n",
    "- 最后，为了训练更快的收敛，我们将过滤掉(`filterPairs`)长度大于 `MAX_LENGTH` 阈值的句子。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preparing training data ...\n",
      "Reading lines...\n",
      "Read 221282 sentence pairs\n",
      "Trimmed to 64217 sentence pairs\n",
      "Counting words...\n",
      "Counted words: 17996\n",
      "\n",
      "pairs:\n",
      "['there .', 'where ?']\n",
      "['you have my word . as a gentleman', 'you re sweet .']\n",
      "['hi .', 'looks like things worked out tonight huh ?']\n",
      "['you know chastity ?', 'i believe we share an art instructor']\n",
      "['have fun tonight ?', 'tons']\n",
      "['well no . . .', 'then that s all you had to say .']\n",
      "['then that s all you had to say .', 'but']\n",
      "['but', 'you always been this selfish ?']\n",
      "['do you listen to this crap ?', 'what crap ?']\n",
      "['what good stuff ?', 'the real you .']\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 10  # Maximum sentence length to consider\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# Read query/response pairs and return a voc object\n",
    "def readVocs(datafile, corpus_name):\n",
    "    print(\"Reading lines...\")\n",
    "    # Read the file and split into lines\n",
    "    lines = open(datafile, encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    voc = Voc(corpus_name)\n",
    "    return voc, pairs\n",
    "\n",
    "# Returns True if both sentences in a pair 'p' are under the MAX_LENGTH threshold\n",
    "def filterPair(p):\n",
    "    # Input sequences need to preserve the last word for EOS token\n",
    "    return all(len(s.split(' ')) < MAX_LENGTH for s in p)\n",
    "\n",
    "# Filter pairs using filterPair condition\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "# Using the functions defined above, return a populated voc object and pairs list\n",
    "def loadPrepareData(corpus, corpus_name, datafile, save_dir):\n",
    "    print(\"Start preparing training data ...\")\n",
    "    voc, pairs = readVocs(datafile, corpus_name)\n",
    "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])\n",
    "    print(\"Counted words:\", voc.num_words)\n",
    "    return voc, pairs\n",
    "\n",
    "\n",
    "# Load/Assemble voc and pairs\n",
    "save_dir = os.path.join(\"data\", \"save\")\n",
    "voc, pairs = loadPrepareData(corpus, corpus_name, datafile, save_dir)\n",
    "# Print some pairs to validate\n",
    "print(\"\\npairs:\")\n",
    "for pair in pairs[:10]:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另一种有利于在训练期间实现更快收敛的策略是修剪掉我们词汇表中很少使用的单词。减小特征空间也会缓和模型逼近的难度。我们将通过两个步骤完成此操作：\n",
    "\n",
    "1. 用`voc.trim`修剪掉数量小于`MIN_COUNT`阈值的词。\n",
    "\n",
    "1. 过滤掉含有被修剪词的句子对。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_words 7820 / 17993 = 0.4346\n",
      "Trimmed from 64217 pairs to 53120, 0.8272 of total\n"
     ]
    }
   ],
   "source": [
    "MIN_COUNT = 3    # Minimum word count threshold for trimming\n",
    "\n",
    "def trimRareWords(voc, pairs, MIN_COUNT):\n",
    "    # Trim words used under the MIN_COUNT from the voc\n",
    "    voc.trim(MIN_COUNT)\n",
    "    # Filter out pairs with trimmed words\n",
    "    keep_pairs = []\n",
    "    for pair in pairs:\n",
    "        input_sentence = pair[0]\n",
    "        output_sentence = pair[1]\n",
    "        keep_input = True\n",
    "        keep_output = True\n",
    "        # Check input sentence\n",
    "        for word in input_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_input = False\n",
    "                break\n",
    "        # Check output sentence\n",
    "        for word in output_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output = False\n",
    "                break\n",
    "\n",
    "        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "\n",
    "    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
    "    return keep_pairs\n",
    "\n",
    "\n",
    "# Trim voc and pairs\n",
    "pairs = trimRareWords(voc, pairs, MIN_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为模型准备数据\n",
    "\n",
    "尽管我们已经投入很大精力来准备和整理数据，把它们放到了漂亮的词表对象和句子对列表，但我们的模型最终需要的的输入却是Tensor的张量数字。\n",
    "可以在[Seq2Seq翻译教程](../intermediate/seq2seq_translation_tutorial)中找到为模型准备预处理数据的方法。\n",
    "在那个教程中，我们使用的批次值为1，这意味着我们所要做的就是将句子对中的单词转换为词汇表中对应的索引值，并将其提供给模型。\n",
    "\n",
    "另外，如果你对加速培训和/或想要利用GPU并行化功能感兴趣，则需要使用小批量培训。\n",
    "\n",
    "使用小批量也意味着我们必须注意批量中句子长度的变化。\n",
    "为了容纳同一批次中不同大小的句子，我们要让批量输入张量的形状 *(max_length，batch_size)* 中的短于 *max_length* 的句子在 *EOS_token* 之后用零填充。\n",
    "\n",
    "如果我们只是简单地通过将单词转换为其索引值(`indexesFromSentence`)和零填充的方法将英语句子转换为张量，张量的形状将是 *(batch_size，max_length)* ，并且在第一维上的索引将在所有时间步骤中返回完整序列。\n",
    "但是，我们需要能够沿着时间、跨批次、在所有序列上进行索引。\n",
    "因此，我们将输入批处理的形状转置为 *(max_length，batch_size)* ，以便跨第一维的索引返回批中所有句子的时间步长。\n",
    "我们在`zeroPadding`函数中隐式处理这个转置。\n",
    "\n",
    "![batches](https://pytorch.org/tutorials/_images/seq2seq_batches.png)\n",
    "\n",
    "函数`inputVar`处理句子到张量的转换过程，最终创建一个形状正确的零填充张量。\n",
    "它还返回批次中每个序列的长度(`lengths`)的张量，它稍后会被传给编码器。\n",
    "\n",
    "函数`outputVar`的执行过程与`inputVar`类似，但是不返回长度（`lenghts`）张量，而是返回二进制的掩码张量和目标句子的最大长度。\n",
    "二进制掩码与输出目标张量具有同样的形状，但是其中的每个 *PAD_token* 元素都为0，其它所有元素都为1。\n",
    "\n",
    "`batch2TrainData`简单的使用一堆句子对并使用上述函数返回输入和目标张量。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variable: tensor([[122, 443,  70,  16, 111],\n",
      "        [  7,  45, 519, 997,  66],\n",
      "        [ 26, 571,   3,   4,   2],\n",
      "        [ 36,   4,   2,   2,   0],\n",
      "        [  4,   2,   0,   0,   0],\n",
      "        [  2,   0,   0,   0,   0]])\n",
      "lengths: tensor([6, 5, 4, 4, 3])\n",
      "target_variable: tensor([[ 192,  785, 7319,   88,   95],\n",
      "        [   4,   12,    4, 2556,    4],\n",
      "        [   2,  786,    2,    4,    4],\n",
      "        [   0,    2,    0,    2,    4],\n",
      "        [   0,    0,    0,    0,    2]])\n",
      "mask: tensor([[1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 0, 0, 0, 1]], dtype=torch.uint8)\n",
      "max_target_len: 5\n"
     ]
    }
   ],
   "source": [
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "\n",
    "\n",
    "def zeroPadding(l, fillvalue=PAD_token):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
    "\n",
    "def binaryMatrix(l, value=PAD_token):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m\n",
    "\n",
    "# Returns padded input sequence tensor and lengths\n",
    "def inputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths\n",
    "\n",
    "# Returns padded target sequence tensor, padding mask, and max target length\n",
    "def outputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.ByteTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, mask, max_target_len\n",
    "\n",
    "# Returns all items for a given batch of pairs\n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len\n",
    "\n",
    "\n",
    "# Example for validation\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"input_variable:\", input_variable)\n",
    "print(\"lengths:\", lengths)\n",
    "print(\"target_variable:\", target_variable)\n",
    "print(\"mask:\", mask)\n",
    "print(\"max_target_len:\", max_target_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Seq2Seq 模型\n",
    "\n",
    "我们这个聊天机器人的大脑是序列到序列（seq2seq）模型。seq2seq 模型的目标是将可变长度序列作为输入，并使用固定大小的模型将可变长度序列作为输出返回。\n",
    "\n",
    "[Sutskever 等人](https://arxiv.org/abs/1409.3215) 发现通过使用两个独立的递归神经网络(RNN)，我们可以完成这项任务。\n",
    "\n",
    "第一个 RNN 充当**编码器**，它将可变长度输入序列编码成固定长度的上下文向量。\n",
    "理论上，这个上下文向量（RNN的最终隐藏层）将包含关于输入给机器人的询问句的语义信息。\n",
    "\n",
    "第二个 RNN 是**解码器**，它采用输入词和上下文向量，并返回序列中后续词的猜测值，以及用于下次迭代的隐藏层。\n",
    "\n",
    "![model](https://jeddy92.github.io/images/ts_intro/seq2seq_ts.png)\n",
    "\n",
    "图片来源：<https://jeddy92.github.io/JEddy92.github.io/ts_seq2seq_intro/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 编码器\n",
    "\n",
    "编码器RNN一次迭代输入句子的一个标记(token)，每个时间步骤输出一个“输出”向量和一个“隐藏状态”向量。\n",
    "然后将隐藏状态向量传递给下一个时间步骤，同时记录输出向量。\n",
    "编码器将其在序列中的每个点看到的上下文转换为高维空间中的一组点，解码器将使用这组点来为给定任务生成有意义的输出。\n",
    "\n",
    "我们这个编码器的的核心是多层门控单元(GRU)，由[Cho 等人](https://arxiv.org/pdf/1406.1078v3.pdf)于2014年发明。\n",
    "我们将使用GRU的一种变种——双向GRU，它使用两种独立的RNN：一个以正常的顺序接收输入序列，另一个以反方向接收输入序列。\n",
    "在同一时间步骤中对每个网络的输出求和。\n",
    "使用双向GRU讲给我们带来对过去和未来上下文进行编码的优势。\n",
    "\n",
    "双向RNN:\n",
    "\n",
    "![rnn_bidir](https://colah.github.io/posts/2015-09-NN-Types-FP/img/RNN-bidirectional.png)\n",
    "\n",
    "图片来源：<https://colah.github.io/posts/2015-09-NN-Types-FP/>\n",
    "\n",
    "注意，一个`embedding`层用于在任意大小的特征空间中编码我们的单词索引。\n",
    "对于我们的模型，这个层会将每个词映射到大小为*hidden_size*的特征空间。\n",
    "训练后，这些值应该编码了近义词之间的语义相似度。\n",
    "\n",
    "最有，如果要填充后的一批序列传入RNN模块，我们必须围绕RNN进行打包和解包，这些方法分别是：\n",
    "- `nn.utils.rnn.pack_padded_sequence`\n",
    "- `nn.utils.rnn.pad_packed_sequence`\n",
    "\n",
    "**计算图：**\n",
    "\n",
    "1. 将词的索引值转为嵌入\n",
    "1. 为RNN模块打包填充后的序列批次\n",
    "1. 通过GRU前向传递\n",
    "1. 解包填充\n",
    "1. 双向GRU输出求和\n",
    "1. 返回输出和最终隐藏状态\n",
    "\n",
    "**输入：**\n",
    "\n",
    "- `input_seq`: 输入句子批次；形状=*(max_length,batch_size)*\n",
    "- `input_lengths`: 由批次中每个句子的长度的所构成的列表；形状=*(batch_size)*\n",
    "- `hidden`: 隐藏状态；形状=*(n_layers x num_directions, batch_size, hidden_size)*\n",
    "\n",
    "**输出：**\n",
    "\n",
    "- `outputs`: 从GRN最终隐藏层的输出特征；形状=*(max_length, batch_size, hidden_size)*\n",
    "- `hidden`: 从GRU更新的隐藏状态；形状=*(n_layers x num_directions, batch_size, hidden_size)*\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "\n",
    "        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n",
    "        #   because our input size is a word embedding with number of features == hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
    "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
    "\n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        # Convert word indexes to embeddings\n",
    "        embedded = self.embedding(input_seq)\n",
    "        # Pack padded batch of sequences for RNN module\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        # Forward pass through GRU\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        # Unpack padding\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        # Sum bidirectional GRU outputs\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
    "        # Return output and final hidden state\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解码器\n",
    "\n",
    "解码器RNN以“一个标记接一个标记(token-by-token)”的形式生成回复句子。\n",
    "它使用编码器的上下文向量和内置隐藏状态生成序列中的后续词。\n",
    "它持续的生成词，直到输出*EOS_token*——表示句子的结束。\n",
    "寻常的Seq2Seq解码器常常遇到的一个问题就是，如果我们依赖于上下文向量来编码整个输入的语义，那么我们很可能丢失信息。\n",
    "\n",
    "在处理长输入序列的时候尤其如此，这极大的限制了我们这个解码器的能力。\n",
    "为了解决这个问题，[Bahdanau 等人](https://arxiv.org/abs/1409.0473)创建了“注意力机制”，允许解码器只关注输入序列的某些部分，而不是在每一步都使用整个固定的上下文。\n",
    "\n",
    "在上层，用解码器的当前隐藏状态和编码器的输出计算注意力。\n",
    "输出注意力权重和输入序列具有相同的形状，这让我们可以将它和编码器输出相乘，得到编码器输出中的要被加以注意力的部分的加权和。\n",
    "\n",
    "[Sean Robertson](https://github.com/spro) 的图示很好的描述了这点：\n",
    "\n",
    "![attn2](https://pytorch.org/tutorials/_images/attn2.png)\n",
    "\n",
    "[Luong 等人](https://arxiv.org/abs/1508.04025)创建了“全局注意力”来改进[Bahdanau 等人](https://arxiv.org/abs/1409.0473)的基础工作。\n",
    "“全局注意力”最关键的不同之处在于：它会考虑所有的编码器隐藏状态，而不是[Bahdanau 等人](https://arxiv.org/abs/1409.0473)的只考虑当前时间步骤中的编码器隐藏状态的“局部注意力”方式。\n",
    "另一个不同之处在于，使用“全局注意力”，我们仅仅使用当前时间步骤的编码器的隐藏状态来计算注意力的权重或能量值。\n",
    "[Bahdanau 等人](https://arxiv.org/abs/1409.0473)的注意力计算需要了解上一个时间步骤中编码器的状态。\n",
    "此外，[Luong 等人](https://arxiv.org/abs/1508.04025)提供了用于计算编码器输出和解码器输出之间的注意力的的多种方法，他们被成为“得分函数”（score functions）：\n",
    "\n",
    "![scores](https://pytorch.org/tutorials/_images/scores.png)\n",
    "\n",
    "其中，\n",
    "- $h_t$ 为当前目标解码器状的态\n",
    "- $\\bar{h}_s$ 为所有编码器的状态\n",
    "\n",
    "总体而言，全局注意力机制可以通过下图来总结。\n",
    "注意我们将在被称作`Attn`的分离的`nn.Module`中实现“注意力层”。\n",
    "这个模块的输出是一个 softmax 标准化权重张量，其形状是 *(batch_size, 1, max_length)* 。\n",
    "\n",
    "![global_attn](https://pytorch.org/tutorials/_images/global_attn.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Luong attention layer\n",
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "\n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        return torch.sum(hidden * encoder_output, dim=2)\n",
    "\n",
    "    def general_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(encoder_output)\n",
    "        return torch.sum(hidden * energy, dim=2)\n",
    "\n",
    "    def concat_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
    "        return torch.sum(self.v * energy, dim=2)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # Calculate the attention weights (energies) based on the given method\n",
    "        if self.method == 'general':\n",
    "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'concat':\n",
    "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'dot':\n",
    "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "\n",
    "        # Transpose max_length and batch_size dimensions\n",
    "        attn_energies = attn_energies.t()\n",
    "\n",
    "        # Return the softmax normalized probability scores (with added dimension)\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们已经定义了注意力子模块，可以实现实际的解码器模块了。\n",
    "对于解码器，我们将手动的在每个时间步骤中提供批数据。\n",
    "这意味着我们的嵌入词张量和GRU输出的形状都是 *(1, batch_size, hidden_size)* 。\n",
    "\n",
    "\n",
    "**计算图：**\n",
    "\n",
    "1. 获得当前输入词的强如嵌入。\n",
    "1. 单向GRU前向。\n",
    "1. 有第二步的GRU输出计算注意力权重。\n",
    "1. 注意力权重与编码器输出相乘，得到“加权和”(weighted sum)上下文向量。\n",
    "1. 使用 Luong 等人的方法将加权上下文向量和GRU输出相加。\n",
    "1. 使用 Luong 等人的方法(不用 softmax)预测后续词。\n",
    "1. 返回输出和最终隐藏层。\n",
    "\n",
    "**输入：**\n",
    "\n",
    "- `input_step`: 输入序列批的一个时间步骤 (一个词)；形状=*(1, batch_size)*\n",
    "- `last_hidden`:  GRU的最终隐藏层；形状=(n_layers x num_directions, batch_size, hidden_size)*\n",
    "- `encoder_outputs`: 编码器的模型输出; 性转=*(max_length, batch_size, hidden_size)*\n",
    "\n",
    "**输出：**\n",
    "\n",
    "- `输出`: softmax 正规化张量，给出了被解码序列中每个词是正确的后续词的概率; 形状=*(batch_size, voc.num_words)*\n",
    "- `hidden`: GRU的最终隐藏状态; 形状=*(n_layers x num_directions, batch_size, hidden_size)*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # Keep for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Define layers\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step (word) at a time\n",
    "        # Get embedding of current input word\n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        # Forward through unidirectional GRU\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        # Calculate attention weights from the current GRU output\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "        # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "        # Predict next word using Luong eq. 6\n",
    "        output = self.out(concat_output)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        # Return output and final hidden state\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义训练过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失掩码\n",
    "\n",
    "由于我们处理的是批量填充序列，因此在计算损失时我们不能简单地仅考虑张量的全部元素。\n",
    "而是通过定义`maskNLLLoss`损失函数，基于解码器输出张量，目标张量和描述目标张量填充的二进制掩码张量，来计算损失。\n",
    "该损失函数计算了对应于掩码向量中*1*的元素的负对数相似度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def maskNLLLoss(inp, target, mask):\n",
    "    nTotal = mask.sum()\n",
    "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
    "    loss = crossEntropy.masked_select(mask).mean()\n",
    "    loss = loss.to(device)\n",
    "    return loss, nTotal.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单次训练的迭代\n",
    "\n",
    "函数 ``train`` 包含一个单次训练迭代（单个输入批次）算法。\n",
    "\n",
    "我们用一些巧妙的技巧来促进收敛：\n",
    "\n",
    "- 第一个技巧是使用 **tacher forcing**。\n",
    "  这意味着某些情况下，通过设置`teacher_forcing_ratio`，我们使用当前目标词，而不是使用解码器的当前猜测结果，作为解码器的后续输入。\n",
    "  这项技术是训练解码器的轮子，有助于更有效的训练。\n",
    "  \"tacher forcing\" 会导致模型在推理期间不稳定，这是因为解码器在训练中没有足够的机会真正的制作它自己的输出序列。\n",
    "  所有，我们必须注意地如何设置`teacher_forcing_ratio`，不要被快速收敛欺骗。\n",
    "\n",
    "- 我们要实现的第二个技巧是**梯度剪切**。\n",
    "  这是一种用于对抗“梯度爆炸”的常用技术。\n",
    "  本质上，通过剪切或者最大阈值，我们防止梯度爆炸性增长和溢出(NaN)，或者在成本函数中从悬崖跌落。\n",
    "\n",
    "![grad_clip](https://pytorch.org/tutorials/_images/grad_clip.png)\n",
    "\n",
    "图像来源: [Goodfellow 等人 *Deep Learning*. 2016.](https://www.deeplearningbook.org/)\n",
    "\n",
    "**运算顺序：**\n",
    "\n",
    "1. 通过编码器向前传递整个输入批次。\n",
    "1. 将解码器输入初始化为`SOS_token`和编码器最终隐藏层的隐藏状态。\n",
    "1. 在每个时间步骤中，通过解码器向前传递输入批的序列。\n",
    "1. 如果用到了 \"tacher forcing\"：把下一个解码器输入作为当前目标；其它：用下一个解码器输入作为当前解码器输出。\n",
    "1. 计算和累积损失。\n",
    "1. 进行反向传播\n",
    "1. 剪切梯度。\n",
    "1. 更新编码器和解码器模型的参数。\n",
    "\n",
    "\n",
    "!!! note \"注意\"\n",
    "\n",
    "    只需将 PyTorch RNN 模块(`RNN`, `LSTM`, `GRU`)的整个输入序列（或批次的序列）传入，它们就可以被用于任何其它类似的非递归层。\n",
    "    我们在`encoder`中这样使用`GUR`层。\n",
    "    实际情况是，在底层，每一个时间步骤上都有一个交互过程迭代计算隐藏状态。\n",
    "  \n",
    "    另外，也可以每个时间步骤运行这些模型。\n",
    "    在这种情况下，我们在训练过程里手动循环遍历序列，就像对`decoder`模型做的那样。\n",
    "    只要维护好这些模块正确的概念模型，实现序列模型就可以非常简单。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
    "          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n",
    "\n",
    "    # Zero gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # Set device options\n",
    "    input_variable = input_variable.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    # Initialize variables\n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "\n",
    "    # Forward pass through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "\n",
    "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
    "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "\n",
    "    # Set initial decoder hidden state to the encoder's final hidden state\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "\n",
    "    # Determine if we are using teacher forcing this iteration\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    # Forward batch of sequences through decoder one time step at a time\n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # Teacher forcing: next input is current target\n",
    "            decoder_input = target_variable[t].view(1, -1)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # No teacher forcing: next input is decoder's own current output\n",
    "            _, topi = decoder_output.topk(1)\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "\n",
    "    # Perform backpropatation\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradients: gradients are modified in place\n",
    "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "\n",
    "    # Adjust model weights\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return sum(print_losses) / n_totals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多次训练的迭代器\n",
    "\n",
    "现在是时候把完整和的训练过程和数据结合在一起了。\n",
    "函数`trainIters`负责运行把模型、优化器、数据等传递给`n_iterations`并运行。\n",
    "这个函数很容易解释的，因为我们已经对`train`函数做了繁多的工作。\n",
    "\n",
    "有一个要注意的事情：当我们保存模型时，所有的编码器和解码器状态字典(参数)、优化器的状态字典、损失、迭代器、等等，都被保存在一个tarball中。\n",
    "被这样保存的模型可以为我们提供了具有最大灵活性的检查点。\n",
    "从检查点加载模型之后，我们可以使用模型参数进行预测，或者从上次对出的地方继续训练。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):\n",
    "\n",
    "    # Load batches for each iteration\n",
    "    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
    "                      for _ in range(n_iteration)]\n",
    "\n",
    "    # Initializations\n",
    "    print('Initializing ...')\n",
    "    start_iteration = 1\n",
    "    print_loss = 0\n",
    "    if loadFilename:\n",
    "        start_iteration = checkpoint['iteration'] + 1\n",
    "\n",
    "    # Training loop\n",
    "    print(\"Training...\")\n",
    "    for iteration in range(start_iteration, n_iteration + 1):\n",
    "        training_batch = training_batches[iteration - 1]\n",
    "        # Extract fields from batch\n",
    "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
    "\n",
    "        # Run a training iteration with batch\n",
    "        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
    "                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
    "        print_loss += loss\n",
    "\n",
    "        # Print progress\n",
    "        if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "            print_loss = 0\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (iteration % save_every == 0):\n",
    "            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torch.save({\n",
    "                'iteration': iteration,\n",
    "                'en': encoder.state_dict(),\n",
    "                'de': decoder.state_dict(),\n",
    "                'en_opt': encoder_optimizer.state_dict(),\n",
    "                'de_opt': decoder_optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                'voc_dict': voc.__dict__,\n",
    "                'embedding': embedding.state_dict()\n",
    "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义评估过程\n",
    "\n",
    "在训练模型后，我们要与机器人交谈。\n",
    "首先，我们必须定义模型如何对输入进行编解码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy decoding\n",
    "\n",
    "\"Greedy decoding\" 是在训练过程中**不**使用 \"tacher forcing\" 的情况下使用的一种解码方式。\n",
    "换而言之，在每个时间步骤，我们只需从`decoder_output`选定softmax值最高的词。\n",
    "这个解码方式在单时间步骤级别上是最佳的。\n",
    "\n",
    "为了方便地使用 \"Greedy decoding\"，我们定义一个`GreedySearchDecoder`类。\n",
    "在运行时，这个类的对象采用的参数是：\n",
    "\n",
    "- 形状为 *(input_seq length, 1)* 的输入序列(`input_seq`)\n",
    "- 标量输入长度(`input_length`) tensor\n",
    "- 答复句子长度限制值 `max_length`\n",
    "\n",
    "使用以下计算图对输入句子进行评估输入：\n",
    "\n",
    "**计算图：**\n",
    "\n",
    "1. 通过编码器模型转发输入。\n",
    "1. 将编码器的最终隐藏层用作解码器的第一个隐藏输入。\n",
    "1. 将解码器的第一个输入初始化为`SOS_token`\n",
    "1. 初始化张量，在其末尾附加附加解码后的词\n",
    "1. 一次迭代解码一个词的标记(token)：\n",
    "    1. 通过解码器前向传播。\n",
    "    1. 获得可能性最大词的token和softmax分值(score)。\n",
    "    1. 记录token和score\n",
    "    1. 将当前token用作下一个解码器的输入\n",
    "1. 返回收集到的词的标记(token)和softmax分值(score)列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_seq, input_length, max_length):\n",
    "        # Forward input through encoder model\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        # Initialize decoder input with SOS_token\n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
    "        # Initialize tensors to append decoded words to\n",
    "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=device)\n",
    "        # Iteratively decode one word token at a time\n",
    "        for _ in range(max_length):\n",
    "            # Forward pass through decoder\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # Obtain most likely word token and its softmax score\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
    "            # Record token and score\n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            # Prepare current token to be next decoder input (add a dimension)\n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "        # Return collections of word tokens and scores\n",
    "        return all_tokens, all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估用户输入文本\n",
    "\n",
    "现在我们已经定义了解码方法，可以编写对输入句子文本进行评估的函数。\n",
    "函数`evaluate`用于管理处理输入句子的底层过程。\n",
    "\n",
    "首先将句子格式化为 *batch_size==1* 的词索引值输入批。\n",
    "要实现这一点，需要将句子中的词转为他们对应的索引值，并调换坐标轴以生成我们模型所需的张量。\n",
    "还要创建一个`lengths`张量，用于记录输入句子的长度。\n",
    "此时，`lengths`是一个标量，因为我们一次只评估一个句子(*batch_size==1*)。\n",
    "\n",
    "然后，通过`GreedySearchDecoder`对象(`searcher`)，我们可以获得解码后的回复句的张量。\n",
    "\n",
    "最后，将回复的索引值转为词，并返回解码出来的词列表。\n",
    "\n",
    "``evaluateInput`` acts as the user interface for our chatbot. \n",
    "`evaluateInput`充当聊天机器人用户界面。\n",
    "调用它的时候，提供一个文本输入界面，我们在这里输入自己的询问句。\n",
    "按*回车*完成后，用和处理训练数据一致的方法对输入文本进行正规化处理，传递给`evaluate`函数，获得解码后的输出句子。\n",
    "循环执行这个过程，这样就可以和机器人不停地聊天。输入“q”或者\"quit\"退出。\n",
    "\n",
    "最后，如果句子中含有词表中不存在的词，应该进行优雅的错误处理：输出错误提示信息，提醒用户输入其它词。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n",
    "    ### Format input sentence as a batch\n",
    "    # words -> indexes\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
    "    # Create lengths tensor\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    # Transpose dimensions of batch to match models' expectations\n",
    "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "    # Use appropriate device\n",
    "    input_batch = input_batch.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    # Decode sentence with searcher\n",
    "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
    "    # indexes -> words\n",
    "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words\n",
    "\n",
    "\n",
    "def evaluateInput(encoder, decoder, searcher, voc):\n",
    "    input_sentence = ''\n",
    "    while(1):\n",
    "        try:\n",
    "            # Get input sentence\n",
    "            input_sentence = input('> ')\n",
    "            # Check if it is quit case\n",
    "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "            # Normalize sentence\n",
    "            input_sentence = normalizeString(input_sentence)\n",
    "            # Evaluate sentence\n",
    "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "            # Format and print response sentence\n",
    "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "            print('Bot:', ' '.join(output_words))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Error: Encountered unknown word.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 运行模型\n",
    "\n",
    "最后，是时候运行我们的模型了！\n",
    "\n",
    "不管训练还是测试，我们都得初始化独立的编码器和解码器模型。\n",
    "在下面的代码块中，我们设置了所需配置，选择从头开始或者从检查点加载并构建和初始化模型。\n",
    "可以自由地使用不同的模型设置来优化性能。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building encoder and decoder ...\n",
      "Models built and ready to go!\n"
     ]
    }
   ],
   "source": [
    "# Configure models\n",
    "model_name = 'cb_model'\n",
    "attn_model = 'dot'\n",
    "#attn_model = 'general'\n",
    "#attn_model = 'concat'\n",
    "hidden_size = 500\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 64\n",
    "\n",
    "# Set checkpoint to load from; set to None if starting from scratch\n",
    "loadFilename = None\n",
    "checkpoint_iter = 4000\n",
    "#loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
    "#                            '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
    "#                            '{}_checkpoint.tar'.format(checkpoint_iter))\n",
    "\n",
    "\n",
    "# Load model if a loadFilename is provided\n",
    "if loadFilename:\n",
    "    # If loading on same machine the model was trained on\n",
    "    checkpoint = torch.load(loadFilename)\n",
    "    # If loading a model trained on GPU to CPU\n",
    "    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
    "    encoder_sd = checkpoint['en']\n",
    "    decoder_sd = checkpoint['de']\n",
    "    encoder_optimizer_sd = checkpoint['en_opt']\n",
    "    decoder_optimizer_sd = checkpoint['de_opt']\n",
    "    embedding_sd = checkpoint['embedding']\n",
    "    voc.__dict__ = checkpoint['voc_dict']\n",
    "\n",
    "\n",
    "print('Building encoder and decoder ...')\n",
    "# Initialize word embeddings\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "if loadFilename:\n",
    "    embedding.load_state_dict(embedding_sd)\n",
    "# Initialize encoder & decoder models\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "if loadFilename:\n",
    "    encoder.load_state_dict(encoder_sd)\n",
    "    decoder.load_state_dict(decoder_sd)\n",
    "# Use appropriate device\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "print('Models built and ready to go!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 运行训练\n",
    "\n",
    "运行以下代码块训练模型。\n",
    "\n",
    "- 首先是设置训练参数\n",
    "- 然后初始化优化器(optimizer)\n",
    "- 最后调用`trainIters`函数运行训练迭代器。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimizers ...\n",
      "Starting Training!\n",
      "Initializing ...\n",
      "Training...\n",
      "Iteration: 1; Percent complete: 0.0%; Average loss: 8.9628\n",
      "Iteration: 2; Percent complete: 0.1%; Average loss: 8.8343\n",
      "Iteration: 3; Percent complete: 0.1%; Average loss: 8.6592\n",
      "Iteration: 4; Percent complete: 0.1%; Average loss: 8.3297\n",
      "Iteration: 5; Percent complete: 0.1%; Average loss: 7.9770\n",
      "Iteration: 6; Percent complete: 0.1%; Average loss: 7.3291\n",
      "Iteration: 7; Percent complete: 0.2%; Average loss: 6.7586\n",
      "Iteration: 8; Percent complete: 0.2%; Average loss: 6.9260\n",
      "Iteration: 9; Percent complete: 0.2%; Average loss: 6.8659\n",
      "Iteration: 10; Percent complete: 0.2%; Average loss: 6.6029\n",
      "Iteration: 11; Percent complete: 0.3%; Average loss: 6.2245\n",
      "Iteration: 12; Percent complete: 0.3%; Average loss: 6.1180\n",
      "Iteration: 13; Percent complete: 0.3%; Average loss: 5.6463\n",
      "Iteration: 14; Percent complete: 0.4%; Average loss: 5.6409\n",
      "Iteration: 15; Percent complete: 0.4%; Average loss: 5.4941\n",
      "Iteration: 16; Percent complete: 0.4%; Average loss: 5.6748\n",
      "Iteration: 17; Percent complete: 0.4%; Average loss: 5.3386\n",
      "Iteration: 18; Percent complete: 0.4%; Average loss: 5.3936\n",
      "Iteration: 19; Percent complete: 0.5%; Average loss: 4.8958\n",
      "Iteration: 20; Percent complete: 0.5%; Average loss: 4.9486\n",
      "Iteration: 21; Percent complete: 0.5%; Average loss: 4.8804\n",
      "Iteration: 22; Percent complete: 0.5%; Average loss: 4.8959\n",
      "Iteration: 23; Percent complete: 0.6%; Average loss: 4.8363\n",
      "Iteration: 24; Percent complete: 0.6%; Average loss: 4.9209\n",
      "Iteration: 25; Percent complete: 0.6%; Average loss: 4.9964\n",
      "Iteration: 26; Percent complete: 0.7%; Average loss: 4.8157\n",
      "Iteration: 27; Percent complete: 0.7%; Average loss: 4.8140\n",
      "Iteration: 28; Percent complete: 0.7%; Average loss: 4.9719\n",
      "Iteration: 29; Percent complete: 0.7%; Average loss: 4.6794\n",
      "Iteration: 30; Percent complete: 0.8%; Average loss: 4.7190\n",
      "Iteration: 31; Percent complete: 0.8%; Average loss: 4.6346\n",
      "Iteration: 32; Percent complete: 0.8%; Average loss: 4.9546\n",
      "Iteration: 33; Percent complete: 0.8%; Average loss: 4.7239\n",
      "Iteration: 34; Percent complete: 0.9%; Average loss: 4.8934\n",
      "Iteration: 35; Percent complete: 0.9%; Average loss: 4.9053\n",
      "Iteration: 36; Percent complete: 0.9%; Average loss: 4.8707\n",
      "Iteration: 37; Percent complete: 0.9%; Average loss: 4.7875\n",
      "Iteration: 38; Percent complete: 0.9%; Average loss: 4.6638\n",
      "Iteration: 39; Percent complete: 1.0%; Average loss: 4.8682\n",
      "Iteration: 40; Percent complete: 1.0%; Average loss: 4.5905\n",
      "Iteration: 41; Percent complete: 1.0%; Average loss: 4.5374\n",
      "Iteration: 42; Percent complete: 1.1%; Average loss: 4.6670\n",
      "Iteration: 43; Percent complete: 1.1%; Average loss: 4.8148\n",
      "Iteration: 44; Percent complete: 1.1%; Average loss: 4.6093\n",
      "Iteration: 45; Percent complete: 1.1%; Average loss: 4.6322\n",
      "Iteration: 46; Percent complete: 1.1%; Average loss: 4.5139\n",
      "Iteration: 47; Percent complete: 1.2%; Average loss: 4.6834\n",
      "Iteration: 48; Percent complete: 1.2%; Average loss: 4.5035\n",
      "Iteration: 49; Percent complete: 1.2%; Average loss: 4.8119\n",
      "Iteration: 50; Percent complete: 1.2%; Average loss: 4.5661\n",
      "Iteration: 51; Percent complete: 1.3%; Average loss: 4.8288\n",
      "Iteration: 52; Percent complete: 1.3%; Average loss: 4.5483\n",
      "Iteration: 53; Percent complete: 1.3%; Average loss: 4.6328\n",
      "Iteration: 54; Percent complete: 1.4%; Average loss: 4.5040\n",
      "Iteration: 55; Percent complete: 1.4%; Average loss: 4.6982\n",
      "Iteration: 56; Percent complete: 1.4%; Average loss: 4.5518\n",
      "Iteration: 57; Percent complete: 1.4%; Average loss: 4.5344\n",
      "Iteration: 58; Percent complete: 1.5%; Average loss: 4.5677\n",
      "Iteration: 59; Percent complete: 1.5%; Average loss: 4.7938\n",
      "Iteration: 60; Percent complete: 1.5%; Average loss: 4.5126\n",
      "Iteration: 61; Percent complete: 1.5%; Average loss: 4.4967\n",
      "Iteration: 62; Percent complete: 1.6%; Average loss: 4.6333\n",
      "Iteration: 63; Percent complete: 1.6%; Average loss: 4.5888\n",
      "Iteration: 64; Percent complete: 1.6%; Average loss: 4.3075\n",
      "Iteration: 65; Percent complete: 1.6%; Average loss: 4.5133\n",
      "Iteration: 66; Percent complete: 1.7%; Average loss: 4.5084\n",
      "Iteration: 67; Percent complete: 1.7%; Average loss: 4.8161\n",
      "Iteration: 68; Percent complete: 1.7%; Average loss: 4.5948\n",
      "Iteration: 69; Percent complete: 1.7%; Average loss: 4.6278\n",
      "Iteration: 70; Percent complete: 1.8%; Average loss: 4.4582\n",
      "Iteration: 71; Percent complete: 1.8%; Average loss: 4.4484\n",
      "Iteration: 72; Percent complete: 1.8%; Average loss: 4.4757\n",
      "Iteration: 73; Percent complete: 1.8%; Average loss: 4.5937\n",
      "Iteration: 74; Percent complete: 1.8%; Average loss: 4.3474\n",
      "Iteration: 75; Percent complete: 1.9%; Average loss: 4.4921\n",
      "Iteration: 76; Percent complete: 1.9%; Average loss: 4.6886\n",
      "Iteration: 77; Percent complete: 1.9%; Average loss: 4.3638\n",
      "Iteration: 78; Percent complete: 1.9%; Average loss: 4.6839\n",
      "Iteration: 79; Percent complete: 2.0%; Average loss: 4.4069\n",
      "Iteration: 80; Percent complete: 2.0%; Average loss: 4.4496\n",
      "Iteration: 81; Percent complete: 2.0%; Average loss: 4.5592\n",
      "Iteration: 82; Percent complete: 2.1%; Average loss: 4.7000\n",
      "Iteration: 83; Percent complete: 2.1%; Average loss: 4.3022\n",
      "Iteration: 84; Percent complete: 2.1%; Average loss: 4.5013\n",
      "Iteration: 85; Percent complete: 2.1%; Average loss: 4.3784\n",
      "Iteration: 86; Percent complete: 2.1%; Average loss: 4.5025\n",
      "Iteration: 87; Percent complete: 2.2%; Average loss: 4.5840\n",
      "Iteration: 88; Percent complete: 2.2%; Average loss: 4.4873\n",
      "Iteration: 89; Percent complete: 2.2%; Average loss: 4.2982\n",
      "Iteration: 90; Percent complete: 2.2%; Average loss: 4.3686\n",
      "Iteration: 91; Percent complete: 2.3%; Average loss: 4.3155\n",
      "Iteration: 92; Percent complete: 2.3%; Average loss: 4.2115\n",
      "Iteration: 93; Percent complete: 2.3%; Average loss: 4.2979\n",
      "Iteration: 94; Percent complete: 2.4%; Average loss: 4.3565\n",
      "Iteration: 95; Percent complete: 2.4%; Average loss: 4.3283\n",
      "Iteration: 96; Percent complete: 2.4%; Average loss: 4.4177\n",
      "Iteration: 97; Percent complete: 2.4%; Average loss: 4.3689\n",
      "Iteration: 98; Percent complete: 2.5%; Average loss: 4.4567\n",
      "Iteration: 99; Percent complete: 2.5%; Average loss: 4.3242\n",
      "Iteration: 100; Percent complete: 2.5%; Average loss: 4.4249\n",
      "Iteration: 101; Percent complete: 2.5%; Average loss: 4.1899\n",
      "Iteration: 102; Percent complete: 2.5%; Average loss: 4.5148\n",
      "Iteration: 103; Percent complete: 2.6%; Average loss: 4.2772\n",
      "Iteration: 104; Percent complete: 2.6%; Average loss: 4.2775\n",
      "Iteration: 105; Percent complete: 2.6%; Average loss: 4.5088\n",
      "Iteration: 106; Percent complete: 2.6%; Average loss: 4.5121\n",
      "Iteration: 107; Percent complete: 2.7%; Average loss: 4.3327\n",
      "Iteration: 108; Percent complete: 2.7%; Average loss: 4.5252\n",
      "Iteration: 109; Percent complete: 2.7%; Average loss: 4.1831\n",
      "Iteration: 110; Percent complete: 2.8%; Average loss: 4.1833\n",
      "Iteration: 111; Percent complete: 2.8%; Average loss: 4.3274\n",
      "Iteration: 112; Percent complete: 2.8%; Average loss: 4.5191\n",
      "Iteration: 113; Percent complete: 2.8%; Average loss: 4.3452\n",
      "Iteration: 114; Percent complete: 2.9%; Average loss: 4.4353\n",
      "Iteration: 115; Percent complete: 2.9%; Average loss: 4.3186\n",
      "Iteration: 116; Percent complete: 2.9%; Average loss: 4.3743\n",
      "Iteration: 117; Percent complete: 2.9%; Average loss: 4.3036\n",
      "Iteration: 118; Percent complete: 2.9%; Average loss: 4.4618\n",
      "Iteration: 119; Percent complete: 3.0%; Average loss: 4.4117\n",
      "Iteration: 120; Percent complete: 3.0%; Average loss: 4.1575\n",
      "Iteration: 121; Percent complete: 3.0%; Average loss: 4.3188\n",
      "Iteration: 122; Percent complete: 3.0%; Average loss: 4.4365\n",
      "Iteration: 123; Percent complete: 3.1%; Average loss: 4.1238\n",
      "Iteration: 124; Percent complete: 3.1%; Average loss: 4.3645\n",
      "Iteration: 125; Percent complete: 3.1%; Average loss: 4.2155\n",
      "Iteration: 126; Percent complete: 3.1%; Average loss: 4.7236\n",
      "Iteration: 127; Percent complete: 3.2%; Average loss: 4.1829\n",
      "Iteration: 128; Percent complete: 3.2%; Average loss: 4.2557\n",
      "Iteration: 129; Percent complete: 3.2%; Average loss: 4.4819\n",
      "Iteration: 130; Percent complete: 3.2%; Average loss: 4.4005\n",
      "Iteration: 131; Percent complete: 3.3%; Average loss: 4.2772\n",
      "Iteration: 132; Percent complete: 3.3%; Average loss: 4.2948\n",
      "Iteration: 133; Percent complete: 3.3%; Average loss: 4.2153\n",
      "Iteration: 134; Percent complete: 3.4%; Average loss: 4.3869\n",
      "Iteration: 135; Percent complete: 3.4%; Average loss: 4.3561\n",
      "Iteration: 136; Percent complete: 3.4%; Average loss: 4.2666\n",
      "Iteration: 137; Percent complete: 3.4%; Average loss: 4.2705\n",
      "Iteration: 138; Percent complete: 3.5%; Average loss: 4.3425\n",
      "Iteration: 139; Percent complete: 3.5%; Average loss: 4.3308\n",
      "Iteration: 140; Percent complete: 3.5%; Average loss: 4.2482\n",
      "Iteration: 141; Percent complete: 3.5%; Average loss: 4.2002\n",
      "Iteration: 142; Percent complete: 3.5%; Average loss: 4.0395\n",
      "Iteration: 143; Percent complete: 3.6%; Average loss: 4.4818\n",
      "Iteration: 144; Percent complete: 3.6%; Average loss: 4.0831\n",
      "Iteration: 145; Percent complete: 3.6%; Average loss: 4.1008\n",
      "Iteration: 146; Percent complete: 3.6%; Average loss: 4.2408\n",
      "Iteration: 147; Percent complete: 3.7%; Average loss: 4.1107\n",
      "Iteration: 148; Percent complete: 3.7%; Average loss: 4.3374\n",
      "Iteration: 149; Percent complete: 3.7%; Average loss: 4.0637\n",
      "Iteration: 150; Percent complete: 3.8%; Average loss: 4.2662\n",
      "Iteration: 151; Percent complete: 3.8%; Average loss: 4.2423\n",
      "Iteration: 152; Percent complete: 3.8%; Average loss: 4.1396\n",
      "Iteration: 153; Percent complete: 3.8%; Average loss: 4.2338\n",
      "Iteration: 154; Percent complete: 3.9%; Average loss: 4.1130\n",
      "Iteration: 155; Percent complete: 3.9%; Average loss: 4.2585\n",
      "Iteration: 156; Percent complete: 3.9%; Average loss: 4.2221\n",
      "Iteration: 157; Percent complete: 3.9%; Average loss: 4.1251\n",
      "Iteration: 158; Percent complete: 4.0%; Average loss: 4.2255\n",
      "Iteration: 159; Percent complete: 4.0%; Average loss: 4.3224\n",
      "Iteration: 160; Percent complete: 4.0%; Average loss: 4.0658\n",
      "Iteration: 161; Percent complete: 4.0%; Average loss: 4.2790\n",
      "Iteration: 162; Percent complete: 4.0%; Average loss: 4.1332\n",
      "Iteration: 163; Percent complete: 4.1%; Average loss: 3.9183\n",
      "Iteration: 164; Percent complete: 4.1%; Average loss: 4.0841\n",
      "Iteration: 165; Percent complete: 4.1%; Average loss: 3.7811\n",
      "Iteration: 166; Percent complete: 4.2%; Average loss: 4.2144\n",
      "Iteration: 167; Percent complete: 4.2%; Average loss: 3.9774\n",
      "Iteration: 168; Percent complete: 4.2%; Average loss: 4.1725\n",
      "Iteration: 169; Percent complete: 4.2%; Average loss: 4.2217\n",
      "Iteration: 170; Percent complete: 4.2%; Average loss: 4.2590\n",
      "Iteration: 171; Percent complete: 4.3%; Average loss: 4.2249\n",
      "Iteration: 172; Percent complete: 4.3%; Average loss: 4.1298\n",
      "Iteration: 173; Percent complete: 4.3%; Average loss: 4.2693\n",
      "Iteration: 174; Percent complete: 4.3%; Average loss: 4.0924\n",
      "Iteration: 175; Percent complete: 4.4%; Average loss: 3.8366\n",
      "Iteration: 176; Percent complete: 4.4%; Average loss: 4.0131\n",
      "Iteration: 177; Percent complete: 4.4%; Average loss: 4.0707\n",
      "Iteration: 178; Percent complete: 4.5%; Average loss: 4.3873\n",
      "Iteration: 179; Percent complete: 4.5%; Average loss: 3.9353\n",
      "Iteration: 180; Percent complete: 4.5%; Average loss: 4.1841\n",
      "Iteration: 181; Percent complete: 4.5%; Average loss: 3.9691\n",
      "Iteration: 182; Percent complete: 4.5%; Average loss: 4.2445\n",
      "Iteration: 183; Percent complete: 4.6%; Average loss: 3.9909\n",
      "Iteration: 184; Percent complete: 4.6%; Average loss: 4.2100\n",
      "Iteration: 185; Percent complete: 4.6%; Average loss: 4.0717\n",
      "Iteration: 186; Percent complete: 4.7%; Average loss: 4.1351\n",
      "Iteration: 187; Percent complete: 4.7%; Average loss: 3.9354\n",
      "Iteration: 188; Percent complete: 4.7%; Average loss: 3.8134\n",
      "Iteration: 189; Percent complete: 4.7%; Average loss: 4.3966\n",
      "Iteration: 190; Percent complete: 4.8%; Average loss: 4.0509\n",
      "Iteration: 191; Percent complete: 4.8%; Average loss: 3.9912\n",
      "Iteration: 192; Percent complete: 4.8%; Average loss: 3.9772\n",
      "Iteration: 193; Percent complete: 4.8%; Average loss: 3.9212\n",
      "Iteration: 194; Percent complete: 4.9%; Average loss: 4.0303\n",
      "Iteration: 195; Percent complete: 4.9%; Average loss: 4.1305\n",
      "Iteration: 196; Percent complete: 4.9%; Average loss: 4.3996\n",
      "Iteration: 197; Percent complete: 4.9%; Average loss: 4.3042\n",
      "Iteration: 198; Percent complete: 5.0%; Average loss: 4.3489\n",
      "Iteration: 199; Percent complete: 5.0%; Average loss: 4.2896\n",
      "Iteration: 200; Percent complete: 5.0%; Average loss: 3.8091\n",
      "Iteration: 201; Percent complete: 5.0%; Average loss: 4.0971\n",
      "Iteration: 202; Percent complete: 5.1%; Average loss: 3.9714\n",
      "Iteration: 203; Percent complete: 5.1%; Average loss: 4.0337\n",
      "Iteration: 204; Percent complete: 5.1%; Average loss: 4.1092\n",
      "Iteration: 205; Percent complete: 5.1%; Average loss: 4.0293\n",
      "Iteration: 206; Percent complete: 5.1%; Average loss: 4.2051\n",
      "Iteration: 207; Percent complete: 5.2%; Average loss: 4.1471\n",
      "Iteration: 208; Percent complete: 5.2%; Average loss: 4.2239\n",
      "Iteration: 209; Percent complete: 5.2%; Average loss: 3.8455\n",
      "Iteration: 210; Percent complete: 5.2%; Average loss: 3.9024\n",
      "Iteration: 211; Percent complete: 5.3%; Average loss: 4.2336\n",
      "Iteration: 212; Percent complete: 5.3%; Average loss: 4.0724\n",
      "Iteration: 213; Percent complete: 5.3%; Average loss: 4.0936\n",
      "Iteration: 214; Percent complete: 5.3%; Average loss: 3.9975\n",
      "Iteration: 215; Percent complete: 5.4%; Average loss: 3.9113\n",
      "Iteration: 216; Percent complete: 5.4%; Average loss: 4.0042\n",
      "Iteration: 217; Percent complete: 5.4%; Average loss: 4.0473\n",
      "Iteration: 218; Percent complete: 5.5%; Average loss: 3.9720\n",
      "Iteration: 219; Percent complete: 5.5%; Average loss: 3.8636\n",
      "Iteration: 220; Percent complete: 5.5%; Average loss: 3.7938\n",
      "Iteration: 221; Percent complete: 5.5%; Average loss: 3.9970\n",
      "Iteration: 222; Percent complete: 5.5%; Average loss: 3.9214\n",
      "Iteration: 223; Percent complete: 5.6%; Average loss: 3.9747\n",
      "Iteration: 224; Percent complete: 5.6%; Average loss: 4.4310\n",
      "Iteration: 225; Percent complete: 5.6%; Average loss: 4.2264\n",
      "Iteration: 226; Percent complete: 5.7%; Average loss: 4.1461\n",
      "Iteration: 227; Percent complete: 5.7%; Average loss: 3.8592\n",
      "Iteration: 228; Percent complete: 5.7%; Average loss: 3.8012\n",
      "Iteration: 229; Percent complete: 5.7%; Average loss: 4.0243\n",
      "Iteration: 230; Percent complete: 5.8%; Average loss: 4.1253\n",
      "Iteration: 231; Percent complete: 5.8%; Average loss: 4.0399\n",
      "Iteration: 232; Percent complete: 5.8%; Average loss: 3.8528\n",
      "Iteration: 233; Percent complete: 5.8%; Average loss: 4.2015\n",
      "Iteration: 234; Percent complete: 5.9%; Average loss: 3.8354\n",
      "Iteration: 235; Percent complete: 5.9%; Average loss: 4.0100\n",
      "Iteration: 236; Percent complete: 5.9%; Average loss: 4.1361\n",
      "Iteration: 237; Percent complete: 5.9%; Average loss: 4.0682\n",
      "Iteration: 238; Percent complete: 5.9%; Average loss: 3.8058\n",
      "Iteration: 239; Percent complete: 6.0%; Average loss: 4.0169\n",
      "Iteration: 240; Percent complete: 6.0%; Average loss: 3.8472\n",
      "Iteration: 241; Percent complete: 6.0%; Average loss: 4.0268\n",
      "Iteration: 242; Percent complete: 6.0%; Average loss: 3.8856\n",
      "Iteration: 243; Percent complete: 6.1%; Average loss: 3.9712\n",
      "Iteration: 244; Percent complete: 6.1%; Average loss: 4.0298\n",
      "Iteration: 245; Percent complete: 6.1%; Average loss: 3.9250\n",
      "Iteration: 246; Percent complete: 6.2%; Average loss: 4.0529\n",
      "Iteration: 247; Percent complete: 6.2%; Average loss: 4.0036\n",
      "Iteration: 248; Percent complete: 6.2%; Average loss: 4.2044\n",
      "Iteration: 249; Percent complete: 6.2%; Average loss: 4.1692\n",
      "Iteration: 250; Percent complete: 6.2%; Average loss: 3.9902\n",
      "Iteration: 251; Percent complete: 6.3%; Average loss: 3.9847\n",
      "Iteration: 252; Percent complete: 6.3%; Average loss: 3.9312\n",
      "Iteration: 253; Percent complete: 6.3%; Average loss: 4.0968\n",
      "Iteration: 254; Percent complete: 6.3%; Average loss: 3.7440\n",
      "Iteration: 255; Percent complete: 6.4%; Average loss: 3.7814\n",
      "Iteration: 256; Percent complete: 6.4%; Average loss: 3.8778\n",
      "Iteration: 257; Percent complete: 6.4%; Average loss: 3.9462\n",
      "Iteration: 258; Percent complete: 6.5%; Average loss: 3.8670\n",
      "Iteration: 259; Percent complete: 6.5%; Average loss: 3.9583\n",
      "Iteration: 260; Percent complete: 6.5%; Average loss: 3.8852\n",
      "Iteration: 261; Percent complete: 6.5%; Average loss: 3.9413\n",
      "Iteration: 262; Percent complete: 6.6%; Average loss: 4.1769\n",
      "Iteration: 263; Percent complete: 6.6%; Average loss: 3.9672\n",
      "Iteration: 264; Percent complete: 6.6%; Average loss: 4.0755\n",
      "Iteration: 265; Percent complete: 6.6%; Average loss: 3.6813\n",
      "Iteration: 266; Percent complete: 6.7%; Average loss: 3.6722\n",
      "Iteration: 267; Percent complete: 6.7%; Average loss: 4.1432\n",
      "Iteration: 268; Percent complete: 6.7%; Average loss: 4.3056\n",
      "Iteration: 269; Percent complete: 6.7%; Average loss: 4.2333\n",
      "Iteration: 270; Percent complete: 6.8%; Average loss: 3.9264\n",
      "Iteration: 271; Percent complete: 6.8%; Average loss: 4.1835\n",
      "Iteration: 272; Percent complete: 6.8%; Average loss: 4.2209\n",
      "Iteration: 273; Percent complete: 6.8%; Average loss: 3.8886\n",
      "Iteration: 274; Percent complete: 6.9%; Average loss: 3.9627\n",
      "Iteration: 275; Percent complete: 6.9%; Average loss: 4.0668\n",
      "Iteration: 276; Percent complete: 6.9%; Average loss: 4.1140\n",
      "Iteration: 277; Percent complete: 6.9%; Average loss: 3.9334\n",
      "Iteration: 278; Percent complete: 7.0%; Average loss: 3.9210\n",
      "Iteration: 279; Percent complete: 7.0%; Average loss: 3.9074\n",
      "Iteration: 280; Percent complete: 7.0%; Average loss: 3.6459\n",
      "Iteration: 281; Percent complete: 7.0%; Average loss: 3.4367\n",
      "Iteration: 282; Percent complete: 7.0%; Average loss: 4.0782\n",
      "Iteration: 283; Percent complete: 7.1%; Average loss: 3.8470\n",
      "Iteration: 284; Percent complete: 7.1%; Average loss: 3.8382\n",
      "Iteration: 285; Percent complete: 7.1%; Average loss: 4.2122\n",
      "Iteration: 286; Percent complete: 7.1%; Average loss: 4.0994\n",
      "Iteration: 287; Percent complete: 7.2%; Average loss: 3.8104\n",
      "Iteration: 288; Percent complete: 7.2%; Average loss: 4.0726\n",
      "Iteration: 289; Percent complete: 7.2%; Average loss: 3.9776\n",
      "Iteration: 290; Percent complete: 7.2%; Average loss: 3.9142\n",
      "Iteration: 291; Percent complete: 7.3%; Average loss: 3.9161\n",
      "Iteration: 292; Percent complete: 7.3%; Average loss: 4.1642\n",
      "Iteration: 293; Percent complete: 7.3%; Average loss: 4.1852\n",
      "Iteration: 294; Percent complete: 7.3%; Average loss: 3.9292\n",
      "Iteration: 295; Percent complete: 7.4%; Average loss: 4.2290\n",
      "Iteration: 296; Percent complete: 7.4%; Average loss: 3.6722\n",
      "Iteration: 297; Percent complete: 7.4%; Average loss: 3.9260\n",
      "Iteration: 298; Percent complete: 7.4%; Average loss: 3.8653\n",
      "Iteration: 299; Percent complete: 7.5%; Average loss: 3.9611\n",
      "Iteration: 300; Percent complete: 7.5%; Average loss: 4.0588\n",
      "Iteration: 301; Percent complete: 7.5%; Average loss: 3.8498\n",
      "Iteration: 302; Percent complete: 7.5%; Average loss: 3.8037\n",
      "Iteration: 303; Percent complete: 7.6%; Average loss: 4.0109\n",
      "Iteration: 304; Percent complete: 7.6%; Average loss: 3.7357\n",
      "Iteration: 305; Percent complete: 7.6%; Average loss: 4.0324\n",
      "Iteration: 306; Percent complete: 7.6%; Average loss: 3.7437\n",
      "Iteration: 307; Percent complete: 7.7%; Average loss: 3.9824\n",
      "Iteration: 308; Percent complete: 7.7%; Average loss: 4.0195\n",
      "Iteration: 309; Percent complete: 7.7%; Average loss: 3.6357\n",
      "Iteration: 310; Percent complete: 7.8%; Average loss: 4.2062\n",
      "Iteration: 311; Percent complete: 7.8%; Average loss: 3.9330\n",
      "Iteration: 312; Percent complete: 7.8%; Average loss: 4.0195\n",
      "Iteration: 313; Percent complete: 7.8%; Average loss: 3.8258\n",
      "Iteration: 314; Percent complete: 7.8%; Average loss: 3.6191\n",
      "Iteration: 315; Percent complete: 7.9%; Average loss: 3.7524\n",
      "Iteration: 316; Percent complete: 7.9%; Average loss: 3.7817\n",
      "Iteration: 317; Percent complete: 7.9%; Average loss: 3.7227\n",
      "Iteration: 318; Percent complete: 8.0%; Average loss: 3.6559\n",
      "Iteration: 319; Percent complete: 8.0%; Average loss: 3.9009\n",
      "Iteration: 320; Percent complete: 8.0%; Average loss: 4.0995\n",
      "Iteration: 321; Percent complete: 8.0%; Average loss: 3.9927\n",
      "Iteration: 322; Percent complete: 8.1%; Average loss: 4.1229\n",
      "Iteration: 323; Percent complete: 8.1%; Average loss: 3.8154\n",
      "Iteration: 324; Percent complete: 8.1%; Average loss: 4.0058\n",
      "Iteration: 325; Percent complete: 8.1%; Average loss: 3.5169\n",
      "Iteration: 326; Percent complete: 8.2%; Average loss: 3.8350\n",
      "Iteration: 327; Percent complete: 8.2%; Average loss: 3.8259\n",
      "Iteration: 328; Percent complete: 8.2%; Average loss: 3.9748\n",
      "Iteration: 329; Percent complete: 8.2%; Average loss: 3.7931\n",
      "Iteration: 330; Percent complete: 8.2%; Average loss: 3.8386\n",
      "Iteration: 331; Percent complete: 8.3%; Average loss: 3.8571\n",
      "Iteration: 332; Percent complete: 8.3%; Average loss: 3.8165\n",
      "Iteration: 333; Percent complete: 8.3%; Average loss: 3.8858\n",
      "Iteration: 334; Percent complete: 8.3%; Average loss: 3.6886\n",
      "Iteration: 335; Percent complete: 8.4%; Average loss: 3.6719\n",
      "Iteration: 336; Percent complete: 8.4%; Average loss: 3.7104\n",
      "Iteration: 337; Percent complete: 8.4%; Average loss: 3.5886\n",
      "Iteration: 338; Percent complete: 8.5%; Average loss: 3.7231\n",
      "Iteration: 339; Percent complete: 8.5%; Average loss: 3.8111\n",
      "Iteration: 340; Percent complete: 8.5%; Average loss: 4.0626\n",
      "Iteration: 341; Percent complete: 8.5%; Average loss: 3.8089\n",
      "Iteration: 342; Percent complete: 8.6%; Average loss: 3.9092\n",
      "Iteration: 343; Percent complete: 8.6%; Average loss: 3.8564\n",
      "Iteration: 344; Percent complete: 8.6%; Average loss: 3.7870\n",
      "Iteration: 345; Percent complete: 8.6%; Average loss: 4.0120\n",
      "Iteration: 346; Percent complete: 8.6%; Average loss: 3.7148\n",
      "Iteration: 347; Percent complete: 8.7%; Average loss: 3.8811\n",
      "Iteration: 348; Percent complete: 8.7%; Average loss: 3.8372\n",
      "Iteration: 349; Percent complete: 8.7%; Average loss: 3.7754\n",
      "Iteration: 350; Percent complete: 8.8%; Average loss: 4.1021\n",
      "Iteration: 351; Percent complete: 8.8%; Average loss: 3.9062\n",
      "Iteration: 352; Percent complete: 8.8%; Average loss: 3.7697\n",
      "Iteration: 353; Percent complete: 8.8%; Average loss: 3.6772\n",
      "Iteration: 354; Percent complete: 8.8%; Average loss: 4.0363\n",
      "Iteration: 355; Percent complete: 8.9%; Average loss: 3.9751\n",
      "Iteration: 356; Percent complete: 8.9%; Average loss: 3.7483\n",
      "Iteration: 357; Percent complete: 8.9%; Average loss: 3.9562\n",
      "Iteration: 358; Percent complete: 8.9%; Average loss: 3.8029\n",
      "Iteration: 359; Percent complete: 9.0%; Average loss: 3.9083\n",
      "Iteration: 360; Percent complete: 9.0%; Average loss: 3.8005\n",
      "Iteration: 361; Percent complete: 9.0%; Average loss: 3.8683\n",
      "Iteration: 362; Percent complete: 9.0%; Average loss: 3.8801\n",
      "Iteration: 363; Percent complete: 9.1%; Average loss: 3.8870\n",
      "Iteration: 364; Percent complete: 9.1%; Average loss: 3.8691\n",
      "Iteration: 365; Percent complete: 9.1%; Average loss: 3.6718\n",
      "Iteration: 366; Percent complete: 9.2%; Average loss: 4.0133\n",
      "Iteration: 367; Percent complete: 9.2%; Average loss: 3.6297\n",
      "Iteration: 368; Percent complete: 9.2%; Average loss: 3.8958\n",
      "Iteration: 369; Percent complete: 9.2%; Average loss: 3.7986\n",
      "Iteration: 370; Percent complete: 9.2%; Average loss: 3.7870\n",
      "Iteration: 371; Percent complete: 9.3%; Average loss: 3.9622\n",
      "Iteration: 372; Percent complete: 9.3%; Average loss: 3.8877\n",
      "Iteration: 373; Percent complete: 9.3%; Average loss: 3.7196\n",
      "Iteration: 374; Percent complete: 9.3%; Average loss: 3.7833\n",
      "Iteration: 375; Percent complete: 9.4%; Average loss: 3.9449\n",
      "Iteration: 376; Percent complete: 9.4%; Average loss: 3.9530\n",
      "Iteration: 377; Percent complete: 9.4%; Average loss: 3.4805\n",
      "Iteration: 378; Percent complete: 9.4%; Average loss: 3.6414\n",
      "Iteration: 379; Percent complete: 9.5%; Average loss: 3.6594\n",
      "Iteration: 380; Percent complete: 9.5%; Average loss: 3.7621\n",
      "Iteration: 381; Percent complete: 9.5%; Average loss: 3.9670\n",
      "Iteration: 382; Percent complete: 9.6%; Average loss: 3.5196\n",
      "Iteration: 383; Percent complete: 9.6%; Average loss: 3.5022\n",
      "Iteration: 384; Percent complete: 9.6%; Average loss: 3.9580\n",
      "Iteration: 385; Percent complete: 9.6%; Average loss: 3.7315\n",
      "Iteration: 386; Percent complete: 9.7%; Average loss: 4.0758\n",
      "Iteration: 387; Percent complete: 9.7%; Average loss: 3.8051\n",
      "Iteration: 388; Percent complete: 9.7%; Average loss: 3.8562\n",
      "Iteration: 389; Percent complete: 9.7%; Average loss: 3.7532\n",
      "Iteration: 390; Percent complete: 9.8%; Average loss: 4.1445\n",
      "Iteration: 391; Percent complete: 9.8%; Average loss: 3.9031\n",
      "Iteration: 392; Percent complete: 9.8%; Average loss: 3.6054\n",
      "Iteration: 393; Percent complete: 9.8%; Average loss: 4.0023\n",
      "Iteration: 394; Percent complete: 9.8%; Average loss: 3.8720\n",
      "Iteration: 395; Percent complete: 9.9%; Average loss: 3.8136\n",
      "Iteration: 396; Percent complete: 9.9%; Average loss: 3.7782\n",
      "Iteration: 397; Percent complete: 9.9%; Average loss: 3.8818\n",
      "Iteration: 398; Percent complete: 10.0%; Average loss: 3.6830\n",
      "Iteration: 399; Percent complete: 10.0%; Average loss: 3.6042\n",
      "Iteration: 400; Percent complete: 10.0%; Average loss: 3.6033\n",
      "Iteration: 401; Percent complete: 10.0%; Average loss: 4.0543\n",
      "Iteration: 402; Percent complete: 10.1%; Average loss: 3.8603\n",
      "Iteration: 403; Percent complete: 10.1%; Average loss: 3.7808\n",
      "Iteration: 404; Percent complete: 10.1%; Average loss: 4.1854\n",
      "Iteration: 405; Percent complete: 10.1%; Average loss: 3.7163\n",
      "Iteration: 406; Percent complete: 10.2%; Average loss: 3.7211\n",
      "Iteration: 407; Percent complete: 10.2%; Average loss: 4.0517\n",
      "Iteration: 408; Percent complete: 10.2%; Average loss: 3.9546\n",
      "Iteration: 409; Percent complete: 10.2%; Average loss: 3.7168\n",
      "Iteration: 410; Percent complete: 10.2%; Average loss: 3.8187\n",
      "Iteration: 411; Percent complete: 10.3%; Average loss: 3.7692\n",
      "Iteration: 412; Percent complete: 10.3%; Average loss: 3.7195\n",
      "Iteration: 413; Percent complete: 10.3%; Average loss: 3.8198\n",
      "Iteration: 414; Percent complete: 10.3%; Average loss: 3.9124\n",
      "Iteration: 415; Percent complete: 10.4%; Average loss: 4.0625\n",
      "Iteration: 416; Percent complete: 10.4%; Average loss: 3.7785\n",
      "Iteration: 417; Percent complete: 10.4%; Average loss: 3.5422\n",
      "Iteration: 418; Percent complete: 10.4%; Average loss: 3.5326\n",
      "Iteration: 419; Percent complete: 10.5%; Average loss: 3.7042\n",
      "Iteration: 420; Percent complete: 10.5%; Average loss: 4.1719\n",
      "Iteration: 421; Percent complete: 10.5%; Average loss: 3.8295\n",
      "Iteration: 422; Percent complete: 10.5%; Average loss: 3.8512\n",
      "Iteration: 423; Percent complete: 10.6%; Average loss: 3.9442\n",
      "Iteration: 424; Percent complete: 10.6%; Average loss: 3.8014\n",
      "Iteration: 425; Percent complete: 10.6%; Average loss: 3.6830\n",
      "Iteration: 426; Percent complete: 10.7%; Average loss: 3.8851\n",
      "Iteration: 427; Percent complete: 10.7%; Average loss: 3.4497\n",
      "Iteration: 428; Percent complete: 10.7%; Average loss: 3.8967\n",
      "Iteration: 429; Percent complete: 10.7%; Average loss: 3.8292\n",
      "Iteration: 430; Percent complete: 10.8%; Average loss: 4.0449\n",
      "Iteration: 431; Percent complete: 10.8%; Average loss: 3.7376\n",
      "Iteration: 432; Percent complete: 10.8%; Average loss: 3.8036\n",
      "Iteration: 433; Percent complete: 10.8%; Average loss: 4.0134\n",
      "Iteration: 434; Percent complete: 10.8%; Average loss: 3.7928\n",
      "Iteration: 435; Percent complete: 10.9%; Average loss: 3.7534\n",
      "Iteration: 436; Percent complete: 10.9%; Average loss: 3.6854\n",
      "Iteration: 437; Percent complete: 10.9%; Average loss: 3.6860\n",
      "Iteration: 438; Percent complete: 10.9%; Average loss: 3.6491\n",
      "Iteration: 439; Percent complete: 11.0%; Average loss: 3.6968\n",
      "Iteration: 440; Percent complete: 11.0%; Average loss: 3.7408\n",
      "Iteration: 441; Percent complete: 11.0%; Average loss: 4.0733\n",
      "Iteration: 442; Percent complete: 11.1%; Average loss: 4.0408\n",
      "Iteration: 443; Percent complete: 11.1%; Average loss: 3.7522\n",
      "Iteration: 444; Percent complete: 11.1%; Average loss: 3.7933\n",
      "Iteration: 445; Percent complete: 11.1%; Average loss: 3.8746\n",
      "Iteration: 446; Percent complete: 11.2%; Average loss: 3.7394\n",
      "Iteration: 447; Percent complete: 11.2%; Average loss: 3.6027\n",
      "Iteration: 448; Percent complete: 11.2%; Average loss: 3.6644\n",
      "Iteration: 449; Percent complete: 11.2%; Average loss: 3.7040\n",
      "Iteration: 450; Percent complete: 11.2%; Average loss: 3.6673\n",
      "Iteration: 451; Percent complete: 11.3%; Average loss: 3.8281\n",
      "Iteration: 452; Percent complete: 11.3%; Average loss: 3.7541\n",
      "Iteration: 453; Percent complete: 11.3%; Average loss: 3.6738\n",
      "Iteration: 454; Percent complete: 11.3%; Average loss: 3.6599\n",
      "Iteration: 455; Percent complete: 11.4%; Average loss: 3.7282\n",
      "Iteration: 456; Percent complete: 11.4%; Average loss: 3.5735\n",
      "Iteration: 457; Percent complete: 11.4%; Average loss: 3.7592\n",
      "Iteration: 458; Percent complete: 11.5%; Average loss: 3.7065\n",
      "Iteration: 459; Percent complete: 11.5%; Average loss: 3.8106\n",
      "Iteration: 460; Percent complete: 11.5%; Average loss: 3.5145\n",
      "Iteration: 461; Percent complete: 11.5%; Average loss: 3.5765\n",
      "Iteration: 462; Percent complete: 11.6%; Average loss: 3.8841\n",
      "Iteration: 463; Percent complete: 11.6%; Average loss: 3.8804\n",
      "Iteration: 464; Percent complete: 11.6%; Average loss: 3.7238\n",
      "Iteration: 465; Percent complete: 11.6%; Average loss: 4.0917\n",
      "Iteration: 466; Percent complete: 11.7%; Average loss: 3.6467\n",
      "Iteration: 467; Percent complete: 11.7%; Average loss: 3.7112\n",
      "Iteration: 468; Percent complete: 11.7%; Average loss: 3.9512\n",
      "Iteration: 469; Percent complete: 11.7%; Average loss: 3.6835\n",
      "Iteration: 470; Percent complete: 11.8%; Average loss: 3.4151\n",
      "Iteration: 471; Percent complete: 11.8%; Average loss: 3.7216\n",
      "Iteration: 472; Percent complete: 11.8%; Average loss: 3.7019\n",
      "Iteration: 473; Percent complete: 11.8%; Average loss: 3.6703\n",
      "Iteration: 474; Percent complete: 11.8%; Average loss: 3.9414\n",
      "Iteration: 475; Percent complete: 11.9%; Average loss: 3.7452\n",
      "Iteration: 476; Percent complete: 11.9%; Average loss: 3.9532\n",
      "Iteration: 477; Percent complete: 11.9%; Average loss: 3.8105\n",
      "Iteration: 478; Percent complete: 11.9%; Average loss: 3.8009\n",
      "Iteration: 479; Percent complete: 12.0%; Average loss: 3.7122\n",
      "Iteration: 480; Percent complete: 12.0%; Average loss: 3.7430\n",
      "Iteration: 481; Percent complete: 12.0%; Average loss: 3.8451\n",
      "Iteration: 482; Percent complete: 12.0%; Average loss: 3.7796\n",
      "Iteration: 483; Percent complete: 12.1%; Average loss: 3.6644\n",
      "Iteration: 484; Percent complete: 12.1%; Average loss: 3.7532\n",
      "Iteration: 485; Percent complete: 12.1%; Average loss: 3.8663\n",
      "Iteration: 486; Percent complete: 12.2%; Average loss: 3.5834\n",
      "Iteration: 487; Percent complete: 12.2%; Average loss: 3.9960\n",
      "Iteration: 488; Percent complete: 12.2%; Average loss: 3.6028\n",
      "Iteration: 489; Percent complete: 12.2%; Average loss: 3.9242\n",
      "Iteration: 490; Percent complete: 12.2%; Average loss: 3.5886\n",
      "Iteration: 491; Percent complete: 12.3%; Average loss: 3.7678\n",
      "Iteration: 492; Percent complete: 12.3%; Average loss: 3.7378\n",
      "Iteration: 493; Percent complete: 12.3%; Average loss: 3.6492\n",
      "Iteration: 494; Percent complete: 12.3%; Average loss: 3.7200\n",
      "Iteration: 495; Percent complete: 12.4%; Average loss: 3.7285\n",
      "Iteration: 496; Percent complete: 12.4%; Average loss: 3.6411\n",
      "Iteration: 497; Percent complete: 12.4%; Average loss: 3.7766\n",
      "Iteration: 498; Percent complete: 12.4%; Average loss: 3.5712\n",
      "Iteration: 499; Percent complete: 12.5%; Average loss: 3.6934\n",
      "Iteration: 500; Percent complete: 12.5%; Average loss: 3.4050\n",
      "Iteration: 501; Percent complete: 12.5%; Average loss: 3.7637\n",
      "Iteration: 502; Percent complete: 12.6%; Average loss: 3.6943\n",
      "Iteration: 503; Percent complete: 12.6%; Average loss: 4.0403\n",
      "Iteration: 504; Percent complete: 12.6%; Average loss: 3.8772\n",
      "Iteration: 505; Percent complete: 12.6%; Average loss: 3.6806\n",
      "Iteration: 506; Percent complete: 12.7%; Average loss: 3.9077\n",
      "Iteration: 507; Percent complete: 12.7%; Average loss: 3.8560\n",
      "Iteration: 508; Percent complete: 12.7%; Average loss: 3.7142\n",
      "Iteration: 509; Percent complete: 12.7%; Average loss: 3.7543\n",
      "Iteration: 510; Percent complete: 12.8%; Average loss: 3.8389\n",
      "Iteration: 511; Percent complete: 12.8%; Average loss: 3.7334\n",
      "Iteration: 512; Percent complete: 12.8%; Average loss: 3.7529\n",
      "Iteration: 513; Percent complete: 12.8%; Average loss: 3.7681\n",
      "Iteration: 514; Percent complete: 12.8%; Average loss: 3.9264\n",
      "Iteration: 515; Percent complete: 12.9%; Average loss: 3.9280\n",
      "Iteration: 516; Percent complete: 12.9%; Average loss: 3.5613\n",
      "Iteration: 517; Percent complete: 12.9%; Average loss: 3.7961\n",
      "Iteration: 518; Percent complete: 13.0%; Average loss: 4.2622\n",
      "Iteration: 519; Percent complete: 13.0%; Average loss: 3.7063\n",
      "Iteration: 520; Percent complete: 13.0%; Average loss: 3.7242\n",
      "Iteration: 521; Percent complete: 13.0%; Average loss: 3.6466\n",
      "Iteration: 522; Percent complete: 13.1%; Average loss: 3.6605\n",
      "Iteration: 523; Percent complete: 13.1%; Average loss: 3.6951\n",
      "Iteration: 524; Percent complete: 13.1%; Average loss: 3.8780\n",
      "Iteration: 525; Percent complete: 13.1%; Average loss: 3.6828\n",
      "Iteration: 526; Percent complete: 13.2%; Average loss: 3.6776\n",
      "Iteration: 527; Percent complete: 13.2%; Average loss: 3.6464\n",
      "Iteration: 528; Percent complete: 13.2%; Average loss: 3.8845\n",
      "Iteration: 529; Percent complete: 13.2%; Average loss: 3.5866\n",
      "Iteration: 530; Percent complete: 13.2%; Average loss: 3.6426\n",
      "Iteration: 531; Percent complete: 13.3%; Average loss: 3.5789\n",
      "Iteration: 532; Percent complete: 13.3%; Average loss: 3.9215\n",
      "Iteration: 533; Percent complete: 13.3%; Average loss: 3.7895\n",
      "Iteration: 534; Percent complete: 13.4%; Average loss: 3.7361\n",
      "Iteration: 535; Percent complete: 13.4%; Average loss: 3.5429\n",
      "Iteration: 536; Percent complete: 13.4%; Average loss: 3.6919\n",
      "Iteration: 537; Percent complete: 13.4%; Average loss: 3.6720\n",
      "Iteration: 538; Percent complete: 13.5%; Average loss: 3.4389\n",
      "Iteration: 539; Percent complete: 13.5%; Average loss: 3.6855\n",
      "Iteration: 540; Percent complete: 13.5%; Average loss: 3.5914\n",
      "Iteration: 541; Percent complete: 13.5%; Average loss: 3.6102\n",
      "Iteration: 542; Percent complete: 13.6%; Average loss: 3.5880\n",
      "Iteration: 543; Percent complete: 13.6%; Average loss: 3.6183\n",
      "Iteration: 544; Percent complete: 13.6%; Average loss: 3.6859\n",
      "Iteration: 545; Percent complete: 13.6%; Average loss: 3.7343\n",
      "Iteration: 546; Percent complete: 13.7%; Average loss: 3.8276\n",
      "Iteration: 547; Percent complete: 13.7%; Average loss: 3.8533\n",
      "Iteration: 548; Percent complete: 13.7%; Average loss: 3.6370\n",
      "Iteration: 549; Percent complete: 13.7%; Average loss: 3.7400\n",
      "Iteration: 550; Percent complete: 13.8%; Average loss: 3.4673\n",
      "Iteration: 551; Percent complete: 13.8%; Average loss: 3.6513\n",
      "Iteration: 552; Percent complete: 13.8%; Average loss: 3.8294\n",
      "Iteration: 553; Percent complete: 13.8%; Average loss: 3.8554\n",
      "Iteration: 554; Percent complete: 13.9%; Average loss: 3.7860\n",
      "Iteration: 555; Percent complete: 13.9%; Average loss: 3.7085\n",
      "Iteration: 556; Percent complete: 13.9%; Average loss: 3.6445\n",
      "Iteration: 557; Percent complete: 13.9%; Average loss: 3.5229\n",
      "Iteration: 558; Percent complete: 14.0%; Average loss: 3.9394\n",
      "Iteration: 559; Percent complete: 14.0%; Average loss: 3.8552\n",
      "Iteration: 560; Percent complete: 14.0%; Average loss: 3.8065\n",
      "Iteration: 561; Percent complete: 14.0%; Average loss: 3.7205\n",
      "Iteration: 562; Percent complete: 14.1%; Average loss: 3.7204\n",
      "Iteration: 563; Percent complete: 14.1%; Average loss: 3.6498\n",
      "Iteration: 564; Percent complete: 14.1%; Average loss: 3.6531\n",
      "Iteration: 565; Percent complete: 14.1%; Average loss: 3.6938\n",
      "Iteration: 566; Percent complete: 14.1%; Average loss: 3.4877\n",
      "Iteration: 567; Percent complete: 14.2%; Average loss: 3.7694\n",
      "Iteration: 568; Percent complete: 14.2%; Average loss: 3.6035\n",
      "Iteration: 569; Percent complete: 14.2%; Average loss: 3.6045\n",
      "Iteration: 570; Percent complete: 14.2%; Average loss: 3.7176\n",
      "Iteration: 571; Percent complete: 14.3%; Average loss: 3.6273\n",
      "Iteration: 572; Percent complete: 14.3%; Average loss: 3.6440\n",
      "Iteration: 573; Percent complete: 14.3%; Average loss: 3.5800\n",
      "Iteration: 574; Percent complete: 14.3%; Average loss: 3.7222\n",
      "Iteration: 575; Percent complete: 14.4%; Average loss: 3.4439\n",
      "Iteration: 576; Percent complete: 14.4%; Average loss: 3.4557\n",
      "Iteration: 577; Percent complete: 14.4%; Average loss: 3.8653\n",
      "Iteration: 578; Percent complete: 14.4%; Average loss: 3.4434\n",
      "Iteration: 579; Percent complete: 14.5%; Average loss: 4.0301\n",
      "Iteration: 580; Percent complete: 14.5%; Average loss: 3.7929\n",
      "Iteration: 581; Percent complete: 14.5%; Average loss: 3.6134\n",
      "Iteration: 582; Percent complete: 14.5%; Average loss: 3.7934\n",
      "Iteration: 583; Percent complete: 14.6%; Average loss: 3.5687\n",
      "Iteration: 584; Percent complete: 14.6%; Average loss: 3.3886\n",
      "Iteration: 585; Percent complete: 14.6%; Average loss: 3.8155\n",
      "Iteration: 586; Percent complete: 14.6%; Average loss: 3.8307\n",
      "Iteration: 587; Percent complete: 14.7%; Average loss: 3.5291\n",
      "Iteration: 588; Percent complete: 14.7%; Average loss: 3.3265\n",
      "Iteration: 589; Percent complete: 14.7%; Average loss: 3.4991\n",
      "Iteration: 590; Percent complete: 14.8%; Average loss: 3.7146\n",
      "Iteration: 591; Percent complete: 14.8%; Average loss: 3.8169\n",
      "Iteration: 592; Percent complete: 14.8%; Average loss: 3.4924\n",
      "Iteration: 593; Percent complete: 14.8%; Average loss: 3.4134\n",
      "Iteration: 594; Percent complete: 14.8%; Average loss: 3.5661\n",
      "Iteration: 595; Percent complete: 14.9%; Average loss: 3.6817\n",
      "Iteration: 596; Percent complete: 14.9%; Average loss: 3.6530\n",
      "Iteration: 597; Percent complete: 14.9%; Average loss: 3.3046\n",
      "Iteration: 598; Percent complete: 14.9%; Average loss: 3.8228\n",
      "Iteration: 599; Percent complete: 15.0%; Average loss: 3.9314\n",
      "Iteration: 600; Percent complete: 15.0%; Average loss: 3.7030\n",
      "Iteration: 601; Percent complete: 15.0%; Average loss: 3.5892\n",
      "Iteration: 602; Percent complete: 15.0%; Average loss: 3.5931\n",
      "Iteration: 603; Percent complete: 15.1%; Average loss: 3.7933\n",
      "Iteration: 604; Percent complete: 15.1%; Average loss: 3.5734\n",
      "Iteration: 605; Percent complete: 15.1%; Average loss: 3.5999\n",
      "Iteration: 606; Percent complete: 15.2%; Average loss: 3.4313\n",
      "Iteration: 607; Percent complete: 15.2%; Average loss: 3.6277\n",
      "Iteration: 608; Percent complete: 15.2%; Average loss: 3.7649\n",
      "Iteration: 609; Percent complete: 15.2%; Average loss: 3.6757\n",
      "Iteration: 610; Percent complete: 15.2%; Average loss: 3.9065\n",
      "Iteration: 611; Percent complete: 15.3%; Average loss: 3.5413\n",
      "Iteration: 612; Percent complete: 15.3%; Average loss: 3.5871\n",
      "Iteration: 613; Percent complete: 15.3%; Average loss: 3.8822\n",
      "Iteration: 614; Percent complete: 15.3%; Average loss: 3.6300\n",
      "Iteration: 615; Percent complete: 15.4%; Average loss: 3.8569\n",
      "Iteration: 616; Percent complete: 15.4%; Average loss: 3.7766\n",
      "Iteration: 617; Percent complete: 15.4%; Average loss: 3.7841\n",
      "Iteration: 618; Percent complete: 15.4%; Average loss: 3.8145\n",
      "Iteration: 619; Percent complete: 15.5%; Average loss: 3.8911\n",
      "Iteration: 620; Percent complete: 15.5%; Average loss: 3.4458\n",
      "Iteration: 621; Percent complete: 15.5%; Average loss: 3.3701\n",
      "Iteration: 622; Percent complete: 15.6%; Average loss: 3.7175\n",
      "Iteration: 623; Percent complete: 15.6%; Average loss: 3.5337\n",
      "Iteration: 624; Percent complete: 15.6%; Average loss: 4.0521\n",
      "Iteration: 625; Percent complete: 15.6%; Average loss: 3.8515\n",
      "Iteration: 626; Percent complete: 15.7%; Average loss: 3.7054\n",
      "Iteration: 627; Percent complete: 15.7%; Average loss: 3.5507\n",
      "Iteration: 628; Percent complete: 15.7%; Average loss: 3.6639\n",
      "Iteration: 629; Percent complete: 15.7%; Average loss: 3.5412\n",
      "Iteration: 630; Percent complete: 15.8%; Average loss: 3.6610\n",
      "Iteration: 631; Percent complete: 15.8%; Average loss: 3.6869\n",
      "Iteration: 632; Percent complete: 15.8%; Average loss: 3.9102\n",
      "Iteration: 633; Percent complete: 15.8%; Average loss: 3.4345\n",
      "Iteration: 634; Percent complete: 15.8%; Average loss: 3.7326\n",
      "Iteration: 635; Percent complete: 15.9%; Average loss: 3.8203\n",
      "Iteration: 636; Percent complete: 15.9%; Average loss: 3.3605\n",
      "Iteration: 637; Percent complete: 15.9%; Average loss: 3.8944\n",
      "Iteration: 638; Percent complete: 16.0%; Average loss: 3.5699\n",
      "Iteration: 639; Percent complete: 16.0%; Average loss: 3.5902\n",
      "Iteration: 640; Percent complete: 16.0%; Average loss: 3.8047\n",
      "Iteration: 641; Percent complete: 16.0%; Average loss: 3.4144\n",
      "Iteration: 642; Percent complete: 16.1%; Average loss: 3.6899\n",
      "Iteration: 643; Percent complete: 16.1%; Average loss: 3.8405\n",
      "Iteration: 644; Percent complete: 16.1%; Average loss: 3.5504\n",
      "Iteration: 645; Percent complete: 16.1%; Average loss: 3.4787\n",
      "Iteration: 646; Percent complete: 16.2%; Average loss: 3.5888\n",
      "Iteration: 647; Percent complete: 16.2%; Average loss: 3.5492\n",
      "Iteration: 648; Percent complete: 16.2%; Average loss: 3.5877\n",
      "Iteration: 649; Percent complete: 16.2%; Average loss: 3.8612\n",
      "Iteration: 650; Percent complete: 16.2%; Average loss: 3.4469\n",
      "Iteration: 651; Percent complete: 16.3%; Average loss: 3.5281\n",
      "Iteration: 652; Percent complete: 16.3%; Average loss: 3.4904\n",
      "Iteration: 653; Percent complete: 16.3%; Average loss: 3.5642\n",
      "Iteration: 654; Percent complete: 16.4%; Average loss: 3.3360\n",
      "Iteration: 655; Percent complete: 16.4%; Average loss: 4.0082\n",
      "Iteration: 656; Percent complete: 16.4%; Average loss: 3.6184\n",
      "Iteration: 657; Percent complete: 16.4%; Average loss: 3.6745\n",
      "Iteration: 658; Percent complete: 16.4%; Average loss: 3.6890\n",
      "Iteration: 659; Percent complete: 16.5%; Average loss: 3.6936\n",
      "Iteration: 660; Percent complete: 16.5%; Average loss: 3.4461\n",
      "Iteration: 661; Percent complete: 16.5%; Average loss: 3.4395\n",
      "Iteration: 662; Percent complete: 16.6%; Average loss: 3.3765\n",
      "Iteration: 663; Percent complete: 16.6%; Average loss: 3.6121\n",
      "Iteration: 664; Percent complete: 16.6%; Average loss: 3.5725\n",
      "Iteration: 665; Percent complete: 16.6%; Average loss: 3.5572\n",
      "Iteration: 666; Percent complete: 16.7%; Average loss: 3.8594\n",
      "Iteration: 667; Percent complete: 16.7%; Average loss: 3.4797\n",
      "Iteration: 668; Percent complete: 16.7%; Average loss: 3.6888\n",
      "Iteration: 669; Percent complete: 16.7%; Average loss: 3.6844\n",
      "Iteration: 670; Percent complete: 16.8%; Average loss: 3.4451\n",
      "Iteration: 671; Percent complete: 16.8%; Average loss: 3.7818\n",
      "Iteration: 672; Percent complete: 16.8%; Average loss: 3.4658\n",
      "Iteration: 673; Percent complete: 16.8%; Average loss: 3.2167\n",
      "Iteration: 674; Percent complete: 16.9%; Average loss: 3.3791\n",
      "Iteration: 675; Percent complete: 16.9%; Average loss: 3.5105\n",
      "Iteration: 676; Percent complete: 16.9%; Average loss: 3.5353\n",
      "Iteration: 677; Percent complete: 16.9%; Average loss: 3.4139\n",
      "Iteration: 678; Percent complete: 17.0%; Average loss: 3.7559\n",
      "Iteration: 679; Percent complete: 17.0%; Average loss: 3.9090\n",
      "Iteration: 680; Percent complete: 17.0%; Average loss: 3.7739\n",
      "Iteration: 681; Percent complete: 17.0%; Average loss: 3.5693\n",
      "Iteration: 682; Percent complete: 17.1%; Average loss: 3.8804\n",
      "Iteration: 683; Percent complete: 17.1%; Average loss: 3.6567\n",
      "Iteration: 684; Percent complete: 17.1%; Average loss: 3.5583\n",
      "Iteration: 685; Percent complete: 17.1%; Average loss: 3.5636\n",
      "Iteration: 686; Percent complete: 17.2%; Average loss: 3.3426\n",
      "Iteration: 687; Percent complete: 17.2%; Average loss: 3.6325\n",
      "Iteration: 688; Percent complete: 17.2%; Average loss: 3.5755\n",
      "Iteration: 689; Percent complete: 17.2%; Average loss: 3.9421\n",
      "Iteration: 690; Percent complete: 17.2%; Average loss: 3.7110\n",
      "Iteration: 691; Percent complete: 17.3%; Average loss: 3.6895\n",
      "Iteration: 692; Percent complete: 17.3%; Average loss: 3.6401\n",
      "Iteration: 693; Percent complete: 17.3%; Average loss: 3.9377\n",
      "Iteration: 694; Percent complete: 17.3%; Average loss: 3.5453\n",
      "Iteration: 695; Percent complete: 17.4%; Average loss: 3.7622\n",
      "Iteration: 696; Percent complete: 17.4%; Average loss: 3.5246\n",
      "Iteration: 697; Percent complete: 17.4%; Average loss: 3.6749\n",
      "Iteration: 698; Percent complete: 17.4%; Average loss: 3.5956\n",
      "Iteration: 699; Percent complete: 17.5%; Average loss: 3.6051\n",
      "Iteration: 700; Percent complete: 17.5%; Average loss: 3.9431\n",
      "Iteration: 701; Percent complete: 17.5%; Average loss: 3.5296\n",
      "Iteration: 702; Percent complete: 17.5%; Average loss: 3.8589\n",
      "Iteration: 703; Percent complete: 17.6%; Average loss: 3.3820\n",
      "Iteration: 704; Percent complete: 17.6%; Average loss: 3.4485\n",
      "Iteration: 705; Percent complete: 17.6%; Average loss: 3.3530\n",
      "Iteration: 706; Percent complete: 17.6%; Average loss: 3.6531\n",
      "Iteration: 707; Percent complete: 17.7%; Average loss: 3.4037\n",
      "Iteration: 708; Percent complete: 17.7%; Average loss: 3.5056\n",
      "Iteration: 709; Percent complete: 17.7%; Average loss: 3.7576\n",
      "Iteration: 710; Percent complete: 17.8%; Average loss: 3.3733\n",
      "Iteration: 711; Percent complete: 17.8%; Average loss: 3.5497\n",
      "Iteration: 712; Percent complete: 17.8%; Average loss: 3.4299\n",
      "Iteration: 713; Percent complete: 17.8%; Average loss: 3.6077\n",
      "Iteration: 714; Percent complete: 17.8%; Average loss: 3.6160\n",
      "Iteration: 715; Percent complete: 17.9%; Average loss: 3.6875\n",
      "Iteration: 716; Percent complete: 17.9%; Average loss: 3.8424\n",
      "Iteration: 717; Percent complete: 17.9%; Average loss: 3.5597\n",
      "Iteration: 718; Percent complete: 17.9%; Average loss: 3.3719\n",
      "Iteration: 719; Percent complete: 18.0%; Average loss: 3.7144\n",
      "Iteration: 720; Percent complete: 18.0%; Average loss: 3.7321\n",
      "Iteration: 721; Percent complete: 18.0%; Average loss: 3.7388\n",
      "Iteration: 722; Percent complete: 18.1%; Average loss: 3.4843\n",
      "Iteration: 723; Percent complete: 18.1%; Average loss: 3.4233\n",
      "Iteration: 724; Percent complete: 18.1%; Average loss: 3.5898\n",
      "Iteration: 725; Percent complete: 18.1%; Average loss: 3.8557\n",
      "Iteration: 726; Percent complete: 18.1%; Average loss: 3.8385\n",
      "Iteration: 727; Percent complete: 18.2%; Average loss: 3.7131\n",
      "Iteration: 728; Percent complete: 18.2%; Average loss: 3.7178\n",
      "Iteration: 729; Percent complete: 18.2%; Average loss: 4.1074\n",
      "Iteration: 730; Percent complete: 18.2%; Average loss: 3.5278\n",
      "Iteration: 731; Percent complete: 18.3%; Average loss: 3.7509\n",
      "Iteration: 732; Percent complete: 18.3%; Average loss: 3.6628\n",
      "Iteration: 733; Percent complete: 18.3%; Average loss: 3.5518\n",
      "Iteration: 734; Percent complete: 18.4%; Average loss: 3.6094\n",
      "Iteration: 735; Percent complete: 18.4%; Average loss: 3.5243\n",
      "Iteration: 736; Percent complete: 18.4%; Average loss: 3.7603\n",
      "Iteration: 737; Percent complete: 18.4%; Average loss: 3.3238\n",
      "Iteration: 738; Percent complete: 18.4%; Average loss: 3.5140\n",
      "Iteration: 739; Percent complete: 18.5%; Average loss: 3.5051\n",
      "Iteration: 740; Percent complete: 18.5%; Average loss: 3.6614\n",
      "Iteration: 741; Percent complete: 18.5%; Average loss: 3.7263\n",
      "Iteration: 742; Percent complete: 18.6%; Average loss: 3.7878\n",
      "Iteration: 743; Percent complete: 18.6%; Average loss: 3.7736\n",
      "Iteration: 744; Percent complete: 18.6%; Average loss: 3.3851\n",
      "Iteration: 745; Percent complete: 18.6%; Average loss: 3.6624\n",
      "Iteration: 746; Percent complete: 18.6%; Average loss: 3.5097\n",
      "Iteration: 747; Percent complete: 18.7%; Average loss: 3.8095\n",
      "Iteration: 748; Percent complete: 18.7%; Average loss: 3.3399\n",
      "Iteration: 749; Percent complete: 18.7%; Average loss: 3.7161\n",
      "Iteration: 750; Percent complete: 18.8%; Average loss: 3.6133\n",
      "Iteration: 751; Percent complete: 18.8%; Average loss: 3.7416\n",
      "Iteration: 752; Percent complete: 18.8%; Average loss: 3.7949\n",
      "Iteration: 753; Percent complete: 18.8%; Average loss: 3.5560\n",
      "Iteration: 754; Percent complete: 18.9%; Average loss: 3.7997\n",
      "Iteration: 755; Percent complete: 18.9%; Average loss: 3.4895\n",
      "Iteration: 756; Percent complete: 18.9%; Average loss: 3.7303\n",
      "Iteration: 757; Percent complete: 18.9%; Average loss: 3.5593\n",
      "Iteration: 758; Percent complete: 18.9%; Average loss: 3.5854\n",
      "Iteration: 759; Percent complete: 19.0%; Average loss: 3.3611\n",
      "Iteration: 760; Percent complete: 19.0%; Average loss: 3.5116\n",
      "Iteration: 761; Percent complete: 19.0%; Average loss: 3.6401\n",
      "Iteration: 762; Percent complete: 19.1%; Average loss: 3.6278\n",
      "Iteration: 763; Percent complete: 19.1%; Average loss: 3.6157\n",
      "Iteration: 764; Percent complete: 19.1%; Average loss: 3.4133\n",
      "Iteration: 765; Percent complete: 19.1%; Average loss: 3.6686\n",
      "Iteration: 766; Percent complete: 19.1%; Average loss: 3.5565\n",
      "Iteration: 767; Percent complete: 19.2%; Average loss: 3.5312\n",
      "Iteration: 768; Percent complete: 19.2%; Average loss: 3.6221\n",
      "Iteration: 769; Percent complete: 19.2%; Average loss: 3.6621\n",
      "Iteration: 770; Percent complete: 19.2%; Average loss: 3.6298\n",
      "Iteration: 771; Percent complete: 19.3%; Average loss: 3.4978\n",
      "Iteration: 772; Percent complete: 19.3%; Average loss: 3.5311\n",
      "Iteration: 773; Percent complete: 19.3%; Average loss: 3.4143\n",
      "Iteration: 774; Percent complete: 19.4%; Average loss: 3.1761\n",
      "Iteration: 775; Percent complete: 19.4%; Average loss: 3.5972\n",
      "Iteration: 776; Percent complete: 19.4%; Average loss: 3.5982\n",
      "Iteration: 777; Percent complete: 19.4%; Average loss: 3.5905\n",
      "Iteration: 778; Percent complete: 19.4%; Average loss: 3.4382\n",
      "Iteration: 779; Percent complete: 19.5%; Average loss: 3.4797\n",
      "Iteration: 780; Percent complete: 19.5%; Average loss: 3.4883\n",
      "Iteration: 781; Percent complete: 19.5%; Average loss: 3.6410\n",
      "Iteration: 782; Percent complete: 19.6%; Average loss: 3.7022\n",
      "Iteration: 783; Percent complete: 19.6%; Average loss: 3.6563\n",
      "Iteration: 784; Percent complete: 19.6%; Average loss: 3.5219\n",
      "Iteration: 785; Percent complete: 19.6%; Average loss: 3.3917\n",
      "Iteration: 786; Percent complete: 19.7%; Average loss: 3.5456\n",
      "Iteration: 787; Percent complete: 19.7%; Average loss: 3.8979\n",
      "Iteration: 788; Percent complete: 19.7%; Average loss: 3.5261\n",
      "Iteration: 789; Percent complete: 19.7%; Average loss: 3.6247\n",
      "Iteration: 790; Percent complete: 19.8%; Average loss: 3.6166\n",
      "Iteration: 791; Percent complete: 19.8%; Average loss: 3.3911\n",
      "Iteration: 792; Percent complete: 19.8%; Average loss: 3.5538\n",
      "Iteration: 793; Percent complete: 19.8%; Average loss: 3.6301\n",
      "Iteration: 794; Percent complete: 19.9%; Average loss: 3.5063\n",
      "Iteration: 795; Percent complete: 19.9%; Average loss: 3.6609\n",
      "Iteration: 796; Percent complete: 19.9%; Average loss: 3.5223\n",
      "Iteration: 797; Percent complete: 19.9%; Average loss: 3.7565\n",
      "Iteration: 798; Percent complete: 20.0%; Average loss: 3.5414\n",
      "Iteration: 799; Percent complete: 20.0%; Average loss: 3.4539\n",
      "Iteration: 800; Percent complete: 20.0%; Average loss: 3.5645\n",
      "Iteration: 801; Percent complete: 20.0%; Average loss: 3.4538\n",
      "Iteration: 802; Percent complete: 20.1%; Average loss: 3.6022\n",
      "Iteration: 803; Percent complete: 20.1%; Average loss: 3.5889\n",
      "Iteration: 804; Percent complete: 20.1%; Average loss: 3.4370\n",
      "Iteration: 805; Percent complete: 20.1%; Average loss: 3.4511\n",
      "Iteration: 806; Percent complete: 20.2%; Average loss: 3.5771\n",
      "Iteration: 807; Percent complete: 20.2%; Average loss: 3.5379\n",
      "Iteration: 808; Percent complete: 20.2%; Average loss: 3.3270\n",
      "Iteration: 809; Percent complete: 20.2%; Average loss: 3.1621\n",
      "Iteration: 810; Percent complete: 20.2%; Average loss: 3.6326\n",
      "Iteration: 811; Percent complete: 20.3%; Average loss: 3.7955\n",
      "Iteration: 812; Percent complete: 20.3%; Average loss: 3.5261\n",
      "Iteration: 813; Percent complete: 20.3%; Average loss: 3.5820\n",
      "Iteration: 814; Percent complete: 20.3%; Average loss: 3.3628\n",
      "Iteration: 815; Percent complete: 20.4%; Average loss: 3.6605\n",
      "Iteration: 816; Percent complete: 20.4%; Average loss: 3.5128\n",
      "Iteration: 817; Percent complete: 20.4%; Average loss: 3.7156\n",
      "Iteration: 818; Percent complete: 20.4%; Average loss: 3.9293\n",
      "Iteration: 819; Percent complete: 20.5%; Average loss: 3.4814\n",
      "Iteration: 820; Percent complete: 20.5%; Average loss: 3.4905\n",
      "Iteration: 821; Percent complete: 20.5%; Average loss: 3.3458\n",
      "Iteration: 822; Percent complete: 20.5%; Average loss: 3.4010\n",
      "Iteration: 823; Percent complete: 20.6%; Average loss: 3.7499\n",
      "Iteration: 824; Percent complete: 20.6%; Average loss: 3.4270\n",
      "Iteration: 825; Percent complete: 20.6%; Average loss: 3.5985\n",
      "Iteration: 826; Percent complete: 20.6%; Average loss: 3.3891\n",
      "Iteration: 827; Percent complete: 20.7%; Average loss: 3.5869\n",
      "Iteration: 828; Percent complete: 20.7%; Average loss: 3.4493\n",
      "Iteration: 829; Percent complete: 20.7%; Average loss: 3.8053\n",
      "Iteration: 830; Percent complete: 20.8%; Average loss: 3.5465\n",
      "Iteration: 831; Percent complete: 20.8%; Average loss: 3.3203\n",
      "Iteration: 832; Percent complete: 20.8%; Average loss: 3.7204\n",
      "Iteration: 833; Percent complete: 20.8%; Average loss: 3.2725\n",
      "Iteration: 834; Percent complete: 20.8%; Average loss: 3.5377\n",
      "Iteration: 835; Percent complete: 20.9%; Average loss: 3.5848\n",
      "Iteration: 836; Percent complete: 20.9%; Average loss: 3.5857\n",
      "Iteration: 837; Percent complete: 20.9%; Average loss: 3.5773\n",
      "Iteration: 838; Percent complete: 20.9%; Average loss: 3.3663\n",
      "Iteration: 839; Percent complete: 21.0%; Average loss: 3.6197\n",
      "Iteration: 840; Percent complete: 21.0%; Average loss: 3.6037\n",
      "Iteration: 841; Percent complete: 21.0%; Average loss: 3.5231\n",
      "Iteration: 842; Percent complete: 21.1%; Average loss: 3.5001\n",
      "Iteration: 843; Percent complete: 21.1%; Average loss: 3.5841\n",
      "Iteration: 844; Percent complete: 21.1%; Average loss: 3.6276\n",
      "Iteration: 845; Percent complete: 21.1%; Average loss: 3.7463\n",
      "Iteration: 846; Percent complete: 21.1%; Average loss: 3.4006\n",
      "Iteration: 847; Percent complete: 21.2%; Average loss: 3.3359\n",
      "Iteration: 848; Percent complete: 21.2%; Average loss: 3.3949\n",
      "Iteration: 849; Percent complete: 21.2%; Average loss: 3.5315\n",
      "Iteration: 850; Percent complete: 21.2%; Average loss: 3.6480\n",
      "Iteration: 851; Percent complete: 21.3%; Average loss: 3.5539\n",
      "Iteration: 852; Percent complete: 21.3%; Average loss: 3.6276\n",
      "Iteration: 853; Percent complete: 21.3%; Average loss: 3.4616\n",
      "Iteration: 854; Percent complete: 21.3%; Average loss: 3.3897\n",
      "Iteration: 855; Percent complete: 21.4%; Average loss: 3.5216\n",
      "Iteration: 856; Percent complete: 21.4%; Average loss: 3.3250\n",
      "Iteration: 857; Percent complete: 21.4%; Average loss: 3.5170\n",
      "Iteration: 858; Percent complete: 21.4%; Average loss: 3.6663\n",
      "Iteration: 859; Percent complete: 21.5%; Average loss: 3.6312\n",
      "Iteration: 860; Percent complete: 21.5%; Average loss: 3.4810\n",
      "Iteration: 861; Percent complete: 21.5%; Average loss: 3.4135\n",
      "Iteration: 862; Percent complete: 21.6%; Average loss: 3.5074\n",
      "Iteration: 863; Percent complete: 21.6%; Average loss: 3.4013\n",
      "Iteration: 864; Percent complete: 21.6%; Average loss: 3.4131\n",
      "Iteration: 865; Percent complete: 21.6%; Average loss: 3.4332\n",
      "Iteration: 866; Percent complete: 21.6%; Average loss: 3.6537\n",
      "Iteration: 867; Percent complete: 21.7%; Average loss: 3.5194\n",
      "Iteration: 868; Percent complete: 21.7%; Average loss: 3.5412\n",
      "Iteration: 869; Percent complete: 21.7%; Average loss: 3.8455\n",
      "Iteration: 870; Percent complete: 21.8%; Average loss: 3.5537\n",
      "Iteration: 871; Percent complete: 21.8%; Average loss: 3.4311\n",
      "Iteration: 872; Percent complete: 21.8%; Average loss: 3.5531\n",
      "Iteration: 873; Percent complete: 21.8%; Average loss: 3.6795\n",
      "Iteration: 874; Percent complete: 21.9%; Average loss: 3.9202\n",
      "Iteration: 875; Percent complete: 21.9%; Average loss: 3.4337\n",
      "Iteration: 876; Percent complete: 21.9%; Average loss: 3.6008\n",
      "Iteration: 877; Percent complete: 21.9%; Average loss: 3.6333\n",
      "Iteration: 878; Percent complete: 21.9%; Average loss: 3.5520\n",
      "Iteration: 879; Percent complete: 22.0%; Average loss: 3.7014\n",
      "Iteration: 880; Percent complete: 22.0%; Average loss: 3.4167\n",
      "Iteration: 881; Percent complete: 22.0%; Average loss: 3.4480\n",
      "Iteration: 882; Percent complete: 22.1%; Average loss: 3.3562\n",
      "Iteration: 883; Percent complete: 22.1%; Average loss: 3.7513\n",
      "Iteration: 884; Percent complete: 22.1%; Average loss: 3.6109\n",
      "Iteration: 885; Percent complete: 22.1%; Average loss: 3.4533\n",
      "Iteration: 886; Percent complete: 22.1%; Average loss: 3.5784\n",
      "Iteration: 887; Percent complete: 22.2%; Average loss: 3.8337\n",
      "Iteration: 888; Percent complete: 22.2%; Average loss: 3.6128\n",
      "Iteration: 889; Percent complete: 22.2%; Average loss: 3.5425\n",
      "Iteration: 890; Percent complete: 22.2%; Average loss: 3.5607\n",
      "Iteration: 891; Percent complete: 22.3%; Average loss: 3.3575\n",
      "Iteration: 892; Percent complete: 22.3%; Average loss: 3.4576\n",
      "Iteration: 893; Percent complete: 22.3%; Average loss: 3.3373\n",
      "Iteration: 894; Percent complete: 22.4%; Average loss: 3.5568\n",
      "Iteration: 895; Percent complete: 22.4%; Average loss: 3.6575\n",
      "Iteration: 896; Percent complete: 22.4%; Average loss: 3.7700\n",
      "Iteration: 897; Percent complete: 22.4%; Average loss: 3.3262\n",
      "Iteration: 898; Percent complete: 22.4%; Average loss: 3.6849\n",
      "Iteration: 899; Percent complete: 22.5%; Average loss: 3.3986\n",
      "Iteration: 900; Percent complete: 22.5%; Average loss: 3.7253\n",
      "Iteration: 901; Percent complete: 22.5%; Average loss: 3.3032\n",
      "Iteration: 902; Percent complete: 22.6%; Average loss: 3.6491\n",
      "Iteration: 903; Percent complete: 22.6%; Average loss: 3.6549\n",
      "Iteration: 904; Percent complete: 22.6%; Average loss: 3.4655\n",
      "Iteration: 905; Percent complete: 22.6%; Average loss: 3.4510\n",
      "Iteration: 906; Percent complete: 22.7%; Average loss: 3.4310\n",
      "Iteration: 907; Percent complete: 22.7%; Average loss: 3.4675\n",
      "Iteration: 908; Percent complete: 22.7%; Average loss: 3.4511\n",
      "Iteration: 909; Percent complete: 22.7%; Average loss: 3.4042\n",
      "Iteration: 910; Percent complete: 22.8%; Average loss: 3.3496\n",
      "Iteration: 911; Percent complete: 22.8%; Average loss: 3.5439\n",
      "Iteration: 912; Percent complete: 22.8%; Average loss: 3.4406\n",
      "Iteration: 913; Percent complete: 22.8%; Average loss: 3.3593\n",
      "Iteration: 914; Percent complete: 22.9%; Average loss: 3.5348\n",
      "Iteration: 915; Percent complete: 22.9%; Average loss: 3.7245\n",
      "Iteration: 916; Percent complete: 22.9%; Average loss: 3.6471\n",
      "Iteration: 917; Percent complete: 22.9%; Average loss: 3.6803\n",
      "Iteration: 918; Percent complete: 22.9%; Average loss: 3.4830\n",
      "Iteration: 919; Percent complete: 23.0%; Average loss: 3.2568\n",
      "Iteration: 920; Percent complete: 23.0%; Average loss: 3.7267\n",
      "Iteration: 921; Percent complete: 23.0%; Average loss: 3.6653\n",
      "Iteration: 922; Percent complete: 23.1%; Average loss: 3.4491\n",
      "Iteration: 923; Percent complete: 23.1%; Average loss: 3.6209\n",
      "Iteration: 924; Percent complete: 23.1%; Average loss: 3.6114\n",
      "Iteration: 925; Percent complete: 23.1%; Average loss: 3.1260\n",
      "Iteration: 926; Percent complete: 23.2%; Average loss: 3.7398\n",
      "Iteration: 927; Percent complete: 23.2%; Average loss: 3.3786\n",
      "Iteration: 928; Percent complete: 23.2%; Average loss: 3.5939\n",
      "Iteration: 929; Percent complete: 23.2%; Average loss: 3.2974\n",
      "Iteration: 930; Percent complete: 23.2%; Average loss: 3.5081\n",
      "Iteration: 931; Percent complete: 23.3%; Average loss: 3.6164\n",
      "Iteration: 932; Percent complete: 23.3%; Average loss: 3.4276\n",
      "Iteration: 933; Percent complete: 23.3%; Average loss: 3.4698\n",
      "Iteration: 934; Percent complete: 23.4%; Average loss: 3.4674\n",
      "Iteration: 935; Percent complete: 23.4%; Average loss: 3.4487\n",
      "Iteration: 936; Percent complete: 23.4%; Average loss: 3.8329\n",
      "Iteration: 937; Percent complete: 23.4%; Average loss: 3.4054\n",
      "Iteration: 938; Percent complete: 23.4%; Average loss: 3.6054\n",
      "Iteration: 939; Percent complete: 23.5%; Average loss: 3.4963\n",
      "Iteration: 940; Percent complete: 23.5%; Average loss: 3.6354\n",
      "Iteration: 941; Percent complete: 23.5%; Average loss: 3.6042\n",
      "Iteration: 942; Percent complete: 23.5%; Average loss: 3.3475\n",
      "Iteration: 943; Percent complete: 23.6%; Average loss: 3.3167\n",
      "Iteration: 944; Percent complete: 23.6%; Average loss: 3.3889\n",
      "Iteration: 945; Percent complete: 23.6%; Average loss: 3.2977\n",
      "Iteration: 946; Percent complete: 23.6%; Average loss: 3.4713\n",
      "Iteration: 947; Percent complete: 23.7%; Average loss: 3.4775\n",
      "Iteration: 948; Percent complete: 23.7%; Average loss: 3.5051\n",
      "Iteration: 949; Percent complete: 23.7%; Average loss: 3.1252\n",
      "Iteration: 950; Percent complete: 23.8%; Average loss: 3.6533\n",
      "Iteration: 951; Percent complete: 23.8%; Average loss: 3.5571\n",
      "Iteration: 952; Percent complete: 23.8%; Average loss: 3.5177\n",
      "Iteration: 953; Percent complete: 23.8%; Average loss: 3.3169\n",
      "Iteration: 954; Percent complete: 23.8%; Average loss: 3.7467\n",
      "Iteration: 955; Percent complete: 23.9%; Average loss: 3.4274\n",
      "Iteration: 956; Percent complete: 23.9%; Average loss: 3.5838\n",
      "Iteration: 957; Percent complete: 23.9%; Average loss: 3.3769\n",
      "Iteration: 958; Percent complete: 23.9%; Average loss: 3.4067\n",
      "Iteration: 959; Percent complete: 24.0%; Average loss: 3.4789\n",
      "Iteration: 960; Percent complete: 24.0%; Average loss: 3.4014\n",
      "Iteration: 961; Percent complete: 24.0%; Average loss: 3.5607\n",
      "Iteration: 962; Percent complete: 24.1%; Average loss: 3.3497\n",
      "Iteration: 963; Percent complete: 24.1%; Average loss: 3.3740\n",
      "Iteration: 964; Percent complete: 24.1%; Average loss: 3.3644\n",
      "Iteration: 965; Percent complete: 24.1%; Average loss: 3.6642\n",
      "Iteration: 966; Percent complete: 24.1%; Average loss: 3.5393\n",
      "Iteration: 967; Percent complete: 24.2%; Average loss: 3.5352\n",
      "Iteration: 968; Percent complete: 24.2%; Average loss: 3.4962\n",
      "Iteration: 969; Percent complete: 24.2%; Average loss: 3.4899\n",
      "Iteration: 970; Percent complete: 24.2%; Average loss: 3.5454\n",
      "Iteration: 971; Percent complete: 24.3%; Average loss: 3.4335\n",
      "Iteration: 972; Percent complete: 24.3%; Average loss: 3.4028\n",
      "Iteration: 973; Percent complete: 24.3%; Average loss: 3.4868\n",
      "Iteration: 974; Percent complete: 24.3%; Average loss: 3.3918\n",
      "Iteration: 975; Percent complete: 24.4%; Average loss: 3.4541\n",
      "Iteration: 976; Percent complete: 24.4%; Average loss: 3.2493\n",
      "Iteration: 977; Percent complete: 24.4%; Average loss: 3.4464\n",
      "Iteration: 978; Percent complete: 24.4%; Average loss: 3.4639\n",
      "Iteration: 979; Percent complete: 24.5%; Average loss: 3.3465\n",
      "Iteration: 980; Percent complete: 24.5%; Average loss: 3.2723\n",
      "Iteration: 981; Percent complete: 24.5%; Average loss: 3.2729\n",
      "Iteration: 982; Percent complete: 24.6%; Average loss: 3.6451\n",
      "Iteration: 983; Percent complete: 24.6%; Average loss: 3.4533\n",
      "Iteration: 984; Percent complete: 24.6%; Average loss: 3.5463\n",
      "Iteration: 985; Percent complete: 24.6%; Average loss: 3.4242\n",
      "Iteration: 986; Percent complete: 24.6%; Average loss: 3.5540\n",
      "Iteration: 987; Percent complete: 24.7%; Average loss: 3.4739\n",
      "Iteration: 988; Percent complete: 24.7%; Average loss: 3.4252\n",
      "Iteration: 989; Percent complete: 24.7%; Average loss: 3.3033\n",
      "Iteration: 990; Percent complete: 24.8%; Average loss: 3.4102\n",
      "Iteration: 991; Percent complete: 24.8%; Average loss: 3.5793\n",
      "Iteration: 992; Percent complete: 24.8%; Average loss: 3.4535\n",
      "Iteration: 993; Percent complete: 24.8%; Average loss: 3.4009\n",
      "Iteration: 994; Percent complete: 24.9%; Average loss: 3.5699\n",
      "Iteration: 995; Percent complete: 24.9%; Average loss: 3.4716\n",
      "Iteration: 996; Percent complete: 24.9%; Average loss: 3.5791\n",
      "Iteration: 997; Percent complete: 24.9%; Average loss: 3.2969\n",
      "Iteration: 998; Percent complete: 24.9%; Average loss: 3.1974\n",
      "Iteration: 999; Percent complete: 25.0%; Average loss: 3.2873\n",
      "Iteration: 1000; Percent complete: 25.0%; Average loss: 3.6855\n",
      "Iteration: 1001; Percent complete: 25.0%; Average loss: 3.2325\n",
      "Iteration: 1002; Percent complete: 25.1%; Average loss: 3.5274\n",
      "Iteration: 1003; Percent complete: 25.1%; Average loss: 3.7042\n",
      "Iteration: 1004; Percent complete: 25.1%; Average loss: 3.6182\n",
      "Iteration: 1005; Percent complete: 25.1%; Average loss: 3.2686\n",
      "Iteration: 1006; Percent complete: 25.1%; Average loss: 3.2909\n",
      "Iteration: 1007; Percent complete: 25.2%; Average loss: 3.4840\n",
      "Iteration: 1008; Percent complete: 25.2%; Average loss: 3.5833\n",
      "Iteration: 1009; Percent complete: 25.2%; Average loss: 3.4722\n",
      "Iteration: 1010; Percent complete: 25.2%; Average loss: 3.4814\n",
      "Iteration: 1011; Percent complete: 25.3%; Average loss: 3.6635\n",
      "Iteration: 1012; Percent complete: 25.3%; Average loss: 3.6570\n",
      "Iteration: 1013; Percent complete: 25.3%; Average loss: 3.3822\n",
      "Iteration: 1014; Percent complete: 25.4%; Average loss: 3.4184\n",
      "Iteration: 1015; Percent complete: 25.4%; Average loss: 3.5297\n",
      "Iteration: 1016; Percent complete: 25.4%; Average loss: 3.0870\n",
      "Iteration: 1017; Percent complete: 25.4%; Average loss: 3.4151\n",
      "Iteration: 1018; Percent complete: 25.4%; Average loss: 3.1984\n",
      "Iteration: 1019; Percent complete: 25.5%; Average loss: 3.5597\n",
      "Iteration: 1020; Percent complete: 25.5%; Average loss: 3.5073\n",
      "Iteration: 1021; Percent complete: 25.5%; Average loss: 3.4539\n",
      "Iteration: 1022; Percent complete: 25.6%; Average loss: 3.4809\n",
      "Iteration: 1023; Percent complete: 25.6%; Average loss: 3.3777\n",
      "Iteration: 1024; Percent complete: 25.6%; Average loss: 3.7249\n",
      "Iteration: 1025; Percent complete: 25.6%; Average loss: 3.4981\n",
      "Iteration: 1026; Percent complete: 25.7%; Average loss: 3.4003\n",
      "Iteration: 1027; Percent complete: 25.7%; Average loss: 3.2648\n",
      "Iteration: 1028; Percent complete: 25.7%; Average loss: 3.5892\n",
      "Iteration: 1029; Percent complete: 25.7%; Average loss: 3.6561\n",
      "Iteration: 1030; Percent complete: 25.8%; Average loss: 3.2470\n",
      "Iteration: 1031; Percent complete: 25.8%; Average loss: 3.3200\n",
      "Iteration: 1032; Percent complete: 25.8%; Average loss: 3.5689\n",
      "Iteration: 1033; Percent complete: 25.8%; Average loss: 3.3992\n",
      "Iteration: 1034; Percent complete: 25.9%; Average loss: 3.5077\n",
      "Iteration: 1035; Percent complete: 25.9%; Average loss: 3.3738\n",
      "Iteration: 1036; Percent complete: 25.9%; Average loss: 3.5188\n",
      "Iteration: 1037; Percent complete: 25.9%; Average loss: 3.3653\n",
      "Iteration: 1038; Percent complete: 25.9%; Average loss: 3.3464\n",
      "Iteration: 1039; Percent complete: 26.0%; Average loss: 3.4738\n",
      "Iteration: 1040; Percent complete: 26.0%; Average loss: 3.3141\n",
      "Iteration: 1041; Percent complete: 26.0%; Average loss: 3.3878\n",
      "Iteration: 1042; Percent complete: 26.1%; Average loss: 3.4279\n",
      "Iteration: 1043; Percent complete: 26.1%; Average loss: 3.4310\n",
      "Iteration: 1044; Percent complete: 26.1%; Average loss: 3.3725\n",
      "Iteration: 1045; Percent complete: 26.1%; Average loss: 3.8419\n",
      "Iteration: 1046; Percent complete: 26.2%; Average loss: 3.3358\n",
      "Iteration: 1047; Percent complete: 26.2%; Average loss: 3.6724\n",
      "Iteration: 1048; Percent complete: 26.2%; Average loss: 3.3505\n",
      "Iteration: 1049; Percent complete: 26.2%; Average loss: 3.2956\n",
      "Iteration: 1050; Percent complete: 26.2%; Average loss: 3.2860\n",
      "Iteration: 1051; Percent complete: 26.3%; Average loss: 3.4088\n",
      "Iteration: 1052; Percent complete: 26.3%; Average loss: 3.6164\n",
      "Iteration: 1053; Percent complete: 26.3%; Average loss: 3.7105\n",
      "Iteration: 1054; Percent complete: 26.4%; Average loss: 3.6051\n",
      "Iteration: 1055; Percent complete: 26.4%; Average loss: 3.3170\n",
      "Iteration: 1056; Percent complete: 26.4%; Average loss: 3.4801\n",
      "Iteration: 1057; Percent complete: 26.4%; Average loss: 3.4772\n",
      "Iteration: 1058; Percent complete: 26.5%; Average loss: 3.3950\n",
      "Iteration: 1059; Percent complete: 26.5%; Average loss: 3.1410\n",
      "Iteration: 1060; Percent complete: 26.5%; Average loss: 3.4419\n",
      "Iteration: 1061; Percent complete: 26.5%; Average loss: 3.6071\n",
      "Iteration: 1062; Percent complete: 26.6%; Average loss: 3.4191\n",
      "Iteration: 1063; Percent complete: 26.6%; Average loss: 3.4889\n",
      "Iteration: 1064; Percent complete: 26.6%; Average loss: 3.7739\n",
      "Iteration: 1065; Percent complete: 26.6%; Average loss: 3.5487\n",
      "Iteration: 1066; Percent complete: 26.7%; Average loss: 3.4202\n",
      "Iteration: 1067; Percent complete: 26.7%; Average loss: 3.6634\n",
      "Iteration: 1068; Percent complete: 26.7%; Average loss: 3.2873\n",
      "Iteration: 1069; Percent complete: 26.7%; Average loss: 3.5069\n",
      "Iteration: 1070; Percent complete: 26.8%; Average loss: 3.2480\n",
      "Iteration: 1071; Percent complete: 26.8%; Average loss: 3.4556\n",
      "Iteration: 1072; Percent complete: 26.8%; Average loss: 3.5446\n",
      "Iteration: 1073; Percent complete: 26.8%; Average loss: 3.5157\n",
      "Iteration: 1074; Percent complete: 26.9%; Average loss: 3.4550\n",
      "Iteration: 1075; Percent complete: 26.9%; Average loss: 3.5131\n",
      "Iteration: 1076; Percent complete: 26.9%; Average loss: 3.4119\n",
      "Iteration: 1077; Percent complete: 26.9%; Average loss: 3.4230\n",
      "Iteration: 1078; Percent complete: 27.0%; Average loss: 3.5849\n",
      "Iteration: 1079; Percent complete: 27.0%; Average loss: 3.1230\n",
      "Iteration: 1080; Percent complete: 27.0%; Average loss: 3.1496\n",
      "Iteration: 1081; Percent complete: 27.0%; Average loss: 3.3635\n",
      "Iteration: 1082; Percent complete: 27.1%; Average loss: 3.7272\n",
      "Iteration: 1083; Percent complete: 27.1%; Average loss: 3.2388\n",
      "Iteration: 1084; Percent complete: 27.1%; Average loss: 3.5667\n",
      "Iteration: 1085; Percent complete: 27.1%; Average loss: 3.3594\n",
      "Iteration: 1086; Percent complete: 27.2%; Average loss: 3.3956\n",
      "Iteration: 1087; Percent complete: 27.2%; Average loss: 3.1149\n",
      "Iteration: 1088; Percent complete: 27.2%; Average loss: 3.3598\n",
      "Iteration: 1089; Percent complete: 27.2%; Average loss: 3.8926\n",
      "Iteration: 1090; Percent complete: 27.3%; Average loss: 3.7141\n",
      "Iteration: 1091; Percent complete: 27.3%; Average loss: 3.6096\n",
      "Iteration: 1092; Percent complete: 27.3%; Average loss: 3.4429\n",
      "Iteration: 1093; Percent complete: 27.3%; Average loss: 3.6357\n",
      "Iteration: 1094; Percent complete: 27.4%; Average loss: 3.3907\n",
      "Iteration: 1095; Percent complete: 27.4%; Average loss: 3.3197\n",
      "Iteration: 1096; Percent complete: 27.4%; Average loss: 3.1119\n",
      "Iteration: 1097; Percent complete: 27.4%; Average loss: 3.0901\n",
      "Iteration: 1098; Percent complete: 27.5%; Average loss: 3.5611\n",
      "Iteration: 1099; Percent complete: 27.5%; Average loss: 3.7190\n",
      "Iteration: 1100; Percent complete: 27.5%; Average loss: 3.6275\n",
      "Iteration: 1101; Percent complete: 27.5%; Average loss: 3.5717\n",
      "Iteration: 1102; Percent complete: 27.6%; Average loss: 3.1786\n",
      "Iteration: 1103; Percent complete: 27.6%; Average loss: 3.7171\n",
      "Iteration: 1104; Percent complete: 27.6%; Average loss: 3.3975\n",
      "Iteration: 1105; Percent complete: 27.6%; Average loss: 3.4284\n",
      "Iteration: 1106; Percent complete: 27.7%; Average loss: 3.2208\n",
      "Iteration: 1107; Percent complete: 27.7%; Average loss: 3.5802\n",
      "Iteration: 1108; Percent complete: 27.7%; Average loss: 3.2912\n",
      "Iteration: 1109; Percent complete: 27.7%; Average loss: 3.5566\n",
      "Iteration: 1110; Percent complete: 27.8%; Average loss: 3.1842\n",
      "Iteration: 1111; Percent complete: 27.8%; Average loss: 3.5535\n",
      "Iteration: 1112; Percent complete: 27.8%; Average loss: 3.2853\n",
      "Iteration: 1113; Percent complete: 27.8%; Average loss: 3.5890\n",
      "Iteration: 1114; Percent complete: 27.9%; Average loss: 3.2193\n",
      "Iteration: 1115; Percent complete: 27.9%; Average loss: 3.2593\n",
      "Iteration: 1116; Percent complete: 27.9%; Average loss: 3.5051\n",
      "Iteration: 1117; Percent complete: 27.9%; Average loss: 3.3173\n",
      "Iteration: 1118; Percent complete: 28.0%; Average loss: 3.3634\n",
      "Iteration: 1119; Percent complete: 28.0%; Average loss: 3.4383\n",
      "Iteration: 1120; Percent complete: 28.0%; Average loss: 3.2621\n",
      "Iteration: 1121; Percent complete: 28.0%; Average loss: 3.2845\n",
      "Iteration: 1122; Percent complete: 28.1%; Average loss: 3.3336\n",
      "Iteration: 1123; Percent complete: 28.1%; Average loss: 3.2216\n",
      "Iteration: 1124; Percent complete: 28.1%; Average loss: 3.2762\n",
      "Iteration: 1125; Percent complete: 28.1%; Average loss: 3.5245\n",
      "Iteration: 1126; Percent complete: 28.1%; Average loss: 3.1087\n",
      "Iteration: 1127; Percent complete: 28.2%; Average loss: 3.6523\n",
      "Iteration: 1128; Percent complete: 28.2%; Average loss: 3.3426\n",
      "Iteration: 1129; Percent complete: 28.2%; Average loss: 3.3690\n",
      "Iteration: 1130; Percent complete: 28.2%; Average loss: 3.4334\n",
      "Iteration: 1131; Percent complete: 28.3%; Average loss: 3.2746\n",
      "Iteration: 1132; Percent complete: 28.3%; Average loss: 3.5091\n",
      "Iteration: 1133; Percent complete: 28.3%; Average loss: 3.5834\n",
      "Iteration: 1134; Percent complete: 28.3%; Average loss: 3.2084\n",
      "Iteration: 1135; Percent complete: 28.4%; Average loss: 3.5185\n",
      "Iteration: 1136; Percent complete: 28.4%; Average loss: 3.4850\n",
      "Iteration: 1137; Percent complete: 28.4%; Average loss: 3.1962\n",
      "Iteration: 1138; Percent complete: 28.4%; Average loss: 3.4021\n",
      "Iteration: 1139; Percent complete: 28.5%; Average loss: 3.6018\n",
      "Iteration: 1140; Percent complete: 28.5%; Average loss: 3.5646\n",
      "Iteration: 1141; Percent complete: 28.5%; Average loss: 3.2766\n",
      "Iteration: 1142; Percent complete: 28.5%; Average loss: 3.3545\n",
      "Iteration: 1143; Percent complete: 28.6%; Average loss: 3.2054\n",
      "Iteration: 1144; Percent complete: 28.6%; Average loss: 3.5684\n",
      "Iteration: 1145; Percent complete: 28.6%; Average loss: 3.3730\n",
      "Iteration: 1146; Percent complete: 28.6%; Average loss: 3.3580\n",
      "Iteration: 1147; Percent complete: 28.7%; Average loss: 3.5411\n",
      "Iteration: 1148; Percent complete: 28.7%; Average loss: 3.5103\n",
      "Iteration: 1149; Percent complete: 28.7%; Average loss: 3.5753\n",
      "Iteration: 1150; Percent complete: 28.7%; Average loss: 3.2917\n",
      "Iteration: 1151; Percent complete: 28.8%; Average loss: 3.3203\n",
      "Iteration: 1152; Percent complete: 28.8%; Average loss: 3.2972\n",
      "Iteration: 1153; Percent complete: 28.8%; Average loss: 3.4172\n",
      "Iteration: 1154; Percent complete: 28.8%; Average loss: 3.3854\n",
      "Iteration: 1155; Percent complete: 28.9%; Average loss: 3.6790\n",
      "Iteration: 1156; Percent complete: 28.9%; Average loss: 3.6520\n",
      "Iteration: 1157; Percent complete: 28.9%; Average loss: 3.5157\n",
      "Iteration: 1158; Percent complete: 28.9%; Average loss: 3.1978\n",
      "Iteration: 1159; Percent complete: 29.0%; Average loss: 3.3821\n",
      "Iteration: 1160; Percent complete: 29.0%; Average loss: 3.7369\n",
      "Iteration: 1161; Percent complete: 29.0%; Average loss: 3.2006\n",
      "Iteration: 1162; Percent complete: 29.0%; Average loss: 3.1708\n",
      "Iteration: 1163; Percent complete: 29.1%; Average loss: 3.4499\n",
      "Iteration: 1164; Percent complete: 29.1%; Average loss: 3.3072\n",
      "Iteration: 1165; Percent complete: 29.1%; Average loss: 3.4391\n",
      "Iteration: 1166; Percent complete: 29.1%; Average loss: 3.4102\n",
      "Iteration: 1167; Percent complete: 29.2%; Average loss: 3.5171\n",
      "Iteration: 1168; Percent complete: 29.2%; Average loss: 3.2941\n",
      "Iteration: 1169; Percent complete: 29.2%; Average loss: 3.4647\n",
      "Iteration: 1170; Percent complete: 29.2%; Average loss: 3.4245\n",
      "Iteration: 1171; Percent complete: 29.3%; Average loss: 3.4860\n",
      "Iteration: 1172; Percent complete: 29.3%; Average loss: 3.2974\n",
      "Iteration: 1173; Percent complete: 29.3%; Average loss: 3.3110\n",
      "Iteration: 1174; Percent complete: 29.3%; Average loss: 3.2935\n",
      "Iteration: 1175; Percent complete: 29.4%; Average loss: 3.6118\n",
      "Iteration: 1176; Percent complete: 29.4%; Average loss: 3.3962\n",
      "Iteration: 1177; Percent complete: 29.4%; Average loss: 3.3924\n",
      "Iteration: 1178; Percent complete: 29.4%; Average loss: 3.3507\n",
      "Iteration: 1179; Percent complete: 29.5%; Average loss: 3.5898\n",
      "Iteration: 1180; Percent complete: 29.5%; Average loss: 3.5854\n",
      "Iteration: 1181; Percent complete: 29.5%; Average loss: 3.2520\n",
      "Iteration: 1182; Percent complete: 29.5%; Average loss: 3.3434\n",
      "Iteration: 1183; Percent complete: 29.6%; Average loss: 3.3307\n",
      "Iteration: 1184; Percent complete: 29.6%; Average loss: 3.2823\n",
      "Iteration: 1185; Percent complete: 29.6%; Average loss: 3.4077\n",
      "Iteration: 1186; Percent complete: 29.6%; Average loss: 3.2617\n",
      "Iteration: 1187; Percent complete: 29.7%; Average loss: 3.3286\n",
      "Iteration: 1188; Percent complete: 29.7%; Average loss: 3.6794\n",
      "Iteration: 1189; Percent complete: 29.7%; Average loss: 3.3547\n",
      "Iteration: 1190; Percent complete: 29.8%; Average loss: 3.4249\n",
      "Iteration: 1191; Percent complete: 29.8%; Average loss: 3.3854\n",
      "Iteration: 1192; Percent complete: 29.8%; Average loss: 3.2782\n",
      "Iteration: 1193; Percent complete: 29.8%; Average loss: 3.2950\n",
      "Iteration: 1194; Percent complete: 29.8%; Average loss: 3.3090\n",
      "Iteration: 1195; Percent complete: 29.9%; Average loss: 3.3662\n",
      "Iteration: 1196; Percent complete: 29.9%; Average loss: 3.5265\n",
      "Iteration: 1197; Percent complete: 29.9%; Average loss: 3.3203\n",
      "Iteration: 1198; Percent complete: 29.9%; Average loss: 3.2653\n",
      "Iteration: 1199; Percent complete: 30.0%; Average loss: 3.3040\n",
      "Iteration: 1200; Percent complete: 30.0%; Average loss: 3.4843\n",
      "Iteration: 1201; Percent complete: 30.0%; Average loss: 3.5059\n",
      "Iteration: 1202; Percent complete: 30.0%; Average loss: 3.2906\n",
      "Iteration: 1203; Percent complete: 30.1%; Average loss: 3.5463\n",
      "Iteration: 1204; Percent complete: 30.1%; Average loss: 3.6588\n",
      "Iteration: 1205; Percent complete: 30.1%; Average loss: 3.2958\n",
      "Iteration: 1206; Percent complete: 30.1%; Average loss: 3.4777\n",
      "Iteration: 1207; Percent complete: 30.2%; Average loss: 3.2783\n",
      "Iteration: 1208; Percent complete: 30.2%; Average loss: 3.4041\n",
      "Iteration: 1209; Percent complete: 30.2%; Average loss: 3.3784\n",
      "Iteration: 1210; Percent complete: 30.2%; Average loss: 3.4538\n",
      "Iteration: 1211; Percent complete: 30.3%; Average loss: 3.2769\n",
      "Iteration: 1212; Percent complete: 30.3%; Average loss: 3.4682\n",
      "Iteration: 1213; Percent complete: 30.3%; Average loss: 3.1071\n",
      "Iteration: 1214; Percent complete: 30.3%; Average loss: 3.4931\n",
      "Iteration: 1215; Percent complete: 30.4%; Average loss: 3.5234\n",
      "Iteration: 1216; Percent complete: 30.4%; Average loss: 3.3680\n",
      "Iteration: 1217; Percent complete: 30.4%; Average loss: 3.3327\n",
      "Iteration: 1218; Percent complete: 30.4%; Average loss: 3.4088\n",
      "Iteration: 1219; Percent complete: 30.5%; Average loss: 3.6000\n",
      "Iteration: 1220; Percent complete: 30.5%; Average loss: 3.5628\n",
      "Iteration: 1221; Percent complete: 30.5%; Average loss: 3.2329\n",
      "Iteration: 1222; Percent complete: 30.6%; Average loss: 3.4396\n",
      "Iteration: 1223; Percent complete: 30.6%; Average loss: 3.3859\n",
      "Iteration: 1224; Percent complete: 30.6%; Average loss: 3.2597\n",
      "Iteration: 1225; Percent complete: 30.6%; Average loss: 3.2235\n",
      "Iteration: 1226; Percent complete: 30.6%; Average loss: 3.5944\n",
      "Iteration: 1227; Percent complete: 30.7%; Average loss: 3.2327\n",
      "Iteration: 1228; Percent complete: 30.7%; Average loss: 3.2696\n",
      "Iteration: 1229; Percent complete: 30.7%; Average loss: 3.1657\n",
      "Iteration: 1230; Percent complete: 30.8%; Average loss: 3.4409\n",
      "Iteration: 1231; Percent complete: 30.8%; Average loss: 3.2590\n",
      "Iteration: 1232; Percent complete: 30.8%; Average loss: 3.5405\n",
      "Iteration: 1233; Percent complete: 30.8%; Average loss: 3.4164\n",
      "Iteration: 1234; Percent complete: 30.9%; Average loss: 3.2695\n",
      "Iteration: 1235; Percent complete: 30.9%; Average loss: 3.2286\n",
      "Iteration: 1236; Percent complete: 30.9%; Average loss: 3.3534\n",
      "Iteration: 1237; Percent complete: 30.9%; Average loss: 3.5711\n",
      "Iteration: 1238; Percent complete: 30.9%; Average loss: 3.4164\n",
      "Iteration: 1239; Percent complete: 31.0%; Average loss: 3.3308\n",
      "Iteration: 1240; Percent complete: 31.0%; Average loss: 3.4876\n",
      "Iteration: 1241; Percent complete: 31.0%; Average loss: 3.5128\n",
      "Iteration: 1242; Percent complete: 31.1%; Average loss: 3.4155\n",
      "Iteration: 1243; Percent complete: 31.1%; Average loss: 3.3458\n",
      "Iteration: 1244; Percent complete: 31.1%; Average loss: 3.5423\n",
      "Iteration: 1245; Percent complete: 31.1%; Average loss: 3.4959\n",
      "Iteration: 1246; Percent complete: 31.1%; Average loss: 3.2350\n",
      "Iteration: 1247; Percent complete: 31.2%; Average loss: 3.1694\n",
      "Iteration: 1248; Percent complete: 31.2%; Average loss: 3.4860\n",
      "Iteration: 1249; Percent complete: 31.2%; Average loss: 3.3868\n",
      "Iteration: 1250; Percent complete: 31.2%; Average loss: 3.3078\n",
      "Iteration: 1251; Percent complete: 31.3%; Average loss: 3.6386\n",
      "Iteration: 1252; Percent complete: 31.3%; Average loss: 3.5785\n",
      "Iteration: 1253; Percent complete: 31.3%; Average loss: 3.7612\n",
      "Iteration: 1254; Percent complete: 31.4%; Average loss: 3.2868\n",
      "Iteration: 1255; Percent complete: 31.4%; Average loss: 3.4709\n",
      "Iteration: 1256; Percent complete: 31.4%; Average loss: 3.3390\n",
      "Iteration: 1257; Percent complete: 31.4%; Average loss: 3.4660\n",
      "Iteration: 1258; Percent complete: 31.4%; Average loss: 3.2997\n",
      "Iteration: 1259; Percent complete: 31.5%; Average loss: 3.2849\n",
      "Iteration: 1260; Percent complete: 31.5%; Average loss: 3.2408\n",
      "Iteration: 1261; Percent complete: 31.5%; Average loss: 3.3716\n",
      "Iteration: 1262; Percent complete: 31.6%; Average loss: 3.4106\n",
      "Iteration: 1263; Percent complete: 31.6%; Average loss: 3.3841\n",
      "Iteration: 1264; Percent complete: 31.6%; Average loss: 3.4994\n",
      "Iteration: 1265; Percent complete: 31.6%; Average loss: 3.5058\n",
      "Iteration: 1266; Percent complete: 31.6%; Average loss: 3.2695\n",
      "Iteration: 1267; Percent complete: 31.7%; Average loss: 3.2332\n",
      "Iteration: 1268; Percent complete: 31.7%; Average loss: 3.5514\n",
      "Iteration: 1269; Percent complete: 31.7%; Average loss: 3.3619\n",
      "Iteration: 1270; Percent complete: 31.8%; Average loss: 3.3013\n",
      "Iteration: 1271; Percent complete: 31.8%; Average loss: 3.5951\n",
      "Iteration: 1272; Percent complete: 31.8%; Average loss: 3.5497\n",
      "Iteration: 1273; Percent complete: 31.8%; Average loss: 3.4859\n",
      "Iteration: 1274; Percent complete: 31.9%; Average loss: 3.2828\n",
      "Iteration: 1275; Percent complete: 31.9%; Average loss: 3.5645\n",
      "Iteration: 1276; Percent complete: 31.9%; Average loss: 3.4103\n",
      "Iteration: 1277; Percent complete: 31.9%; Average loss: 3.3707\n",
      "Iteration: 1278; Percent complete: 31.9%; Average loss: 3.4423\n",
      "Iteration: 1279; Percent complete: 32.0%; Average loss: 3.3864\n",
      "Iteration: 1280; Percent complete: 32.0%; Average loss: 3.4208\n",
      "Iteration: 1281; Percent complete: 32.0%; Average loss: 3.6646\n",
      "Iteration: 1282; Percent complete: 32.0%; Average loss: 3.5360\n",
      "Iteration: 1283; Percent complete: 32.1%; Average loss: 3.3565\n",
      "Iteration: 1284; Percent complete: 32.1%; Average loss: 3.2624\n",
      "Iteration: 1285; Percent complete: 32.1%; Average loss: 3.1663\n",
      "Iteration: 1286; Percent complete: 32.1%; Average loss: 3.4615\n",
      "Iteration: 1287; Percent complete: 32.2%; Average loss: 3.4985\n",
      "Iteration: 1288; Percent complete: 32.2%; Average loss: 3.3606\n",
      "Iteration: 1289; Percent complete: 32.2%; Average loss: 3.2504\n",
      "Iteration: 1290; Percent complete: 32.2%; Average loss: 3.1189\n",
      "Iteration: 1291; Percent complete: 32.3%; Average loss: 3.1394\n",
      "Iteration: 1292; Percent complete: 32.3%; Average loss: 3.5708\n",
      "Iteration: 1293; Percent complete: 32.3%; Average loss: 3.3905\n",
      "Iteration: 1294; Percent complete: 32.4%; Average loss: 3.6477\n",
      "Iteration: 1295; Percent complete: 32.4%; Average loss: 3.3037\n",
      "Iteration: 1296; Percent complete: 32.4%; Average loss: 3.5348\n",
      "Iteration: 1297; Percent complete: 32.4%; Average loss: 3.2369\n",
      "Iteration: 1298; Percent complete: 32.5%; Average loss: 3.2639\n",
      "Iteration: 1299; Percent complete: 32.5%; Average loss: 3.3452\n",
      "Iteration: 1300; Percent complete: 32.5%; Average loss: 3.1631\n",
      "Iteration: 1301; Percent complete: 32.5%; Average loss: 3.3955\n",
      "Iteration: 1302; Percent complete: 32.6%; Average loss: 3.2996\n",
      "Iteration: 1303; Percent complete: 32.6%; Average loss: 3.3941\n",
      "Iteration: 1304; Percent complete: 32.6%; Average loss: 3.4682\n",
      "Iteration: 1305; Percent complete: 32.6%; Average loss: 3.2827\n",
      "Iteration: 1306; Percent complete: 32.6%; Average loss: 3.4269\n",
      "Iteration: 1307; Percent complete: 32.7%; Average loss: 3.5330\n",
      "Iteration: 1308; Percent complete: 32.7%; Average loss: 3.3512\n",
      "Iteration: 1309; Percent complete: 32.7%; Average loss: 3.1152\n",
      "Iteration: 1310; Percent complete: 32.8%; Average loss: 3.3459\n",
      "Iteration: 1311; Percent complete: 32.8%; Average loss: 3.4356\n",
      "Iteration: 1312; Percent complete: 32.8%; Average loss: 3.5147\n",
      "Iteration: 1313; Percent complete: 32.8%; Average loss: 3.3596\n",
      "Iteration: 1314; Percent complete: 32.9%; Average loss: 3.5494\n",
      "Iteration: 1315; Percent complete: 32.9%; Average loss: 3.2821\n",
      "Iteration: 1316; Percent complete: 32.9%; Average loss: 3.3712\n",
      "Iteration: 1317; Percent complete: 32.9%; Average loss: 3.5842\n",
      "Iteration: 1318; Percent complete: 33.0%; Average loss: 3.3862\n",
      "Iteration: 1319; Percent complete: 33.0%; Average loss: 3.5419\n",
      "Iteration: 1320; Percent complete: 33.0%; Average loss: 3.3121\n",
      "Iteration: 1321; Percent complete: 33.0%; Average loss: 3.4419\n",
      "Iteration: 1322; Percent complete: 33.1%; Average loss: 3.3700\n",
      "Iteration: 1323; Percent complete: 33.1%; Average loss: 3.2580\n",
      "Iteration: 1324; Percent complete: 33.1%; Average loss: 3.2560\n",
      "Iteration: 1325; Percent complete: 33.1%; Average loss: 3.1759\n",
      "Iteration: 1326; Percent complete: 33.1%; Average loss: 3.3677\n",
      "Iteration: 1327; Percent complete: 33.2%; Average loss: 3.4352\n",
      "Iteration: 1328; Percent complete: 33.2%; Average loss: 3.1544\n",
      "Iteration: 1329; Percent complete: 33.2%; Average loss: 3.2133\n",
      "Iteration: 1330; Percent complete: 33.2%; Average loss: 3.1968\n",
      "Iteration: 1331; Percent complete: 33.3%; Average loss: 3.1073\n",
      "Iteration: 1332; Percent complete: 33.3%; Average loss: 3.3342\n",
      "Iteration: 1333; Percent complete: 33.3%; Average loss: 3.3237\n",
      "Iteration: 1334; Percent complete: 33.4%; Average loss: 3.5931\n",
      "Iteration: 1335; Percent complete: 33.4%; Average loss: 3.5538\n",
      "Iteration: 1336; Percent complete: 33.4%; Average loss: 3.4758\n",
      "Iteration: 1337; Percent complete: 33.4%; Average loss: 3.2387\n",
      "Iteration: 1338; Percent complete: 33.5%; Average loss: 3.1353\n",
      "Iteration: 1339; Percent complete: 33.5%; Average loss: 3.3341\n",
      "Iteration: 1340; Percent complete: 33.5%; Average loss: 3.4654\n",
      "Iteration: 1341; Percent complete: 33.5%; Average loss: 3.1349\n",
      "Iteration: 1342; Percent complete: 33.6%; Average loss: 3.2993\n",
      "Iteration: 1343; Percent complete: 33.6%; Average loss: 3.1209\n",
      "Iteration: 1344; Percent complete: 33.6%; Average loss: 3.3624\n",
      "Iteration: 1345; Percent complete: 33.6%; Average loss: 3.3508\n",
      "Iteration: 1346; Percent complete: 33.7%; Average loss: 3.0245\n",
      "Iteration: 1347; Percent complete: 33.7%; Average loss: 3.3446\n",
      "Iteration: 1348; Percent complete: 33.7%; Average loss: 3.4064\n",
      "Iteration: 1349; Percent complete: 33.7%; Average loss: 3.3198\n",
      "Iteration: 1350; Percent complete: 33.8%; Average loss: 3.4660\n",
      "Iteration: 1351; Percent complete: 33.8%; Average loss: 3.1197\n",
      "Iteration: 1352; Percent complete: 33.8%; Average loss: 3.4816\n",
      "Iteration: 1353; Percent complete: 33.8%; Average loss: 3.4092\n",
      "Iteration: 1354; Percent complete: 33.9%; Average loss: 3.1850\n",
      "Iteration: 1355; Percent complete: 33.9%; Average loss: 3.3011\n",
      "Iteration: 1356; Percent complete: 33.9%; Average loss: 3.3445\n",
      "Iteration: 1357; Percent complete: 33.9%; Average loss: 3.5676\n",
      "Iteration: 1358; Percent complete: 34.0%; Average loss: 3.3175\n",
      "Iteration: 1359; Percent complete: 34.0%; Average loss: 3.5758\n",
      "Iteration: 1360; Percent complete: 34.0%; Average loss: 3.0686\n",
      "Iteration: 1361; Percent complete: 34.0%; Average loss: 3.1018\n",
      "Iteration: 1362; Percent complete: 34.1%; Average loss: 3.4027\n",
      "Iteration: 1363; Percent complete: 34.1%; Average loss: 3.4235\n",
      "Iteration: 1364; Percent complete: 34.1%; Average loss: 3.2070\n",
      "Iteration: 1365; Percent complete: 34.1%; Average loss: 3.4107\n",
      "Iteration: 1366; Percent complete: 34.2%; Average loss: 3.2742\n",
      "Iteration: 1367; Percent complete: 34.2%; Average loss: 3.3266\n",
      "Iteration: 1368; Percent complete: 34.2%; Average loss: 3.4072\n",
      "Iteration: 1369; Percent complete: 34.2%; Average loss: 3.4958\n",
      "Iteration: 1370; Percent complete: 34.2%; Average loss: 3.2853\n",
      "Iteration: 1371; Percent complete: 34.3%; Average loss: 3.5436\n",
      "Iteration: 1372; Percent complete: 34.3%; Average loss: 3.5354\n",
      "Iteration: 1373; Percent complete: 34.3%; Average loss: 3.2952\n",
      "Iteration: 1374; Percent complete: 34.4%; Average loss: 3.4385\n",
      "Iteration: 1375; Percent complete: 34.4%; Average loss: 3.3569\n",
      "Iteration: 1376; Percent complete: 34.4%; Average loss: 3.0008\n",
      "Iteration: 1377; Percent complete: 34.4%; Average loss: 3.8009\n",
      "Iteration: 1378; Percent complete: 34.4%; Average loss: 3.3266\n",
      "Iteration: 1379; Percent complete: 34.5%; Average loss: 3.1768\n",
      "Iteration: 1380; Percent complete: 34.5%; Average loss: 3.5706\n",
      "Iteration: 1381; Percent complete: 34.5%; Average loss: 3.4232\n",
      "Iteration: 1382; Percent complete: 34.5%; Average loss: 3.5156\n",
      "Iteration: 1383; Percent complete: 34.6%; Average loss: 3.4124\n",
      "Iteration: 1384; Percent complete: 34.6%; Average loss: 3.2435\n",
      "Iteration: 1385; Percent complete: 34.6%; Average loss: 3.3121\n",
      "Iteration: 1386; Percent complete: 34.6%; Average loss: 3.4889\n",
      "Iteration: 1387; Percent complete: 34.7%; Average loss: 3.3456\n",
      "Iteration: 1388; Percent complete: 34.7%; Average loss: 3.4371\n",
      "Iteration: 1389; Percent complete: 34.7%; Average loss: 3.3818\n",
      "Iteration: 1390; Percent complete: 34.8%; Average loss: 3.4394\n",
      "Iteration: 1391; Percent complete: 34.8%; Average loss: 3.1665\n",
      "Iteration: 1392; Percent complete: 34.8%; Average loss: 3.4033\n",
      "Iteration: 1393; Percent complete: 34.8%; Average loss: 3.5298\n",
      "Iteration: 1394; Percent complete: 34.8%; Average loss: 3.2085\n",
      "Iteration: 1395; Percent complete: 34.9%; Average loss: 3.0194\n",
      "Iteration: 1396; Percent complete: 34.9%; Average loss: 3.3512\n",
      "Iteration: 1397; Percent complete: 34.9%; Average loss: 3.3296\n",
      "Iteration: 1398; Percent complete: 34.9%; Average loss: 3.0238\n",
      "Iteration: 1399; Percent complete: 35.0%; Average loss: 3.1455\n",
      "Iteration: 1400; Percent complete: 35.0%; Average loss: 2.9905\n",
      "Iteration: 1401; Percent complete: 35.0%; Average loss: 3.1701\n",
      "Iteration: 1402; Percent complete: 35.0%; Average loss: 3.4527\n",
      "Iteration: 1403; Percent complete: 35.1%; Average loss: 3.2137\n",
      "Iteration: 1404; Percent complete: 35.1%; Average loss: 3.1841\n",
      "Iteration: 1405; Percent complete: 35.1%; Average loss: 3.2687\n",
      "Iteration: 1406; Percent complete: 35.1%; Average loss: 3.4170\n",
      "Iteration: 1407; Percent complete: 35.2%; Average loss: 3.2435\n",
      "Iteration: 1408; Percent complete: 35.2%; Average loss: 3.5382\n",
      "Iteration: 1409; Percent complete: 35.2%; Average loss: 3.2707\n",
      "Iteration: 1410; Percent complete: 35.2%; Average loss: 3.4647\n",
      "Iteration: 1411; Percent complete: 35.3%; Average loss: 3.3420\n",
      "Iteration: 1412; Percent complete: 35.3%; Average loss: 3.1993\n",
      "Iteration: 1413; Percent complete: 35.3%; Average loss: 3.5202\n",
      "Iteration: 1414; Percent complete: 35.4%; Average loss: 3.2845\n",
      "Iteration: 1415; Percent complete: 35.4%; Average loss: 3.2461\n",
      "Iteration: 1416; Percent complete: 35.4%; Average loss: 3.3519\n",
      "Iteration: 1417; Percent complete: 35.4%; Average loss: 3.3718\n",
      "Iteration: 1418; Percent complete: 35.4%; Average loss: 3.4330\n",
      "Iteration: 1419; Percent complete: 35.5%; Average loss: 3.4659\n",
      "Iteration: 1420; Percent complete: 35.5%; Average loss: 3.4026\n",
      "Iteration: 1421; Percent complete: 35.5%; Average loss: 3.2468\n",
      "Iteration: 1422; Percent complete: 35.5%; Average loss: 3.3979\n",
      "Iteration: 1423; Percent complete: 35.6%; Average loss: 3.1711\n",
      "Iteration: 1424; Percent complete: 35.6%; Average loss: 3.4085\n",
      "Iteration: 1425; Percent complete: 35.6%; Average loss: 3.2346\n",
      "Iteration: 1426; Percent complete: 35.6%; Average loss: 3.3699\n",
      "Iteration: 1427; Percent complete: 35.7%; Average loss: 3.3563\n",
      "Iteration: 1428; Percent complete: 35.7%; Average loss: 3.4010\n",
      "Iteration: 1429; Percent complete: 35.7%; Average loss: 3.3687\n",
      "Iteration: 1430; Percent complete: 35.8%; Average loss: 3.1894\n",
      "Iteration: 1431; Percent complete: 35.8%; Average loss: 3.4224\n",
      "Iteration: 1432; Percent complete: 35.8%; Average loss: 3.1035\n",
      "Iteration: 1433; Percent complete: 35.8%; Average loss: 3.2205\n",
      "Iteration: 1434; Percent complete: 35.9%; Average loss: 3.0578\n",
      "Iteration: 1435; Percent complete: 35.9%; Average loss: 3.3864\n",
      "Iteration: 1436; Percent complete: 35.9%; Average loss: 3.4729\n",
      "Iteration: 1437; Percent complete: 35.9%; Average loss: 3.4461\n",
      "Iteration: 1438; Percent complete: 35.9%; Average loss: 3.3293\n",
      "Iteration: 1439; Percent complete: 36.0%; Average loss: 3.2806\n",
      "Iteration: 1440; Percent complete: 36.0%; Average loss: 3.2169\n",
      "Iteration: 1441; Percent complete: 36.0%; Average loss: 3.4162\n",
      "Iteration: 1442; Percent complete: 36.0%; Average loss: 3.2754\n",
      "Iteration: 1443; Percent complete: 36.1%; Average loss: 3.5577\n",
      "Iteration: 1444; Percent complete: 36.1%; Average loss: 3.1890\n",
      "Iteration: 1445; Percent complete: 36.1%; Average loss: 3.2804\n",
      "Iteration: 1446; Percent complete: 36.1%; Average loss: 3.4320\n",
      "Iteration: 1447; Percent complete: 36.2%; Average loss: 3.2852\n",
      "Iteration: 1448; Percent complete: 36.2%; Average loss: 3.5093\n",
      "Iteration: 1449; Percent complete: 36.2%; Average loss: 3.1936\n",
      "Iteration: 1450; Percent complete: 36.2%; Average loss: 3.1954\n",
      "Iteration: 1451; Percent complete: 36.3%; Average loss: 3.3873\n",
      "Iteration: 1452; Percent complete: 36.3%; Average loss: 3.2636\n",
      "Iteration: 1453; Percent complete: 36.3%; Average loss: 3.2706\n",
      "Iteration: 1454; Percent complete: 36.4%; Average loss: 3.1513\n",
      "Iteration: 1455; Percent complete: 36.4%; Average loss: 3.4187\n",
      "Iteration: 1456; Percent complete: 36.4%; Average loss: 3.4063\n",
      "Iteration: 1457; Percent complete: 36.4%; Average loss: 3.2307\n",
      "Iteration: 1458; Percent complete: 36.4%; Average loss: 3.3445\n",
      "Iteration: 1459; Percent complete: 36.5%; Average loss: 3.2706\n",
      "Iteration: 1460; Percent complete: 36.5%; Average loss: 3.0638\n",
      "Iteration: 1461; Percent complete: 36.5%; Average loss: 2.9783\n",
      "Iteration: 1462; Percent complete: 36.5%; Average loss: 3.4609\n",
      "Iteration: 1463; Percent complete: 36.6%; Average loss: 3.1469\n",
      "Iteration: 1464; Percent complete: 36.6%; Average loss: 3.3021\n",
      "Iteration: 1465; Percent complete: 36.6%; Average loss: 3.2708\n",
      "Iteration: 1466; Percent complete: 36.6%; Average loss: 3.1350\n",
      "Iteration: 1467; Percent complete: 36.7%; Average loss: 3.1991\n",
      "Iteration: 1468; Percent complete: 36.7%; Average loss: 3.3467\n",
      "Iteration: 1469; Percent complete: 36.7%; Average loss: 3.2377\n",
      "Iteration: 1470; Percent complete: 36.8%; Average loss: 3.1275\n",
      "Iteration: 1471; Percent complete: 36.8%; Average loss: 3.3203\n",
      "Iteration: 1472; Percent complete: 36.8%; Average loss: 3.6607\n",
      "Iteration: 1473; Percent complete: 36.8%; Average loss: 3.4064\n",
      "Iteration: 1474; Percent complete: 36.9%; Average loss: 3.1828\n",
      "Iteration: 1475; Percent complete: 36.9%; Average loss: 3.3238\n",
      "Iteration: 1476; Percent complete: 36.9%; Average loss: 3.4740\n",
      "Iteration: 1477; Percent complete: 36.9%; Average loss: 3.0380\n",
      "Iteration: 1478; Percent complete: 37.0%; Average loss: 3.6326\n",
      "Iteration: 1479; Percent complete: 37.0%; Average loss: 3.6307\n",
      "Iteration: 1480; Percent complete: 37.0%; Average loss: 3.3536\n",
      "Iteration: 1481; Percent complete: 37.0%; Average loss: 3.3328\n",
      "Iteration: 1482; Percent complete: 37.0%; Average loss: 3.5123\n",
      "Iteration: 1483; Percent complete: 37.1%; Average loss: 3.2374\n",
      "Iteration: 1484; Percent complete: 37.1%; Average loss: 3.2034\n",
      "Iteration: 1485; Percent complete: 37.1%; Average loss: 3.4141\n",
      "Iteration: 1486; Percent complete: 37.1%; Average loss: 3.3675\n",
      "Iteration: 1487; Percent complete: 37.2%; Average loss: 3.1559\n",
      "Iteration: 1488; Percent complete: 37.2%; Average loss: 3.1924\n",
      "Iteration: 1489; Percent complete: 37.2%; Average loss: 3.3427\n",
      "Iteration: 1490; Percent complete: 37.2%; Average loss: 3.5639\n",
      "Iteration: 1491; Percent complete: 37.3%; Average loss: 3.3479\n",
      "Iteration: 1492; Percent complete: 37.3%; Average loss: 3.2384\n",
      "Iteration: 1493; Percent complete: 37.3%; Average loss: 3.1886\n",
      "Iteration: 1494; Percent complete: 37.4%; Average loss: 3.6953\n",
      "Iteration: 1495; Percent complete: 37.4%; Average loss: 3.5848\n",
      "Iteration: 1496; Percent complete: 37.4%; Average loss: 3.2389\n",
      "Iteration: 1497; Percent complete: 37.4%; Average loss: 3.3284\n",
      "Iteration: 1498; Percent complete: 37.5%; Average loss: 3.1658\n",
      "Iteration: 1499; Percent complete: 37.5%; Average loss: 3.3764\n",
      "Iteration: 1500; Percent complete: 37.5%; Average loss: 3.1852\n",
      "Iteration: 1501; Percent complete: 37.5%; Average loss: 3.2811\n",
      "Iteration: 1502; Percent complete: 37.5%; Average loss: 3.3556\n",
      "Iteration: 1503; Percent complete: 37.6%; Average loss: 3.0454\n",
      "Iteration: 1504; Percent complete: 37.6%; Average loss: 3.2825\n",
      "Iteration: 1505; Percent complete: 37.6%; Average loss: 3.1059\n",
      "Iteration: 1506; Percent complete: 37.6%; Average loss: 3.2047\n",
      "Iteration: 1507; Percent complete: 37.7%; Average loss: 3.1982\n",
      "Iteration: 1508; Percent complete: 37.7%; Average loss: 2.9349\n",
      "Iteration: 1509; Percent complete: 37.7%; Average loss: 3.3957\n",
      "Iteration: 1510; Percent complete: 37.8%; Average loss: 2.9322\n",
      "Iteration: 1511; Percent complete: 37.8%; Average loss: 3.1681\n",
      "Iteration: 1512; Percent complete: 37.8%; Average loss: 3.5575\n",
      "Iteration: 1513; Percent complete: 37.8%; Average loss: 2.9218\n",
      "Iteration: 1514; Percent complete: 37.9%; Average loss: 3.2164\n",
      "Iteration: 1515; Percent complete: 37.9%; Average loss: 3.3670\n",
      "Iteration: 1516; Percent complete: 37.9%; Average loss: 3.2559\n",
      "Iteration: 1517; Percent complete: 37.9%; Average loss: 3.2558\n",
      "Iteration: 1518; Percent complete: 38.0%; Average loss: 3.3094\n",
      "Iteration: 1519; Percent complete: 38.0%; Average loss: 3.5517\n",
      "Iteration: 1520; Percent complete: 38.0%; Average loss: 3.2588\n",
      "Iteration: 1521; Percent complete: 38.0%; Average loss: 3.1360\n",
      "Iteration: 1522; Percent complete: 38.0%; Average loss: 3.2725\n",
      "Iteration: 1523; Percent complete: 38.1%; Average loss: 3.3827\n",
      "Iteration: 1524; Percent complete: 38.1%; Average loss: 3.2261\n",
      "Iteration: 1525; Percent complete: 38.1%; Average loss: 3.2958\n",
      "Iteration: 1526; Percent complete: 38.1%; Average loss: 3.1877\n",
      "Iteration: 1527; Percent complete: 38.2%; Average loss: 3.1610\n",
      "Iteration: 1528; Percent complete: 38.2%; Average loss: 3.1740\n",
      "Iteration: 1529; Percent complete: 38.2%; Average loss: 3.4668\n",
      "Iteration: 1530; Percent complete: 38.2%; Average loss: 3.3595\n",
      "Iteration: 1531; Percent complete: 38.3%; Average loss: 3.3976\n",
      "Iteration: 1532; Percent complete: 38.3%; Average loss: 3.3456\n",
      "Iteration: 1533; Percent complete: 38.3%; Average loss: 3.2906\n",
      "Iteration: 1534; Percent complete: 38.4%; Average loss: 3.3467\n",
      "Iteration: 1535; Percent complete: 38.4%; Average loss: 3.2514\n",
      "Iteration: 1536; Percent complete: 38.4%; Average loss: 3.0888\n",
      "Iteration: 1537; Percent complete: 38.4%; Average loss: 3.0713\n",
      "Iteration: 1538; Percent complete: 38.5%; Average loss: 3.2358\n",
      "Iteration: 1539; Percent complete: 38.5%; Average loss: 3.2046\n",
      "Iteration: 1540; Percent complete: 38.5%; Average loss: 3.6050\n",
      "Iteration: 1541; Percent complete: 38.5%; Average loss: 3.4687\n",
      "Iteration: 1542; Percent complete: 38.6%; Average loss: 3.2880\n",
      "Iteration: 1543; Percent complete: 38.6%; Average loss: 3.3498\n",
      "Iteration: 1544; Percent complete: 38.6%; Average loss: 3.2711\n",
      "Iteration: 1545; Percent complete: 38.6%; Average loss: 3.0882\n",
      "Iteration: 1546; Percent complete: 38.6%; Average loss: 3.4675\n",
      "Iteration: 1547; Percent complete: 38.7%; Average loss: 3.3136\n",
      "Iteration: 1548; Percent complete: 38.7%; Average loss: 3.4352\n",
      "Iteration: 1549; Percent complete: 38.7%; Average loss: 3.2541\n",
      "Iteration: 1550; Percent complete: 38.8%; Average loss: 3.2738\n",
      "Iteration: 1551; Percent complete: 38.8%; Average loss: 3.2710\n",
      "Iteration: 1552; Percent complete: 38.8%; Average loss: 3.2654\n",
      "Iteration: 1553; Percent complete: 38.8%; Average loss: 3.4501\n",
      "Iteration: 1554; Percent complete: 38.9%; Average loss: 3.2156\n",
      "Iteration: 1555; Percent complete: 38.9%; Average loss: 3.3635\n",
      "Iteration: 1556; Percent complete: 38.9%; Average loss: 3.4191\n",
      "Iteration: 1557; Percent complete: 38.9%; Average loss: 3.1605\n",
      "Iteration: 1558; Percent complete: 39.0%; Average loss: 3.2360\n",
      "Iteration: 1559; Percent complete: 39.0%; Average loss: 3.4577\n",
      "Iteration: 1560; Percent complete: 39.0%; Average loss: 3.1584\n",
      "Iteration: 1561; Percent complete: 39.0%; Average loss: 3.4698\n",
      "Iteration: 1562; Percent complete: 39.1%; Average loss: 3.4334\n",
      "Iteration: 1563; Percent complete: 39.1%; Average loss: 3.2543\n",
      "Iteration: 1564; Percent complete: 39.1%; Average loss: 3.3854\n",
      "Iteration: 1565; Percent complete: 39.1%; Average loss: 3.2546\n",
      "Iteration: 1566; Percent complete: 39.1%; Average loss: 3.3022\n",
      "Iteration: 1567; Percent complete: 39.2%; Average loss: 3.3012\n",
      "Iteration: 1568; Percent complete: 39.2%; Average loss: 3.5721\n",
      "Iteration: 1569; Percent complete: 39.2%; Average loss: 3.0039\n",
      "Iteration: 1570; Percent complete: 39.2%; Average loss: 3.2307\n",
      "Iteration: 1571; Percent complete: 39.3%; Average loss: 3.2429\n",
      "Iteration: 1572; Percent complete: 39.3%; Average loss: 3.2137\n",
      "Iteration: 1573; Percent complete: 39.3%; Average loss: 3.4119\n",
      "Iteration: 1574; Percent complete: 39.4%; Average loss: 3.3878\n",
      "Iteration: 1575; Percent complete: 39.4%; Average loss: 3.1604\n",
      "Iteration: 1576; Percent complete: 39.4%; Average loss: 3.1626\n",
      "Iteration: 1577; Percent complete: 39.4%; Average loss: 3.3007\n",
      "Iteration: 1578; Percent complete: 39.5%; Average loss: 3.2592\n",
      "Iteration: 1579; Percent complete: 39.5%; Average loss: 3.2758\n",
      "Iteration: 1580; Percent complete: 39.5%; Average loss: 3.6267\n",
      "Iteration: 1581; Percent complete: 39.5%; Average loss: 3.4473\n",
      "Iteration: 1582; Percent complete: 39.6%; Average loss: 3.4671\n",
      "Iteration: 1583; Percent complete: 39.6%; Average loss: 3.4252\n",
      "Iteration: 1584; Percent complete: 39.6%; Average loss: 3.3068\n",
      "Iteration: 1585; Percent complete: 39.6%; Average loss: 3.5446\n",
      "Iteration: 1586; Percent complete: 39.6%; Average loss: 3.0792\n",
      "Iteration: 1587; Percent complete: 39.7%; Average loss: 3.2319\n",
      "Iteration: 1588; Percent complete: 39.7%; Average loss: 3.1976\n",
      "Iteration: 1589; Percent complete: 39.7%; Average loss: 3.4802\n",
      "Iteration: 1590; Percent complete: 39.8%; Average loss: 3.2631\n",
      "Iteration: 1591; Percent complete: 39.8%; Average loss: 3.0641\n",
      "Iteration: 1592; Percent complete: 39.8%; Average loss: 3.4544\n",
      "Iteration: 1593; Percent complete: 39.8%; Average loss: 3.3098\n",
      "Iteration: 1594; Percent complete: 39.9%; Average loss: 3.2107\n",
      "Iteration: 1595; Percent complete: 39.9%; Average loss: 3.4340\n",
      "Iteration: 1596; Percent complete: 39.9%; Average loss: 3.1531\n",
      "Iteration: 1597; Percent complete: 39.9%; Average loss: 3.3466\n",
      "Iteration: 1598; Percent complete: 40.0%; Average loss: 3.1351\n",
      "Iteration: 1599; Percent complete: 40.0%; Average loss: 3.4859\n",
      "Iteration: 1600; Percent complete: 40.0%; Average loss: 3.3846\n",
      "Iteration: 1601; Percent complete: 40.0%; Average loss: 3.2511\n",
      "Iteration: 1602; Percent complete: 40.1%; Average loss: 3.2000\n",
      "Iteration: 1603; Percent complete: 40.1%; Average loss: 3.3334\n",
      "Iteration: 1604; Percent complete: 40.1%; Average loss: 3.1224\n",
      "Iteration: 1605; Percent complete: 40.1%; Average loss: 3.2327\n",
      "Iteration: 1606; Percent complete: 40.2%; Average loss: 3.3431\n",
      "Iteration: 1607; Percent complete: 40.2%; Average loss: 3.2837\n",
      "Iteration: 1608; Percent complete: 40.2%; Average loss: 3.3838\n",
      "Iteration: 1609; Percent complete: 40.2%; Average loss: 3.3573\n",
      "Iteration: 1610; Percent complete: 40.2%; Average loss: 3.1297\n",
      "Iteration: 1611; Percent complete: 40.3%; Average loss: 3.4124\n",
      "Iteration: 1612; Percent complete: 40.3%; Average loss: 3.1478\n",
      "Iteration: 1613; Percent complete: 40.3%; Average loss: 3.0738\n",
      "Iteration: 1614; Percent complete: 40.4%; Average loss: 3.2790\n",
      "Iteration: 1615; Percent complete: 40.4%; Average loss: 3.2837\n",
      "Iteration: 1616; Percent complete: 40.4%; Average loss: 3.1461\n",
      "Iteration: 1617; Percent complete: 40.4%; Average loss: 3.3423\n",
      "Iteration: 1618; Percent complete: 40.5%; Average loss: 3.3120\n",
      "Iteration: 1619; Percent complete: 40.5%; Average loss: 3.3059\n",
      "Iteration: 1620; Percent complete: 40.5%; Average loss: 3.5898\n",
      "Iteration: 1621; Percent complete: 40.5%; Average loss: 3.0933\n",
      "Iteration: 1622; Percent complete: 40.6%; Average loss: 2.9213\n",
      "Iteration: 1623; Percent complete: 40.6%; Average loss: 3.4153\n",
      "Iteration: 1624; Percent complete: 40.6%; Average loss: 3.3667\n",
      "Iteration: 1625; Percent complete: 40.6%; Average loss: 3.3382\n",
      "Iteration: 1626; Percent complete: 40.6%; Average loss: 3.3901\n",
      "Iteration: 1627; Percent complete: 40.7%; Average loss: 3.3473\n",
      "Iteration: 1628; Percent complete: 40.7%; Average loss: 3.3875\n",
      "Iteration: 1629; Percent complete: 40.7%; Average loss: 3.1542\n",
      "Iteration: 1630; Percent complete: 40.8%; Average loss: 3.3152\n",
      "Iteration: 1631; Percent complete: 40.8%; Average loss: 3.1604\n",
      "Iteration: 1632; Percent complete: 40.8%; Average loss: 3.0765\n",
      "Iteration: 1633; Percent complete: 40.8%; Average loss: 3.2234\n",
      "Iteration: 1634; Percent complete: 40.8%; Average loss: 3.1725\n",
      "Iteration: 1635; Percent complete: 40.9%; Average loss: 3.2468\n",
      "Iteration: 1636; Percent complete: 40.9%; Average loss: 3.1424\n",
      "Iteration: 1637; Percent complete: 40.9%; Average loss: 3.0094\n",
      "Iteration: 1638; Percent complete: 40.9%; Average loss: 3.1595\n",
      "Iteration: 1639; Percent complete: 41.0%; Average loss: 3.4891\n",
      "Iteration: 1640; Percent complete: 41.0%; Average loss: 3.1030\n",
      "Iteration: 1641; Percent complete: 41.0%; Average loss: 3.1865\n",
      "Iteration: 1642; Percent complete: 41.0%; Average loss: 3.2970\n",
      "Iteration: 1643; Percent complete: 41.1%; Average loss: 3.2997\n",
      "Iteration: 1644; Percent complete: 41.1%; Average loss: 3.4412\n",
      "Iteration: 1645; Percent complete: 41.1%; Average loss: 3.1460\n",
      "Iteration: 1646; Percent complete: 41.1%; Average loss: 3.3175\n",
      "Iteration: 1647; Percent complete: 41.2%; Average loss: 3.2048\n",
      "Iteration: 1648; Percent complete: 41.2%; Average loss: 3.3547\n",
      "Iteration: 1649; Percent complete: 41.2%; Average loss: 3.2310\n",
      "Iteration: 1650; Percent complete: 41.2%; Average loss: 3.0978\n",
      "Iteration: 1651; Percent complete: 41.3%; Average loss: 3.3480\n",
      "Iteration: 1652; Percent complete: 41.3%; Average loss: 3.2720\n",
      "Iteration: 1653; Percent complete: 41.3%; Average loss: 3.0122\n",
      "Iteration: 1654; Percent complete: 41.3%; Average loss: 3.1171\n",
      "Iteration: 1655; Percent complete: 41.4%; Average loss: 3.1559\n",
      "Iteration: 1656; Percent complete: 41.4%; Average loss: 3.3425\n",
      "Iteration: 1657; Percent complete: 41.4%; Average loss: 3.1542\n",
      "Iteration: 1658; Percent complete: 41.4%; Average loss: 3.2723\n",
      "Iteration: 1659; Percent complete: 41.5%; Average loss: 3.0934\n",
      "Iteration: 1660; Percent complete: 41.5%; Average loss: 3.2247\n",
      "Iteration: 1661; Percent complete: 41.5%; Average loss: 2.9709\n",
      "Iteration: 1662; Percent complete: 41.5%; Average loss: 3.2690\n",
      "Iteration: 1663; Percent complete: 41.6%; Average loss: 3.1796\n",
      "Iteration: 1664; Percent complete: 41.6%; Average loss: 3.3143\n",
      "Iteration: 1665; Percent complete: 41.6%; Average loss: 3.2776\n",
      "Iteration: 1666; Percent complete: 41.6%; Average loss: 3.2233\n",
      "Iteration: 1667; Percent complete: 41.7%; Average loss: 3.2503\n",
      "Iteration: 1668; Percent complete: 41.7%; Average loss: 3.1394\n",
      "Iteration: 1669; Percent complete: 41.7%; Average loss: 3.2403\n",
      "Iteration: 1670; Percent complete: 41.8%; Average loss: 3.3145\n",
      "Iteration: 1671; Percent complete: 41.8%; Average loss: 3.3339\n",
      "Iteration: 1672; Percent complete: 41.8%; Average loss: 3.1796\n",
      "Iteration: 1673; Percent complete: 41.8%; Average loss: 3.1970\n",
      "Iteration: 1674; Percent complete: 41.9%; Average loss: 3.0952\n",
      "Iteration: 1675; Percent complete: 41.9%; Average loss: 3.4530\n",
      "Iteration: 1676; Percent complete: 41.9%; Average loss: 3.1250\n",
      "Iteration: 1677; Percent complete: 41.9%; Average loss: 3.3322\n",
      "Iteration: 1678; Percent complete: 41.9%; Average loss: 3.3537\n",
      "Iteration: 1679; Percent complete: 42.0%; Average loss: 3.3503\n",
      "Iteration: 1680; Percent complete: 42.0%; Average loss: 3.3016\n",
      "Iteration: 1681; Percent complete: 42.0%; Average loss: 3.0670\n",
      "Iteration: 1682; Percent complete: 42.0%; Average loss: 3.2754\n",
      "Iteration: 1683; Percent complete: 42.1%; Average loss: 3.4398\n",
      "Iteration: 1684; Percent complete: 42.1%; Average loss: 3.1970\n",
      "Iteration: 1685; Percent complete: 42.1%; Average loss: 3.2584\n",
      "Iteration: 1686; Percent complete: 42.1%; Average loss: 3.2808\n",
      "Iteration: 1687; Percent complete: 42.2%; Average loss: 3.3765\n",
      "Iteration: 1688; Percent complete: 42.2%; Average loss: 3.2109\n",
      "Iteration: 1689; Percent complete: 42.2%; Average loss: 3.1530\n",
      "Iteration: 1690; Percent complete: 42.2%; Average loss: 3.3300\n",
      "Iteration: 1691; Percent complete: 42.3%; Average loss: 3.3281\n",
      "Iteration: 1692; Percent complete: 42.3%; Average loss: 3.2467\n",
      "Iteration: 1693; Percent complete: 42.3%; Average loss: 3.3082\n",
      "Iteration: 1694; Percent complete: 42.4%; Average loss: 3.3633\n",
      "Iteration: 1695; Percent complete: 42.4%; Average loss: 3.2194\n",
      "Iteration: 1696; Percent complete: 42.4%; Average loss: 3.2342\n",
      "Iteration: 1697; Percent complete: 42.4%; Average loss: 3.1391\n",
      "Iteration: 1698; Percent complete: 42.4%; Average loss: 3.3145\n",
      "Iteration: 1699; Percent complete: 42.5%; Average loss: 3.2582\n",
      "Iteration: 1700; Percent complete: 42.5%; Average loss: 3.1322\n",
      "Iteration: 1701; Percent complete: 42.5%; Average loss: 2.9353\n",
      "Iteration: 1702; Percent complete: 42.5%; Average loss: 2.9088\n",
      "Iteration: 1703; Percent complete: 42.6%; Average loss: 3.4067\n",
      "Iteration: 1704; Percent complete: 42.6%; Average loss: 3.0896\n",
      "Iteration: 1705; Percent complete: 42.6%; Average loss: 3.1764\n",
      "Iteration: 1706; Percent complete: 42.6%; Average loss: 3.2341\n",
      "Iteration: 1707; Percent complete: 42.7%; Average loss: 3.4767\n",
      "Iteration: 1708; Percent complete: 42.7%; Average loss: 3.1424\n",
      "Iteration: 1709; Percent complete: 42.7%; Average loss: 3.1852\n",
      "Iteration: 1710; Percent complete: 42.8%; Average loss: 3.2949\n",
      "Iteration: 1711; Percent complete: 42.8%; Average loss: 3.6801\n",
      "Iteration: 1712; Percent complete: 42.8%; Average loss: 3.4333\n",
      "Iteration: 1713; Percent complete: 42.8%; Average loss: 3.2099\n",
      "Iteration: 1714; Percent complete: 42.9%; Average loss: 3.2764\n",
      "Iteration: 1715; Percent complete: 42.9%; Average loss: 3.3786\n",
      "Iteration: 1716; Percent complete: 42.9%; Average loss: 3.3092\n",
      "Iteration: 1717; Percent complete: 42.9%; Average loss: 3.1970\n",
      "Iteration: 1718; Percent complete: 43.0%; Average loss: 3.2539\n",
      "Iteration: 1719; Percent complete: 43.0%; Average loss: 3.2503\n",
      "Iteration: 1720; Percent complete: 43.0%; Average loss: 3.4296\n",
      "Iteration: 1721; Percent complete: 43.0%; Average loss: 3.3935\n",
      "Iteration: 1722; Percent complete: 43.0%; Average loss: 3.3546\n",
      "Iteration: 1723; Percent complete: 43.1%; Average loss: 3.1472\n",
      "Iteration: 1724; Percent complete: 43.1%; Average loss: 3.3800\n",
      "Iteration: 1725; Percent complete: 43.1%; Average loss: 3.2387\n",
      "Iteration: 1726; Percent complete: 43.1%; Average loss: 3.2898\n",
      "Iteration: 1727; Percent complete: 43.2%; Average loss: 3.3427\n",
      "Iteration: 1728; Percent complete: 43.2%; Average loss: 3.4329\n",
      "Iteration: 1729; Percent complete: 43.2%; Average loss: 3.0428\n",
      "Iteration: 1730; Percent complete: 43.2%; Average loss: 3.3042\n",
      "Iteration: 1731; Percent complete: 43.3%; Average loss: 3.2811\n",
      "Iteration: 1732; Percent complete: 43.3%; Average loss: 3.2720\n",
      "Iteration: 1733; Percent complete: 43.3%; Average loss: 2.9724\n",
      "Iteration: 1734; Percent complete: 43.4%; Average loss: 3.0596\n",
      "Iteration: 1735; Percent complete: 43.4%; Average loss: 3.2289\n",
      "Iteration: 1736; Percent complete: 43.4%; Average loss: 3.2371\n",
      "Iteration: 1737; Percent complete: 43.4%; Average loss: 3.1310\n",
      "Iteration: 1738; Percent complete: 43.5%; Average loss: 3.3377\n",
      "Iteration: 1739; Percent complete: 43.5%; Average loss: 3.0105\n",
      "Iteration: 1740; Percent complete: 43.5%; Average loss: 3.2333\n",
      "Iteration: 1741; Percent complete: 43.5%; Average loss: 3.0533\n",
      "Iteration: 1742; Percent complete: 43.5%; Average loss: 3.3368\n",
      "Iteration: 1743; Percent complete: 43.6%; Average loss: 3.2564\n",
      "Iteration: 1744; Percent complete: 43.6%; Average loss: 3.1726\n",
      "Iteration: 1745; Percent complete: 43.6%; Average loss: 3.3298\n",
      "Iteration: 1746; Percent complete: 43.6%; Average loss: 3.3548\n",
      "Iteration: 1747; Percent complete: 43.7%; Average loss: 3.2832\n",
      "Iteration: 1748; Percent complete: 43.7%; Average loss: 3.2664\n",
      "Iteration: 1749; Percent complete: 43.7%; Average loss: 3.3260\n",
      "Iteration: 1750; Percent complete: 43.8%; Average loss: 3.2545\n",
      "Iteration: 1751; Percent complete: 43.8%; Average loss: 3.3269\n",
      "Iteration: 1752; Percent complete: 43.8%; Average loss: 3.1759\n",
      "Iteration: 1753; Percent complete: 43.8%; Average loss: 3.2739\n",
      "Iteration: 1754; Percent complete: 43.9%; Average loss: 3.3581\n",
      "Iteration: 1755; Percent complete: 43.9%; Average loss: 3.1249\n",
      "Iteration: 1756; Percent complete: 43.9%; Average loss: 3.0306\n",
      "Iteration: 1757; Percent complete: 43.9%; Average loss: 3.2474\n",
      "Iteration: 1758; Percent complete: 44.0%; Average loss: 3.2258\n",
      "Iteration: 1759; Percent complete: 44.0%; Average loss: 3.2227\n",
      "Iteration: 1760; Percent complete: 44.0%; Average loss: 3.0180\n",
      "Iteration: 1761; Percent complete: 44.0%; Average loss: 3.1512\n",
      "Iteration: 1762; Percent complete: 44.0%; Average loss: 3.3239\n",
      "Iteration: 1763; Percent complete: 44.1%; Average loss: 3.1343\n",
      "Iteration: 1764; Percent complete: 44.1%; Average loss: 3.2860\n",
      "Iteration: 1765; Percent complete: 44.1%; Average loss: 3.0836\n",
      "Iteration: 1766; Percent complete: 44.1%; Average loss: 3.1725\n",
      "Iteration: 1767; Percent complete: 44.2%; Average loss: 3.1051\n",
      "Iteration: 1768; Percent complete: 44.2%; Average loss: 3.2529\n",
      "Iteration: 1769; Percent complete: 44.2%; Average loss: 3.1671\n",
      "Iteration: 1770; Percent complete: 44.2%; Average loss: 3.2439\n",
      "Iteration: 1771; Percent complete: 44.3%; Average loss: 3.2535\n",
      "Iteration: 1772; Percent complete: 44.3%; Average loss: 3.3010\n",
      "Iteration: 1773; Percent complete: 44.3%; Average loss: 3.2438\n",
      "Iteration: 1774; Percent complete: 44.4%; Average loss: 3.3068\n",
      "Iteration: 1775; Percent complete: 44.4%; Average loss: 3.1590\n",
      "Iteration: 1776; Percent complete: 44.4%; Average loss: 3.2097\n",
      "Iteration: 1777; Percent complete: 44.4%; Average loss: 2.9020\n",
      "Iteration: 1778; Percent complete: 44.5%; Average loss: 3.2168\n",
      "Iteration: 1779; Percent complete: 44.5%; Average loss: 3.1102\n",
      "Iteration: 1780; Percent complete: 44.5%; Average loss: 3.4255\n",
      "Iteration: 1781; Percent complete: 44.5%; Average loss: 3.3038\n",
      "Iteration: 1782; Percent complete: 44.5%; Average loss: 3.1064\n",
      "Iteration: 1783; Percent complete: 44.6%; Average loss: 3.1988\n",
      "Iteration: 1784; Percent complete: 44.6%; Average loss: 3.3512\n",
      "Iteration: 1785; Percent complete: 44.6%; Average loss: 3.0708\n",
      "Iteration: 1786; Percent complete: 44.6%; Average loss: 3.2355\n",
      "Iteration: 1787; Percent complete: 44.7%; Average loss: 3.0953\n",
      "Iteration: 1788; Percent complete: 44.7%; Average loss: 2.9998\n",
      "Iteration: 1789; Percent complete: 44.7%; Average loss: 3.4002\n",
      "Iteration: 1790; Percent complete: 44.8%; Average loss: 3.0080\n",
      "Iteration: 1791; Percent complete: 44.8%; Average loss: 3.2352\n",
      "Iteration: 1792; Percent complete: 44.8%; Average loss: 3.2270\n",
      "Iteration: 1793; Percent complete: 44.8%; Average loss: 3.2408\n",
      "Iteration: 1794; Percent complete: 44.9%; Average loss: 3.3257\n",
      "Iteration: 1795; Percent complete: 44.9%; Average loss: 3.1964\n",
      "Iteration: 1796; Percent complete: 44.9%; Average loss: 3.2535\n",
      "Iteration: 1797; Percent complete: 44.9%; Average loss: 3.1854\n",
      "Iteration: 1798; Percent complete: 45.0%; Average loss: 3.1728\n",
      "Iteration: 1799; Percent complete: 45.0%; Average loss: 3.1533\n",
      "Iteration: 1800; Percent complete: 45.0%; Average loss: 3.4538\n",
      "Iteration: 1801; Percent complete: 45.0%; Average loss: 3.1524\n",
      "Iteration: 1802; Percent complete: 45.1%; Average loss: 3.1420\n",
      "Iteration: 1803; Percent complete: 45.1%; Average loss: 3.2081\n",
      "Iteration: 1804; Percent complete: 45.1%; Average loss: 3.3607\n",
      "Iteration: 1805; Percent complete: 45.1%; Average loss: 3.3200\n",
      "Iteration: 1806; Percent complete: 45.1%; Average loss: 3.2826\n",
      "Iteration: 1807; Percent complete: 45.2%; Average loss: 3.4802\n",
      "Iteration: 1808; Percent complete: 45.2%; Average loss: 3.4306\n",
      "Iteration: 1809; Percent complete: 45.2%; Average loss: 3.2518\n",
      "Iteration: 1810; Percent complete: 45.2%; Average loss: 3.3997\n",
      "Iteration: 1811; Percent complete: 45.3%; Average loss: 3.3589\n",
      "Iteration: 1812; Percent complete: 45.3%; Average loss: 3.3485\n",
      "Iteration: 1813; Percent complete: 45.3%; Average loss: 3.0921\n",
      "Iteration: 1814; Percent complete: 45.4%; Average loss: 3.3622\n",
      "Iteration: 1815; Percent complete: 45.4%; Average loss: 3.3516\n",
      "Iteration: 1816; Percent complete: 45.4%; Average loss: 2.9022\n",
      "Iteration: 1817; Percent complete: 45.4%; Average loss: 3.2554\n",
      "Iteration: 1818; Percent complete: 45.5%; Average loss: 3.3143\n",
      "Iteration: 1819; Percent complete: 45.5%; Average loss: 3.1725\n",
      "Iteration: 1820; Percent complete: 45.5%; Average loss: 2.9438\n",
      "Iteration: 1821; Percent complete: 45.5%; Average loss: 3.0712\n",
      "Iteration: 1822; Percent complete: 45.6%; Average loss: 3.0540\n",
      "Iteration: 1823; Percent complete: 45.6%; Average loss: 3.5431\n",
      "Iteration: 1824; Percent complete: 45.6%; Average loss: 3.1571\n",
      "Iteration: 1825; Percent complete: 45.6%; Average loss: 3.4339\n",
      "Iteration: 1826; Percent complete: 45.6%; Average loss: 2.8519\n",
      "Iteration: 1827; Percent complete: 45.7%; Average loss: 3.0372\n",
      "Iteration: 1828; Percent complete: 45.7%; Average loss: 3.1696\n",
      "Iteration: 1829; Percent complete: 45.7%; Average loss: 3.4680\n",
      "Iteration: 1830; Percent complete: 45.8%; Average loss: 3.2369\n",
      "Iteration: 1831; Percent complete: 45.8%; Average loss: 2.9861\n",
      "Iteration: 1832; Percent complete: 45.8%; Average loss: 3.1067\n",
      "Iteration: 1833; Percent complete: 45.8%; Average loss: 3.0964\n",
      "Iteration: 1834; Percent complete: 45.9%; Average loss: 3.1945\n",
      "Iteration: 1835; Percent complete: 45.9%; Average loss: 3.5193\n",
      "Iteration: 1836; Percent complete: 45.9%; Average loss: 3.0755\n",
      "Iteration: 1837; Percent complete: 45.9%; Average loss: 3.1492\n",
      "Iteration: 1838; Percent complete: 46.0%; Average loss: 3.0795\n",
      "Iteration: 1839; Percent complete: 46.0%; Average loss: 3.2730\n",
      "Iteration: 1840; Percent complete: 46.0%; Average loss: 3.1958\n",
      "Iteration: 1841; Percent complete: 46.0%; Average loss: 3.2035\n",
      "Iteration: 1842; Percent complete: 46.1%; Average loss: 3.3586\n",
      "Iteration: 1843; Percent complete: 46.1%; Average loss: 3.0348\n",
      "Iteration: 1844; Percent complete: 46.1%; Average loss: 3.2771\n",
      "Iteration: 1845; Percent complete: 46.1%; Average loss: 3.0922\n",
      "Iteration: 1846; Percent complete: 46.2%; Average loss: 2.9237\n",
      "Iteration: 1847; Percent complete: 46.2%; Average loss: 3.4554\n",
      "Iteration: 1848; Percent complete: 46.2%; Average loss: 2.8235\n",
      "Iteration: 1849; Percent complete: 46.2%; Average loss: 3.3057\n",
      "Iteration: 1850; Percent complete: 46.2%; Average loss: 3.2573\n",
      "Iteration: 1851; Percent complete: 46.3%; Average loss: 3.1695\n",
      "Iteration: 1852; Percent complete: 46.3%; Average loss: 2.8142\n",
      "Iteration: 1853; Percent complete: 46.3%; Average loss: 3.2474\n",
      "Iteration: 1854; Percent complete: 46.4%; Average loss: 3.1892\n",
      "Iteration: 1855; Percent complete: 46.4%; Average loss: 3.1886\n",
      "Iteration: 1856; Percent complete: 46.4%; Average loss: 3.1296\n",
      "Iteration: 1857; Percent complete: 46.4%; Average loss: 3.0317\n",
      "Iteration: 1858; Percent complete: 46.5%; Average loss: 3.4448\n",
      "Iteration: 1859; Percent complete: 46.5%; Average loss: 3.3902\n",
      "Iteration: 1860; Percent complete: 46.5%; Average loss: 3.3883\n",
      "Iteration: 1861; Percent complete: 46.5%; Average loss: 3.4157\n",
      "Iteration: 1862; Percent complete: 46.6%; Average loss: 3.4026\n",
      "Iteration: 1863; Percent complete: 46.6%; Average loss: 3.2992\n",
      "Iteration: 1864; Percent complete: 46.6%; Average loss: 3.6761\n",
      "Iteration: 1865; Percent complete: 46.6%; Average loss: 3.0394\n",
      "Iteration: 1866; Percent complete: 46.7%; Average loss: 3.1771\n",
      "Iteration: 1867; Percent complete: 46.7%; Average loss: 3.0232\n",
      "Iteration: 1868; Percent complete: 46.7%; Average loss: 3.3837\n",
      "Iteration: 1869; Percent complete: 46.7%; Average loss: 2.9927\n",
      "Iteration: 1870; Percent complete: 46.8%; Average loss: 3.0303\n",
      "Iteration: 1871; Percent complete: 46.8%; Average loss: 3.1939\n",
      "Iteration: 1872; Percent complete: 46.8%; Average loss: 3.2114\n",
      "Iteration: 1873; Percent complete: 46.8%; Average loss: 3.2382\n",
      "Iteration: 1874; Percent complete: 46.9%; Average loss: 3.0336\n",
      "Iteration: 1875; Percent complete: 46.9%; Average loss: 3.2703\n",
      "Iteration: 1876; Percent complete: 46.9%; Average loss: 3.0808\n",
      "Iteration: 1877; Percent complete: 46.9%; Average loss: 3.0507\n",
      "Iteration: 1878; Percent complete: 46.9%; Average loss: 3.0155\n",
      "Iteration: 1879; Percent complete: 47.0%; Average loss: 2.9668\n",
      "Iteration: 1880; Percent complete: 47.0%; Average loss: 3.0084\n",
      "Iteration: 1881; Percent complete: 47.0%; Average loss: 3.3885\n",
      "Iteration: 1882; Percent complete: 47.0%; Average loss: 3.2488\n",
      "Iteration: 1883; Percent complete: 47.1%; Average loss: 3.2768\n",
      "Iteration: 1884; Percent complete: 47.1%; Average loss: 3.0737\n",
      "Iteration: 1885; Percent complete: 47.1%; Average loss: 3.1842\n",
      "Iteration: 1886; Percent complete: 47.1%; Average loss: 3.3481\n",
      "Iteration: 1887; Percent complete: 47.2%; Average loss: 3.1089\n",
      "Iteration: 1888; Percent complete: 47.2%; Average loss: 3.4178\n",
      "Iteration: 1889; Percent complete: 47.2%; Average loss: 3.0599\n",
      "Iteration: 1890; Percent complete: 47.2%; Average loss: 3.3511\n",
      "Iteration: 1891; Percent complete: 47.3%; Average loss: 3.1818\n",
      "Iteration: 1892; Percent complete: 47.3%; Average loss: 3.0544\n",
      "Iteration: 1893; Percent complete: 47.3%; Average loss: 3.0559\n",
      "Iteration: 1894; Percent complete: 47.3%; Average loss: 3.4408\n",
      "Iteration: 1895; Percent complete: 47.4%; Average loss: 3.3146\n",
      "Iteration: 1896; Percent complete: 47.4%; Average loss: 3.3139\n",
      "Iteration: 1897; Percent complete: 47.4%; Average loss: 3.0016\n",
      "Iteration: 1898; Percent complete: 47.4%; Average loss: 3.0670\n",
      "Iteration: 1899; Percent complete: 47.5%; Average loss: 3.0942\n",
      "Iteration: 1900; Percent complete: 47.5%; Average loss: 3.2458\n",
      "Iteration: 1901; Percent complete: 47.5%; Average loss: 3.1989\n",
      "Iteration: 1902; Percent complete: 47.5%; Average loss: 3.1257\n",
      "Iteration: 1903; Percent complete: 47.6%; Average loss: 3.5761\n",
      "Iteration: 1904; Percent complete: 47.6%; Average loss: 3.2674\n",
      "Iteration: 1905; Percent complete: 47.6%; Average loss: 3.1304\n",
      "Iteration: 1906; Percent complete: 47.6%; Average loss: 3.0014\n",
      "Iteration: 1907; Percent complete: 47.7%; Average loss: 3.2440\n",
      "Iteration: 1908; Percent complete: 47.7%; Average loss: 3.1727\n",
      "Iteration: 1909; Percent complete: 47.7%; Average loss: 3.0841\n",
      "Iteration: 1910; Percent complete: 47.8%; Average loss: 3.2016\n",
      "Iteration: 1911; Percent complete: 47.8%; Average loss: 3.2067\n",
      "Iteration: 1912; Percent complete: 47.8%; Average loss: 3.0726\n",
      "Iteration: 1913; Percent complete: 47.8%; Average loss: 3.2902\n",
      "Iteration: 1914; Percent complete: 47.9%; Average loss: 3.1222\n",
      "Iteration: 1915; Percent complete: 47.9%; Average loss: 3.5211\n",
      "Iteration: 1916; Percent complete: 47.9%; Average loss: 3.2679\n",
      "Iteration: 1917; Percent complete: 47.9%; Average loss: 2.8842\n",
      "Iteration: 1918; Percent complete: 47.9%; Average loss: 3.1873\n",
      "Iteration: 1919; Percent complete: 48.0%; Average loss: 3.3119\n",
      "Iteration: 1920; Percent complete: 48.0%; Average loss: 3.3168\n",
      "Iteration: 1921; Percent complete: 48.0%; Average loss: 2.9828\n",
      "Iteration: 1922; Percent complete: 48.0%; Average loss: 3.2156\n",
      "Iteration: 1923; Percent complete: 48.1%; Average loss: 3.1331\n",
      "Iteration: 1924; Percent complete: 48.1%; Average loss: 3.0838\n",
      "Iteration: 1925; Percent complete: 48.1%; Average loss: 3.2389\n",
      "Iteration: 1926; Percent complete: 48.1%; Average loss: 3.3909\n",
      "Iteration: 1927; Percent complete: 48.2%; Average loss: 3.4071\n",
      "Iteration: 1928; Percent complete: 48.2%; Average loss: 3.0535\n",
      "Iteration: 1929; Percent complete: 48.2%; Average loss: 3.1975\n",
      "Iteration: 1930; Percent complete: 48.2%; Average loss: 3.2160\n",
      "Iteration: 1931; Percent complete: 48.3%; Average loss: 3.1258\n",
      "Iteration: 1932; Percent complete: 48.3%; Average loss: 3.2427\n",
      "Iteration: 1933; Percent complete: 48.3%; Average loss: 3.0206\n",
      "Iteration: 1934; Percent complete: 48.4%; Average loss: 3.0848\n",
      "Iteration: 1935; Percent complete: 48.4%; Average loss: 3.2541\n",
      "Iteration: 1936; Percent complete: 48.4%; Average loss: 3.0758\n",
      "Iteration: 1937; Percent complete: 48.4%; Average loss: 3.3375\n",
      "Iteration: 1938; Percent complete: 48.4%; Average loss: 3.1487\n",
      "Iteration: 1939; Percent complete: 48.5%; Average loss: 3.1254\n",
      "Iteration: 1940; Percent complete: 48.5%; Average loss: 3.1642\n",
      "Iteration: 1941; Percent complete: 48.5%; Average loss: 3.2941\n",
      "Iteration: 1942; Percent complete: 48.5%; Average loss: 3.2600\n",
      "Iteration: 1943; Percent complete: 48.6%; Average loss: 3.2646\n",
      "Iteration: 1944; Percent complete: 48.6%; Average loss: 3.0745\n",
      "Iteration: 1945; Percent complete: 48.6%; Average loss: 3.0826\n",
      "Iteration: 1946; Percent complete: 48.6%; Average loss: 3.2309\n",
      "Iteration: 1947; Percent complete: 48.7%; Average loss: 3.0008\n",
      "Iteration: 1948; Percent complete: 48.7%; Average loss: 3.1870\n",
      "Iteration: 1949; Percent complete: 48.7%; Average loss: 3.0244\n",
      "Iteration: 1950; Percent complete: 48.8%; Average loss: 3.0549\n",
      "Iteration: 1951; Percent complete: 48.8%; Average loss: 3.2872\n",
      "Iteration: 1952; Percent complete: 48.8%; Average loss: 3.3491\n",
      "Iteration: 1953; Percent complete: 48.8%; Average loss: 3.1662\n",
      "Iteration: 1954; Percent complete: 48.9%; Average loss: 3.3495\n",
      "Iteration: 1955; Percent complete: 48.9%; Average loss: 3.1466\n",
      "Iteration: 1956; Percent complete: 48.9%; Average loss: 3.2604\n",
      "Iteration: 1957; Percent complete: 48.9%; Average loss: 3.0930\n",
      "Iteration: 1958; Percent complete: 48.9%; Average loss: 3.0189\n",
      "Iteration: 1959; Percent complete: 49.0%; Average loss: 3.4434\n",
      "Iteration: 1960; Percent complete: 49.0%; Average loss: 3.2460\n",
      "Iteration: 1961; Percent complete: 49.0%; Average loss: 3.2129\n",
      "Iteration: 1962; Percent complete: 49.0%; Average loss: 3.0597\n",
      "Iteration: 1963; Percent complete: 49.1%; Average loss: 3.2764\n",
      "Iteration: 1964; Percent complete: 49.1%; Average loss: 3.3456\n",
      "Iteration: 1965; Percent complete: 49.1%; Average loss: 3.1536\n",
      "Iteration: 1966; Percent complete: 49.1%; Average loss: 3.0357\n",
      "Iteration: 1967; Percent complete: 49.2%; Average loss: 3.2141\n",
      "Iteration: 1968; Percent complete: 49.2%; Average loss: 3.4683\n",
      "Iteration: 1969; Percent complete: 49.2%; Average loss: 3.1661\n",
      "Iteration: 1970; Percent complete: 49.2%; Average loss: 3.4083\n",
      "Iteration: 1971; Percent complete: 49.3%; Average loss: 3.3786\n",
      "Iteration: 1972; Percent complete: 49.3%; Average loss: 2.9513\n",
      "Iteration: 1973; Percent complete: 49.3%; Average loss: 3.2350\n",
      "Iteration: 1974; Percent complete: 49.4%; Average loss: 3.2921\n",
      "Iteration: 1975; Percent complete: 49.4%; Average loss: 3.4953\n",
      "Iteration: 1976; Percent complete: 49.4%; Average loss: 3.3263\n",
      "Iteration: 1977; Percent complete: 49.4%; Average loss: 3.2543\n",
      "Iteration: 1978; Percent complete: 49.5%; Average loss: 3.1496\n",
      "Iteration: 1979; Percent complete: 49.5%; Average loss: 3.1834\n",
      "Iteration: 1980; Percent complete: 49.5%; Average loss: 3.1350\n",
      "Iteration: 1981; Percent complete: 49.5%; Average loss: 3.2269\n",
      "Iteration: 1982; Percent complete: 49.5%; Average loss: 2.9852\n",
      "Iteration: 1983; Percent complete: 49.6%; Average loss: 3.1887\n",
      "Iteration: 1984; Percent complete: 49.6%; Average loss: 3.0983\n",
      "Iteration: 1985; Percent complete: 49.6%; Average loss: 3.0130\n",
      "Iteration: 1986; Percent complete: 49.6%; Average loss: 3.1037\n",
      "Iteration: 1987; Percent complete: 49.7%; Average loss: 3.1281\n",
      "Iteration: 1988; Percent complete: 49.7%; Average loss: 3.2399\n",
      "Iteration: 1989; Percent complete: 49.7%; Average loss: 3.1808\n",
      "Iteration: 1990; Percent complete: 49.8%; Average loss: 3.1546\n",
      "Iteration: 1991; Percent complete: 49.8%; Average loss: 3.0688\n",
      "Iteration: 1992; Percent complete: 49.8%; Average loss: 3.0411\n",
      "Iteration: 1993; Percent complete: 49.8%; Average loss: 3.2910\n",
      "Iteration: 1994; Percent complete: 49.9%; Average loss: 3.0836\n",
      "Iteration: 1995; Percent complete: 49.9%; Average loss: 3.3743\n",
      "Iteration: 1996; Percent complete: 49.9%; Average loss: 3.2843\n",
      "Iteration: 1997; Percent complete: 49.9%; Average loss: 3.1963\n",
      "Iteration: 1998; Percent complete: 50.0%; Average loss: 3.2841\n",
      "Iteration: 1999; Percent complete: 50.0%; Average loss: 3.1529\n",
      "Iteration: 2000; Percent complete: 50.0%; Average loss: 3.2082\n",
      "Iteration: 2001; Percent complete: 50.0%; Average loss: 3.1149\n",
      "Iteration: 2002; Percent complete: 50.0%; Average loss: 3.4692\n",
      "Iteration: 2003; Percent complete: 50.1%; Average loss: 3.1024\n",
      "Iteration: 2004; Percent complete: 50.1%; Average loss: 3.1624\n",
      "Iteration: 2005; Percent complete: 50.1%; Average loss: 3.1737\n",
      "Iteration: 2006; Percent complete: 50.1%; Average loss: 3.1565\n",
      "Iteration: 2007; Percent complete: 50.2%; Average loss: 3.3474\n",
      "Iteration: 2008; Percent complete: 50.2%; Average loss: 3.0540\n",
      "Iteration: 2009; Percent complete: 50.2%; Average loss: 2.9797\n",
      "Iteration: 2010; Percent complete: 50.2%; Average loss: 3.2565\n",
      "Iteration: 2011; Percent complete: 50.3%; Average loss: 3.3492\n",
      "Iteration: 2012; Percent complete: 50.3%; Average loss: 3.1628\n",
      "Iteration: 2013; Percent complete: 50.3%; Average loss: 3.1572\n",
      "Iteration: 2014; Percent complete: 50.3%; Average loss: 3.2238\n",
      "Iteration: 2015; Percent complete: 50.4%; Average loss: 3.2448\n",
      "Iteration: 2016; Percent complete: 50.4%; Average loss: 3.2495\n",
      "Iteration: 2017; Percent complete: 50.4%; Average loss: 2.9318\n",
      "Iteration: 2018; Percent complete: 50.4%; Average loss: 3.2012\n",
      "Iteration: 2019; Percent complete: 50.5%; Average loss: 3.2043\n",
      "Iteration: 2020; Percent complete: 50.5%; Average loss: 3.4169\n",
      "Iteration: 2021; Percent complete: 50.5%; Average loss: 3.2700\n",
      "Iteration: 2022; Percent complete: 50.5%; Average loss: 3.0297\n",
      "Iteration: 2023; Percent complete: 50.6%; Average loss: 2.9735\n",
      "Iteration: 2024; Percent complete: 50.6%; Average loss: 2.7525\n",
      "Iteration: 2025; Percent complete: 50.6%; Average loss: 3.3517\n",
      "Iteration: 2026; Percent complete: 50.6%; Average loss: 3.2983\n",
      "Iteration: 2027; Percent complete: 50.7%; Average loss: 2.9989\n",
      "Iteration: 2028; Percent complete: 50.7%; Average loss: 2.8659\n",
      "Iteration: 2029; Percent complete: 50.7%; Average loss: 3.2319\n",
      "Iteration: 2030; Percent complete: 50.7%; Average loss: 3.1767\n",
      "Iteration: 2031; Percent complete: 50.8%; Average loss: 3.0906\n",
      "Iteration: 2032; Percent complete: 50.8%; Average loss: 2.9274\n",
      "Iteration: 2033; Percent complete: 50.8%; Average loss: 3.3168\n",
      "Iteration: 2034; Percent complete: 50.8%; Average loss: 3.0443\n",
      "Iteration: 2035; Percent complete: 50.9%; Average loss: 3.3384\n",
      "Iteration: 2036; Percent complete: 50.9%; Average loss: 3.1877\n",
      "Iteration: 2037; Percent complete: 50.9%; Average loss: 3.2322\n",
      "Iteration: 2038; Percent complete: 50.9%; Average loss: 3.0349\n",
      "Iteration: 2039; Percent complete: 51.0%; Average loss: 3.1963\n",
      "Iteration: 2040; Percent complete: 51.0%; Average loss: 2.9312\n",
      "Iteration: 2041; Percent complete: 51.0%; Average loss: 3.0710\n",
      "Iteration: 2042; Percent complete: 51.0%; Average loss: 3.2978\n",
      "Iteration: 2043; Percent complete: 51.1%; Average loss: 3.0428\n",
      "Iteration: 2044; Percent complete: 51.1%; Average loss: 3.1851\n",
      "Iteration: 2045; Percent complete: 51.1%; Average loss: 3.4392\n",
      "Iteration: 2046; Percent complete: 51.1%; Average loss: 3.0813\n",
      "Iteration: 2047; Percent complete: 51.2%; Average loss: 3.0319\n",
      "Iteration: 2048; Percent complete: 51.2%; Average loss: 3.1984\n",
      "Iteration: 2049; Percent complete: 51.2%; Average loss: 3.1841\n",
      "Iteration: 2050; Percent complete: 51.2%; Average loss: 3.0969\n",
      "Iteration: 2051; Percent complete: 51.3%; Average loss: 3.2731\n",
      "Iteration: 2052; Percent complete: 51.3%; Average loss: 2.9168\n",
      "Iteration: 2053; Percent complete: 51.3%; Average loss: 3.1649\n",
      "Iteration: 2054; Percent complete: 51.3%; Average loss: 3.1549\n",
      "Iteration: 2055; Percent complete: 51.4%; Average loss: 3.2137\n",
      "Iteration: 2056; Percent complete: 51.4%; Average loss: 3.0599\n",
      "Iteration: 2057; Percent complete: 51.4%; Average loss: 3.0577\n",
      "Iteration: 2058; Percent complete: 51.4%; Average loss: 3.0192\n",
      "Iteration: 2059; Percent complete: 51.5%; Average loss: 3.0032\n",
      "Iteration: 2060; Percent complete: 51.5%; Average loss: 3.3567\n",
      "Iteration: 2061; Percent complete: 51.5%; Average loss: 3.0327\n",
      "Iteration: 2062; Percent complete: 51.5%; Average loss: 3.0040\n",
      "Iteration: 2063; Percent complete: 51.6%; Average loss: 3.1066\n",
      "Iteration: 2064; Percent complete: 51.6%; Average loss: 3.3245\n",
      "Iteration: 2065; Percent complete: 51.6%; Average loss: 3.1876\n",
      "Iteration: 2066; Percent complete: 51.6%; Average loss: 3.1613\n",
      "Iteration: 2067; Percent complete: 51.7%; Average loss: 2.9272\n",
      "Iteration: 2068; Percent complete: 51.7%; Average loss: 3.3433\n",
      "Iteration: 2069; Percent complete: 51.7%; Average loss: 3.1538\n",
      "Iteration: 2070; Percent complete: 51.7%; Average loss: 2.9813\n",
      "Iteration: 2071; Percent complete: 51.8%; Average loss: 3.0278\n",
      "Iteration: 2072; Percent complete: 51.8%; Average loss: 3.4067\n",
      "Iteration: 2073; Percent complete: 51.8%; Average loss: 3.1327\n",
      "Iteration: 2074; Percent complete: 51.8%; Average loss: 3.1426\n",
      "Iteration: 2075; Percent complete: 51.9%; Average loss: 3.0571\n",
      "Iteration: 2076; Percent complete: 51.9%; Average loss: 3.0072\n",
      "Iteration: 2077; Percent complete: 51.9%; Average loss: 3.0279\n",
      "Iteration: 2078; Percent complete: 51.9%; Average loss: 3.1783\n",
      "Iteration: 2079; Percent complete: 52.0%; Average loss: 3.2371\n",
      "Iteration: 2080; Percent complete: 52.0%; Average loss: 3.1959\n",
      "Iteration: 2081; Percent complete: 52.0%; Average loss: 3.2585\n",
      "Iteration: 2082; Percent complete: 52.0%; Average loss: 3.0316\n",
      "Iteration: 2083; Percent complete: 52.1%; Average loss: 3.2417\n",
      "Iteration: 2084; Percent complete: 52.1%; Average loss: 3.1226\n",
      "Iteration: 2085; Percent complete: 52.1%; Average loss: 3.0579\n",
      "Iteration: 2086; Percent complete: 52.1%; Average loss: 3.0619\n",
      "Iteration: 2087; Percent complete: 52.2%; Average loss: 3.0890\n",
      "Iteration: 2088; Percent complete: 52.2%; Average loss: 3.1590\n",
      "Iteration: 2089; Percent complete: 52.2%; Average loss: 3.2042\n",
      "Iteration: 2090; Percent complete: 52.2%; Average loss: 3.0238\n",
      "Iteration: 2091; Percent complete: 52.3%; Average loss: 3.2154\n",
      "Iteration: 2092; Percent complete: 52.3%; Average loss: 3.0813\n",
      "Iteration: 2093; Percent complete: 52.3%; Average loss: 3.0748\n",
      "Iteration: 2094; Percent complete: 52.3%; Average loss: 3.0433\n",
      "Iteration: 2095; Percent complete: 52.4%; Average loss: 3.1053\n",
      "Iteration: 2096; Percent complete: 52.4%; Average loss: 3.1631\n",
      "Iteration: 2097; Percent complete: 52.4%; Average loss: 3.2154\n",
      "Iteration: 2098; Percent complete: 52.4%; Average loss: 3.1838\n",
      "Iteration: 2099; Percent complete: 52.5%; Average loss: 3.3070\n",
      "Iteration: 2100; Percent complete: 52.5%; Average loss: 3.1872\n",
      "Iteration: 2101; Percent complete: 52.5%; Average loss: 3.2999\n",
      "Iteration: 2102; Percent complete: 52.5%; Average loss: 3.4601\n",
      "Iteration: 2103; Percent complete: 52.6%; Average loss: 3.0459\n",
      "Iteration: 2104; Percent complete: 52.6%; Average loss: 3.0534\n",
      "Iteration: 2105; Percent complete: 52.6%; Average loss: 2.9912\n",
      "Iteration: 2106; Percent complete: 52.6%; Average loss: 3.0896\n",
      "Iteration: 2107; Percent complete: 52.7%; Average loss: 3.1473\n",
      "Iteration: 2108; Percent complete: 52.7%; Average loss: 3.0212\n",
      "Iteration: 2109; Percent complete: 52.7%; Average loss: 3.4153\n",
      "Iteration: 2110; Percent complete: 52.8%; Average loss: 3.0631\n",
      "Iteration: 2111; Percent complete: 52.8%; Average loss: 3.3058\n",
      "Iteration: 2112; Percent complete: 52.8%; Average loss: 3.0522\n",
      "Iteration: 2113; Percent complete: 52.8%; Average loss: 3.1656\n",
      "Iteration: 2114; Percent complete: 52.8%; Average loss: 3.1904\n",
      "Iteration: 2115; Percent complete: 52.9%; Average loss: 3.2335\n",
      "Iteration: 2116; Percent complete: 52.9%; Average loss: 3.4354\n",
      "Iteration: 2117; Percent complete: 52.9%; Average loss: 3.0054\n",
      "Iteration: 2118; Percent complete: 52.9%; Average loss: 3.0576\n",
      "Iteration: 2119; Percent complete: 53.0%; Average loss: 3.1077\n",
      "Iteration: 2120; Percent complete: 53.0%; Average loss: 3.0456\n",
      "Iteration: 2121; Percent complete: 53.0%; Average loss: 3.2399\n",
      "Iteration: 2122; Percent complete: 53.0%; Average loss: 3.1187\n",
      "Iteration: 2123; Percent complete: 53.1%; Average loss: 3.2444\n",
      "Iteration: 2124; Percent complete: 53.1%; Average loss: 3.1705\n",
      "Iteration: 2125; Percent complete: 53.1%; Average loss: 2.8593\n",
      "Iteration: 2126; Percent complete: 53.1%; Average loss: 3.0219\n",
      "Iteration: 2127; Percent complete: 53.2%; Average loss: 3.2337\n",
      "Iteration: 2128; Percent complete: 53.2%; Average loss: 3.2209\n",
      "Iteration: 2129; Percent complete: 53.2%; Average loss: 3.1871\n",
      "Iteration: 2130; Percent complete: 53.2%; Average loss: 2.9840\n",
      "Iteration: 2131; Percent complete: 53.3%; Average loss: 3.0416\n",
      "Iteration: 2132; Percent complete: 53.3%; Average loss: 3.1449\n",
      "Iteration: 2133; Percent complete: 53.3%; Average loss: 3.0035\n",
      "Iteration: 2134; Percent complete: 53.3%; Average loss: 3.1888\n",
      "Iteration: 2135; Percent complete: 53.4%; Average loss: 3.3041\n",
      "Iteration: 2136; Percent complete: 53.4%; Average loss: 3.1467\n",
      "Iteration: 2137; Percent complete: 53.4%; Average loss: 3.2681\n",
      "Iteration: 2138; Percent complete: 53.4%; Average loss: 3.0517\n",
      "Iteration: 2139; Percent complete: 53.5%; Average loss: 2.9784\n",
      "Iteration: 2140; Percent complete: 53.5%; Average loss: 3.2595\n",
      "Iteration: 2141; Percent complete: 53.5%; Average loss: 3.0933\n",
      "Iteration: 2142; Percent complete: 53.5%; Average loss: 3.0125\n",
      "Iteration: 2143; Percent complete: 53.6%; Average loss: 3.0328\n",
      "Iteration: 2144; Percent complete: 53.6%; Average loss: 3.0783\n",
      "Iteration: 2145; Percent complete: 53.6%; Average loss: 3.0843\n",
      "Iteration: 2146; Percent complete: 53.6%; Average loss: 3.1724\n",
      "Iteration: 2147; Percent complete: 53.7%; Average loss: 3.2402\n",
      "Iteration: 2148; Percent complete: 53.7%; Average loss: 2.9745\n",
      "Iteration: 2149; Percent complete: 53.7%; Average loss: 3.1805\n",
      "Iteration: 2150; Percent complete: 53.8%; Average loss: 3.0659\n",
      "Iteration: 2151; Percent complete: 53.8%; Average loss: 3.1741\n",
      "Iteration: 2152; Percent complete: 53.8%; Average loss: 3.2166\n",
      "Iteration: 2153; Percent complete: 53.8%; Average loss: 3.0210\n",
      "Iteration: 2154; Percent complete: 53.8%; Average loss: 3.1465\n",
      "Iteration: 2155; Percent complete: 53.9%; Average loss: 3.1798\n",
      "Iteration: 2156; Percent complete: 53.9%; Average loss: 2.9233\n",
      "Iteration: 2157; Percent complete: 53.9%; Average loss: 3.2107\n",
      "Iteration: 2158; Percent complete: 53.9%; Average loss: 3.1495\n",
      "Iteration: 2159; Percent complete: 54.0%; Average loss: 3.0062\n",
      "Iteration: 2160; Percent complete: 54.0%; Average loss: 3.3022\n",
      "Iteration: 2161; Percent complete: 54.0%; Average loss: 3.0096\n",
      "Iteration: 2162; Percent complete: 54.0%; Average loss: 3.1913\n",
      "Iteration: 2163; Percent complete: 54.1%; Average loss: 3.1533\n",
      "Iteration: 2164; Percent complete: 54.1%; Average loss: 3.0350\n",
      "Iteration: 2165; Percent complete: 54.1%; Average loss: 3.1658\n",
      "Iteration: 2166; Percent complete: 54.1%; Average loss: 3.2373\n",
      "Iteration: 2167; Percent complete: 54.2%; Average loss: 3.2373\n",
      "Iteration: 2168; Percent complete: 54.2%; Average loss: 3.0903\n",
      "Iteration: 2169; Percent complete: 54.2%; Average loss: 3.0564\n",
      "Iteration: 2170; Percent complete: 54.2%; Average loss: 2.9251\n",
      "Iteration: 2171; Percent complete: 54.3%; Average loss: 3.2464\n",
      "Iteration: 2172; Percent complete: 54.3%; Average loss: 3.3825\n",
      "Iteration: 2173; Percent complete: 54.3%; Average loss: 3.3807\n",
      "Iteration: 2174; Percent complete: 54.4%; Average loss: 3.2350\n",
      "Iteration: 2175; Percent complete: 54.4%; Average loss: 2.9695\n",
      "Iteration: 2176; Percent complete: 54.4%; Average loss: 2.9056\n",
      "Iteration: 2177; Percent complete: 54.4%; Average loss: 3.0504\n",
      "Iteration: 2178; Percent complete: 54.4%; Average loss: 3.0704\n",
      "Iteration: 2179; Percent complete: 54.5%; Average loss: 3.2341\n",
      "Iteration: 2180; Percent complete: 54.5%; Average loss: 2.9216\n",
      "Iteration: 2181; Percent complete: 54.5%; Average loss: 2.9119\n",
      "Iteration: 2182; Percent complete: 54.5%; Average loss: 3.1728\n",
      "Iteration: 2183; Percent complete: 54.6%; Average loss: 3.2105\n",
      "Iteration: 2184; Percent complete: 54.6%; Average loss: 2.9327\n",
      "Iteration: 2185; Percent complete: 54.6%; Average loss: 3.1283\n",
      "Iteration: 2186; Percent complete: 54.6%; Average loss: 3.2375\n",
      "Iteration: 2187; Percent complete: 54.7%; Average loss: 3.1406\n",
      "Iteration: 2188; Percent complete: 54.7%; Average loss: 3.2877\n",
      "Iteration: 2189; Percent complete: 54.7%; Average loss: 3.0811\n",
      "Iteration: 2190; Percent complete: 54.8%; Average loss: 2.9333\n",
      "Iteration: 2191; Percent complete: 54.8%; Average loss: 3.0446\n",
      "Iteration: 2192; Percent complete: 54.8%; Average loss: 3.1889\n",
      "Iteration: 2193; Percent complete: 54.8%; Average loss: 3.2479\n",
      "Iteration: 2194; Percent complete: 54.9%; Average loss: 3.2153\n",
      "Iteration: 2195; Percent complete: 54.9%; Average loss: 3.3670\n",
      "Iteration: 2196; Percent complete: 54.9%; Average loss: 2.9339\n",
      "Iteration: 2197; Percent complete: 54.9%; Average loss: 3.0430\n",
      "Iteration: 2198; Percent complete: 54.9%; Average loss: 3.0997\n",
      "Iteration: 2199; Percent complete: 55.0%; Average loss: 3.2640\n",
      "Iteration: 2200; Percent complete: 55.0%; Average loss: 3.1570\n",
      "Iteration: 2201; Percent complete: 55.0%; Average loss: 3.0195\n",
      "Iteration: 2202; Percent complete: 55.0%; Average loss: 3.0562\n",
      "Iteration: 2203; Percent complete: 55.1%; Average loss: 2.9020\n",
      "Iteration: 2204; Percent complete: 55.1%; Average loss: 3.1450\n",
      "Iteration: 2205; Percent complete: 55.1%; Average loss: 3.1889\n",
      "Iteration: 2206; Percent complete: 55.1%; Average loss: 3.1361\n",
      "Iteration: 2207; Percent complete: 55.2%; Average loss: 3.2197\n",
      "Iteration: 2208; Percent complete: 55.2%; Average loss: 3.1695\n",
      "Iteration: 2209; Percent complete: 55.2%; Average loss: 3.1391\n",
      "Iteration: 2210; Percent complete: 55.2%; Average loss: 3.0901\n",
      "Iteration: 2211; Percent complete: 55.3%; Average loss: 3.1009\n",
      "Iteration: 2212; Percent complete: 55.3%; Average loss: 3.0961\n",
      "Iteration: 2213; Percent complete: 55.3%; Average loss: 3.1071\n",
      "Iteration: 2214; Percent complete: 55.4%; Average loss: 3.3075\n",
      "Iteration: 2215; Percent complete: 55.4%; Average loss: 3.1559\n",
      "Iteration: 2216; Percent complete: 55.4%; Average loss: 3.0978\n",
      "Iteration: 2217; Percent complete: 55.4%; Average loss: 3.2209\n",
      "Iteration: 2218; Percent complete: 55.5%; Average loss: 2.8812\n",
      "Iteration: 2219; Percent complete: 55.5%; Average loss: 3.0528\n",
      "Iteration: 2220; Percent complete: 55.5%; Average loss: 2.9478\n",
      "Iteration: 2221; Percent complete: 55.5%; Average loss: 3.2022\n",
      "Iteration: 2222; Percent complete: 55.5%; Average loss: 3.0690\n",
      "Iteration: 2223; Percent complete: 55.6%; Average loss: 3.0582\n",
      "Iteration: 2224; Percent complete: 55.6%; Average loss: 2.9638\n",
      "Iteration: 2225; Percent complete: 55.6%; Average loss: 3.2415\n",
      "Iteration: 2226; Percent complete: 55.6%; Average loss: 3.5418\n",
      "Iteration: 2227; Percent complete: 55.7%; Average loss: 2.9684\n",
      "Iteration: 2228; Percent complete: 55.7%; Average loss: 2.9168\n",
      "Iteration: 2229; Percent complete: 55.7%; Average loss: 3.0042\n",
      "Iteration: 2230; Percent complete: 55.8%; Average loss: 3.3420\n",
      "Iteration: 2231; Percent complete: 55.8%; Average loss: 2.7673\n",
      "Iteration: 2232; Percent complete: 55.8%; Average loss: 3.3168\n",
      "Iteration: 2233; Percent complete: 55.8%; Average loss: 3.0216\n",
      "Iteration: 2234; Percent complete: 55.9%; Average loss: 3.1888\n",
      "Iteration: 2235; Percent complete: 55.9%; Average loss: 2.9440\n",
      "Iteration: 2236; Percent complete: 55.9%; Average loss: 3.0129\n",
      "Iteration: 2237; Percent complete: 55.9%; Average loss: 3.2862\n",
      "Iteration: 2238; Percent complete: 56.0%; Average loss: 3.3401\n",
      "Iteration: 2239; Percent complete: 56.0%; Average loss: 3.0064\n",
      "Iteration: 2240; Percent complete: 56.0%; Average loss: 2.9815\n",
      "Iteration: 2241; Percent complete: 56.0%; Average loss: 3.1758\n",
      "Iteration: 2242; Percent complete: 56.0%; Average loss: 3.1954\n",
      "Iteration: 2243; Percent complete: 56.1%; Average loss: 3.0948\n",
      "Iteration: 2244; Percent complete: 56.1%; Average loss: 3.2322\n",
      "Iteration: 2245; Percent complete: 56.1%; Average loss: 2.8999\n",
      "Iteration: 2246; Percent complete: 56.1%; Average loss: 3.1323\n",
      "Iteration: 2247; Percent complete: 56.2%; Average loss: 3.2062\n",
      "Iteration: 2248; Percent complete: 56.2%; Average loss: 3.2596\n",
      "Iteration: 2249; Percent complete: 56.2%; Average loss: 3.0669\n",
      "Iteration: 2250; Percent complete: 56.2%; Average loss: 3.1418\n",
      "Iteration: 2251; Percent complete: 56.3%; Average loss: 3.0625\n",
      "Iteration: 2252; Percent complete: 56.3%; Average loss: 2.8354\n",
      "Iteration: 2253; Percent complete: 56.3%; Average loss: 3.0152\n",
      "Iteration: 2254; Percent complete: 56.4%; Average loss: 3.3499\n",
      "Iteration: 2255; Percent complete: 56.4%; Average loss: 3.1123\n",
      "Iteration: 2256; Percent complete: 56.4%; Average loss: 3.2161\n",
      "Iteration: 2257; Percent complete: 56.4%; Average loss: 2.9346\n",
      "Iteration: 2258; Percent complete: 56.5%; Average loss: 3.4500\n",
      "Iteration: 2259; Percent complete: 56.5%; Average loss: 2.9546\n",
      "Iteration: 2260; Percent complete: 56.5%; Average loss: 3.2969\n",
      "Iteration: 2261; Percent complete: 56.5%; Average loss: 3.0232\n",
      "Iteration: 2262; Percent complete: 56.5%; Average loss: 3.0781\n",
      "Iteration: 2263; Percent complete: 56.6%; Average loss: 2.6908\n",
      "Iteration: 2264; Percent complete: 56.6%; Average loss: 3.0890\n",
      "Iteration: 2265; Percent complete: 56.6%; Average loss: 3.0787\n",
      "Iteration: 2266; Percent complete: 56.6%; Average loss: 2.8231\n",
      "Iteration: 2267; Percent complete: 56.7%; Average loss: 2.8522\n",
      "Iteration: 2268; Percent complete: 56.7%; Average loss: 2.8848\n",
      "Iteration: 2269; Percent complete: 56.7%; Average loss: 3.2179\n",
      "Iteration: 2270; Percent complete: 56.8%; Average loss: 2.9336\n",
      "Iteration: 2271; Percent complete: 56.8%; Average loss: 3.1807\n",
      "Iteration: 2272; Percent complete: 56.8%; Average loss: 3.2438\n",
      "Iteration: 2273; Percent complete: 56.8%; Average loss: 3.1505\n",
      "Iteration: 2274; Percent complete: 56.9%; Average loss: 2.8398\n",
      "Iteration: 2275; Percent complete: 56.9%; Average loss: 3.0749\n",
      "Iteration: 2276; Percent complete: 56.9%; Average loss: 3.2126\n",
      "Iteration: 2277; Percent complete: 56.9%; Average loss: 3.1575\n",
      "Iteration: 2278; Percent complete: 57.0%; Average loss: 3.0908\n",
      "Iteration: 2279; Percent complete: 57.0%; Average loss: 3.2163\n",
      "Iteration: 2280; Percent complete: 57.0%; Average loss: 3.0343\n",
      "Iteration: 2281; Percent complete: 57.0%; Average loss: 3.1416\n",
      "Iteration: 2282; Percent complete: 57.0%; Average loss: 3.2054\n",
      "Iteration: 2283; Percent complete: 57.1%; Average loss: 2.8907\n",
      "Iteration: 2284; Percent complete: 57.1%; Average loss: 3.1890\n",
      "Iteration: 2285; Percent complete: 57.1%; Average loss: 3.0720\n",
      "Iteration: 2286; Percent complete: 57.1%; Average loss: 2.8727\n",
      "Iteration: 2287; Percent complete: 57.2%; Average loss: 3.2101\n",
      "Iteration: 2288; Percent complete: 57.2%; Average loss: 2.7598\n",
      "Iteration: 2289; Percent complete: 57.2%; Average loss: 3.0717\n",
      "Iteration: 2290; Percent complete: 57.2%; Average loss: 2.9435\n",
      "Iteration: 2291; Percent complete: 57.3%; Average loss: 2.9831\n",
      "Iteration: 2292; Percent complete: 57.3%; Average loss: 3.0723\n",
      "Iteration: 2293; Percent complete: 57.3%; Average loss: 3.0705\n",
      "Iteration: 2294; Percent complete: 57.4%; Average loss: 2.9697\n",
      "Iteration: 2295; Percent complete: 57.4%; Average loss: 2.8842\n",
      "Iteration: 2296; Percent complete: 57.4%; Average loss: 3.1654\n",
      "Iteration: 2297; Percent complete: 57.4%; Average loss: 3.0200\n",
      "Iteration: 2298; Percent complete: 57.5%; Average loss: 3.0309\n",
      "Iteration: 2299; Percent complete: 57.5%; Average loss: 3.1875\n",
      "Iteration: 2300; Percent complete: 57.5%; Average loss: 3.1743\n",
      "Iteration: 2301; Percent complete: 57.5%; Average loss: 3.1811\n",
      "Iteration: 2302; Percent complete: 57.6%; Average loss: 3.0401\n",
      "Iteration: 2303; Percent complete: 57.6%; Average loss: 2.9408\n",
      "Iteration: 2304; Percent complete: 57.6%; Average loss: 3.2218\n",
      "Iteration: 2305; Percent complete: 57.6%; Average loss: 3.1464\n",
      "Iteration: 2306; Percent complete: 57.6%; Average loss: 2.9642\n",
      "Iteration: 2307; Percent complete: 57.7%; Average loss: 2.8079\n",
      "Iteration: 2308; Percent complete: 57.7%; Average loss: 2.9996\n",
      "Iteration: 2309; Percent complete: 57.7%; Average loss: 3.0726\n",
      "Iteration: 2310; Percent complete: 57.8%; Average loss: 3.3397\n",
      "Iteration: 2311; Percent complete: 57.8%; Average loss: 3.1430\n",
      "Iteration: 2312; Percent complete: 57.8%; Average loss: 3.3286\n",
      "Iteration: 2313; Percent complete: 57.8%; Average loss: 2.9164\n",
      "Iteration: 2314; Percent complete: 57.9%; Average loss: 3.2109\n",
      "Iteration: 2315; Percent complete: 57.9%; Average loss: 3.3330\n",
      "Iteration: 2316; Percent complete: 57.9%; Average loss: 3.1248\n",
      "Iteration: 2317; Percent complete: 57.9%; Average loss: 3.0707\n",
      "Iteration: 2318; Percent complete: 58.0%; Average loss: 3.0612\n",
      "Iteration: 2319; Percent complete: 58.0%; Average loss: 2.8473\n",
      "Iteration: 2320; Percent complete: 58.0%; Average loss: 3.2078\n",
      "Iteration: 2321; Percent complete: 58.0%; Average loss: 3.0709\n",
      "Iteration: 2322; Percent complete: 58.1%; Average loss: 3.0883\n",
      "Iteration: 2323; Percent complete: 58.1%; Average loss: 3.0236\n",
      "Iteration: 2324; Percent complete: 58.1%; Average loss: 2.9528\n",
      "Iteration: 2325; Percent complete: 58.1%; Average loss: 3.2924\n",
      "Iteration: 2326; Percent complete: 58.1%; Average loss: 2.7107\n",
      "Iteration: 2327; Percent complete: 58.2%; Average loss: 2.9690\n",
      "Iteration: 2328; Percent complete: 58.2%; Average loss: 3.0400\n",
      "Iteration: 2329; Percent complete: 58.2%; Average loss: 2.9971\n",
      "Iteration: 2330; Percent complete: 58.2%; Average loss: 3.0223\n",
      "Iteration: 2331; Percent complete: 58.3%; Average loss: 3.2198\n",
      "Iteration: 2332; Percent complete: 58.3%; Average loss: 3.0670\n",
      "Iteration: 2333; Percent complete: 58.3%; Average loss: 2.8575\n",
      "Iteration: 2334; Percent complete: 58.4%; Average loss: 3.1535\n",
      "Iteration: 2335; Percent complete: 58.4%; Average loss: 2.8534\n",
      "Iteration: 2336; Percent complete: 58.4%; Average loss: 3.1788\n",
      "Iteration: 2337; Percent complete: 58.4%; Average loss: 3.3014\n",
      "Iteration: 2338; Percent complete: 58.5%; Average loss: 3.1429\n",
      "Iteration: 2339; Percent complete: 58.5%; Average loss: 3.0781\n",
      "Iteration: 2340; Percent complete: 58.5%; Average loss: 2.9397\n",
      "Iteration: 2341; Percent complete: 58.5%; Average loss: 2.9744\n",
      "Iteration: 2342; Percent complete: 58.6%; Average loss: 3.0321\n",
      "Iteration: 2343; Percent complete: 58.6%; Average loss: 3.1011\n",
      "Iteration: 2344; Percent complete: 58.6%; Average loss: 3.0047\n",
      "Iteration: 2345; Percent complete: 58.6%; Average loss: 2.8201\n",
      "Iteration: 2346; Percent complete: 58.7%; Average loss: 3.3459\n",
      "Iteration: 2347; Percent complete: 58.7%; Average loss: 3.0558\n",
      "Iteration: 2348; Percent complete: 58.7%; Average loss: 2.8595\n",
      "Iteration: 2349; Percent complete: 58.7%; Average loss: 2.9791\n",
      "Iteration: 2350; Percent complete: 58.8%; Average loss: 2.9259\n",
      "Iteration: 2351; Percent complete: 58.8%; Average loss: 2.9089\n",
      "Iteration: 2352; Percent complete: 58.8%; Average loss: 2.8353\n",
      "Iteration: 2353; Percent complete: 58.8%; Average loss: 3.2003\n",
      "Iteration: 2354; Percent complete: 58.9%; Average loss: 3.3361\n",
      "Iteration: 2355; Percent complete: 58.9%; Average loss: 3.0339\n",
      "Iteration: 2356; Percent complete: 58.9%; Average loss: 3.0604\n",
      "Iteration: 2357; Percent complete: 58.9%; Average loss: 3.0730\n",
      "Iteration: 2358; Percent complete: 59.0%; Average loss: 3.0103\n",
      "Iteration: 2359; Percent complete: 59.0%; Average loss: 3.1640\n",
      "Iteration: 2360; Percent complete: 59.0%; Average loss: 2.8391\n",
      "Iteration: 2361; Percent complete: 59.0%; Average loss: 3.0450\n",
      "Iteration: 2362; Percent complete: 59.1%; Average loss: 3.2066\n",
      "Iteration: 2363; Percent complete: 59.1%; Average loss: 3.0557\n",
      "Iteration: 2364; Percent complete: 59.1%; Average loss: 3.1378\n",
      "Iteration: 2365; Percent complete: 59.1%; Average loss: 3.0553\n",
      "Iteration: 2366; Percent complete: 59.2%; Average loss: 2.9069\n",
      "Iteration: 2367; Percent complete: 59.2%; Average loss: 2.8837\n",
      "Iteration: 2368; Percent complete: 59.2%; Average loss: 3.0619\n",
      "Iteration: 2369; Percent complete: 59.2%; Average loss: 3.2510\n",
      "Iteration: 2370; Percent complete: 59.2%; Average loss: 3.3935\n",
      "Iteration: 2371; Percent complete: 59.3%; Average loss: 2.9976\n",
      "Iteration: 2372; Percent complete: 59.3%; Average loss: 3.2120\n",
      "Iteration: 2373; Percent complete: 59.3%; Average loss: 2.9935\n",
      "Iteration: 2374; Percent complete: 59.4%; Average loss: 2.9533\n",
      "Iteration: 2375; Percent complete: 59.4%; Average loss: 2.8794\n",
      "Iteration: 2376; Percent complete: 59.4%; Average loss: 3.0426\n",
      "Iteration: 2377; Percent complete: 59.4%; Average loss: 2.9115\n",
      "Iteration: 2378; Percent complete: 59.5%; Average loss: 2.9513\n",
      "Iteration: 2379; Percent complete: 59.5%; Average loss: 3.1140\n",
      "Iteration: 2380; Percent complete: 59.5%; Average loss: 2.8890\n",
      "Iteration: 2381; Percent complete: 59.5%; Average loss: 3.1780\n",
      "Iteration: 2382; Percent complete: 59.6%; Average loss: 2.7383\n",
      "Iteration: 2383; Percent complete: 59.6%; Average loss: 2.9650\n",
      "Iteration: 2384; Percent complete: 59.6%; Average loss: 2.8571\n",
      "Iteration: 2385; Percent complete: 59.6%; Average loss: 3.1086\n",
      "Iteration: 2386; Percent complete: 59.7%; Average loss: 3.0087\n",
      "Iteration: 2387; Percent complete: 59.7%; Average loss: 3.0994\n",
      "Iteration: 2388; Percent complete: 59.7%; Average loss: 3.2480\n",
      "Iteration: 2389; Percent complete: 59.7%; Average loss: 3.1875\n",
      "Iteration: 2390; Percent complete: 59.8%; Average loss: 2.8676\n",
      "Iteration: 2391; Percent complete: 59.8%; Average loss: 2.9218\n",
      "Iteration: 2392; Percent complete: 59.8%; Average loss: 3.1167\n",
      "Iteration: 2393; Percent complete: 59.8%; Average loss: 2.9529\n",
      "Iteration: 2394; Percent complete: 59.9%; Average loss: 2.8647\n",
      "Iteration: 2395; Percent complete: 59.9%; Average loss: 3.0451\n",
      "Iteration: 2396; Percent complete: 59.9%; Average loss: 3.0807\n",
      "Iteration: 2397; Percent complete: 59.9%; Average loss: 3.1120\n",
      "Iteration: 2398; Percent complete: 60.0%; Average loss: 2.9271\n",
      "Iteration: 2399; Percent complete: 60.0%; Average loss: 3.1743\n",
      "Iteration: 2400; Percent complete: 60.0%; Average loss: 3.0094\n",
      "Iteration: 2401; Percent complete: 60.0%; Average loss: 2.8377\n",
      "Iteration: 2402; Percent complete: 60.1%; Average loss: 3.2161\n",
      "Iteration: 2403; Percent complete: 60.1%; Average loss: 2.9270\n",
      "Iteration: 2404; Percent complete: 60.1%; Average loss: 2.8011\n",
      "Iteration: 2405; Percent complete: 60.1%; Average loss: 3.1273\n",
      "Iteration: 2406; Percent complete: 60.2%; Average loss: 2.8971\n",
      "Iteration: 2407; Percent complete: 60.2%; Average loss: 2.8312\n",
      "Iteration: 2408; Percent complete: 60.2%; Average loss: 3.0171\n",
      "Iteration: 2409; Percent complete: 60.2%; Average loss: 3.0027\n",
      "Iteration: 2410; Percent complete: 60.2%; Average loss: 2.6430\n",
      "Iteration: 2411; Percent complete: 60.3%; Average loss: 2.8715\n",
      "Iteration: 2412; Percent complete: 60.3%; Average loss: 2.9399\n",
      "Iteration: 2413; Percent complete: 60.3%; Average loss: 3.1935\n",
      "Iteration: 2414; Percent complete: 60.4%; Average loss: 2.9675\n",
      "Iteration: 2415; Percent complete: 60.4%; Average loss: 3.0074\n",
      "Iteration: 2416; Percent complete: 60.4%; Average loss: 2.9939\n",
      "Iteration: 2417; Percent complete: 60.4%; Average loss: 3.3969\n",
      "Iteration: 2418; Percent complete: 60.5%; Average loss: 2.9387\n",
      "Iteration: 2419; Percent complete: 60.5%; Average loss: 2.7750\n",
      "Iteration: 2420; Percent complete: 60.5%; Average loss: 3.0736\n",
      "Iteration: 2421; Percent complete: 60.5%; Average loss: 2.9006\n",
      "Iteration: 2422; Percent complete: 60.6%; Average loss: 3.1029\n",
      "Iteration: 2423; Percent complete: 60.6%; Average loss: 3.0998\n",
      "Iteration: 2424; Percent complete: 60.6%; Average loss: 3.1131\n",
      "Iteration: 2425; Percent complete: 60.6%; Average loss: 3.0232\n",
      "Iteration: 2426; Percent complete: 60.7%; Average loss: 3.0732\n",
      "Iteration: 2427; Percent complete: 60.7%; Average loss: 3.3019\n",
      "Iteration: 2428; Percent complete: 60.7%; Average loss: 3.2356\n",
      "Iteration: 2429; Percent complete: 60.7%; Average loss: 3.0353\n",
      "Iteration: 2430; Percent complete: 60.8%; Average loss: 3.2755\n",
      "Iteration: 2431; Percent complete: 60.8%; Average loss: 3.0375\n",
      "Iteration: 2432; Percent complete: 60.8%; Average loss: 3.1990\n",
      "Iteration: 2433; Percent complete: 60.8%; Average loss: 3.0002\n",
      "Iteration: 2434; Percent complete: 60.9%; Average loss: 3.0500\n",
      "Iteration: 2435; Percent complete: 60.9%; Average loss: 3.2308\n",
      "Iteration: 2436; Percent complete: 60.9%; Average loss: 2.9852\n",
      "Iteration: 2437; Percent complete: 60.9%; Average loss: 3.0617\n",
      "Iteration: 2438; Percent complete: 61.0%; Average loss: 2.8609\n",
      "Iteration: 2439; Percent complete: 61.0%; Average loss: 2.9806\n",
      "Iteration: 2440; Percent complete: 61.0%; Average loss: 3.3641\n",
      "Iteration: 2441; Percent complete: 61.0%; Average loss: 2.9916\n",
      "Iteration: 2442; Percent complete: 61.1%; Average loss: 3.3711\n",
      "Iteration: 2443; Percent complete: 61.1%; Average loss: 3.1155\n",
      "Iteration: 2444; Percent complete: 61.1%; Average loss: 3.0574\n",
      "Iteration: 2445; Percent complete: 61.1%; Average loss: 3.1826\n",
      "Iteration: 2446; Percent complete: 61.2%; Average loss: 2.9566\n",
      "Iteration: 2447; Percent complete: 61.2%; Average loss: 2.7333\n",
      "Iteration: 2448; Percent complete: 61.2%; Average loss: 3.1451\n",
      "Iteration: 2449; Percent complete: 61.2%; Average loss: 3.0976\n",
      "Iteration: 2450; Percent complete: 61.3%; Average loss: 3.0232\n",
      "Iteration: 2451; Percent complete: 61.3%; Average loss: 3.0026\n",
      "Iteration: 2452; Percent complete: 61.3%; Average loss: 3.1373\n",
      "Iteration: 2453; Percent complete: 61.3%; Average loss: 2.9024\n",
      "Iteration: 2454; Percent complete: 61.4%; Average loss: 3.0756\n",
      "Iteration: 2455; Percent complete: 61.4%; Average loss: 3.1137\n",
      "Iteration: 2456; Percent complete: 61.4%; Average loss: 2.9910\n",
      "Iteration: 2457; Percent complete: 61.4%; Average loss: 3.0233\n",
      "Iteration: 2458; Percent complete: 61.5%; Average loss: 3.1661\n",
      "Iteration: 2459; Percent complete: 61.5%; Average loss: 2.8733\n",
      "Iteration: 2460; Percent complete: 61.5%; Average loss: 3.1447\n",
      "Iteration: 2461; Percent complete: 61.5%; Average loss: 3.0538\n",
      "Iteration: 2462; Percent complete: 61.6%; Average loss: 2.9841\n",
      "Iteration: 2463; Percent complete: 61.6%; Average loss: 2.9982\n",
      "Iteration: 2464; Percent complete: 61.6%; Average loss: 2.8630\n",
      "Iteration: 2465; Percent complete: 61.6%; Average loss: 2.9709\n",
      "Iteration: 2466; Percent complete: 61.7%; Average loss: 3.0314\n",
      "Iteration: 2467; Percent complete: 61.7%; Average loss: 3.1028\n",
      "Iteration: 2468; Percent complete: 61.7%; Average loss: 3.0246\n",
      "Iteration: 2469; Percent complete: 61.7%; Average loss: 3.0360\n",
      "Iteration: 2470; Percent complete: 61.8%; Average loss: 2.8862\n",
      "Iteration: 2471; Percent complete: 61.8%; Average loss: 2.9073\n",
      "Iteration: 2472; Percent complete: 61.8%; Average loss: 3.1232\n",
      "Iteration: 2473; Percent complete: 61.8%; Average loss: 2.7387\n",
      "Iteration: 2474; Percent complete: 61.9%; Average loss: 3.0861\n",
      "Iteration: 2475; Percent complete: 61.9%; Average loss: 2.9135\n",
      "Iteration: 2476; Percent complete: 61.9%; Average loss: 3.0335\n",
      "Iteration: 2477; Percent complete: 61.9%; Average loss: 3.3159\n",
      "Iteration: 2478; Percent complete: 62.0%; Average loss: 2.8861\n",
      "Iteration: 2479; Percent complete: 62.0%; Average loss: 3.0872\n",
      "Iteration: 2480; Percent complete: 62.0%; Average loss: 3.0781\n",
      "Iteration: 2481; Percent complete: 62.0%; Average loss: 2.9064\n",
      "Iteration: 2482; Percent complete: 62.1%; Average loss: 3.0143\n",
      "Iteration: 2483; Percent complete: 62.1%; Average loss: 3.2912\n",
      "Iteration: 2484; Percent complete: 62.1%; Average loss: 3.0475\n",
      "Iteration: 2485; Percent complete: 62.1%; Average loss: 3.0903\n",
      "Iteration: 2486; Percent complete: 62.2%; Average loss: 2.8582\n",
      "Iteration: 2487; Percent complete: 62.2%; Average loss: 2.8165\n",
      "Iteration: 2488; Percent complete: 62.2%; Average loss: 2.8773\n",
      "Iteration: 2489; Percent complete: 62.2%; Average loss: 3.0432\n",
      "Iteration: 2490; Percent complete: 62.3%; Average loss: 3.1007\n",
      "Iteration: 2491; Percent complete: 62.3%; Average loss: 2.7417\n",
      "Iteration: 2492; Percent complete: 62.3%; Average loss: 3.0895\n",
      "Iteration: 2493; Percent complete: 62.3%; Average loss: 3.1848\n",
      "Iteration: 2494; Percent complete: 62.4%; Average loss: 3.1985\n",
      "Iteration: 2495; Percent complete: 62.4%; Average loss: 2.9238\n",
      "Iteration: 2496; Percent complete: 62.4%; Average loss: 2.7739\n",
      "Iteration: 2497; Percent complete: 62.4%; Average loss: 2.9055\n",
      "Iteration: 2498; Percent complete: 62.5%; Average loss: 3.3160\n",
      "Iteration: 2499; Percent complete: 62.5%; Average loss: 3.3404\n",
      "Iteration: 2500; Percent complete: 62.5%; Average loss: 2.6977\n",
      "Iteration: 2501; Percent complete: 62.5%; Average loss: 2.9520\n",
      "Iteration: 2502; Percent complete: 62.5%; Average loss: 3.0517\n",
      "Iteration: 2503; Percent complete: 62.6%; Average loss: 2.8219\n",
      "Iteration: 2504; Percent complete: 62.6%; Average loss: 2.8717\n",
      "Iteration: 2505; Percent complete: 62.6%; Average loss: 3.0007\n",
      "Iteration: 2506; Percent complete: 62.6%; Average loss: 3.0205\n",
      "Iteration: 2507; Percent complete: 62.7%; Average loss: 2.9983\n",
      "Iteration: 2508; Percent complete: 62.7%; Average loss: 3.1072\n",
      "Iteration: 2509; Percent complete: 62.7%; Average loss: 3.0707\n",
      "Iteration: 2510; Percent complete: 62.7%; Average loss: 3.0299\n",
      "Iteration: 2511; Percent complete: 62.8%; Average loss: 3.0130\n",
      "Iteration: 2512; Percent complete: 62.8%; Average loss: 3.1158\n",
      "Iteration: 2513; Percent complete: 62.8%; Average loss: 2.9568\n",
      "Iteration: 2514; Percent complete: 62.8%; Average loss: 2.8753\n",
      "Iteration: 2515; Percent complete: 62.9%; Average loss: 2.9292\n",
      "Iteration: 2516; Percent complete: 62.9%; Average loss: 3.1571\n",
      "Iteration: 2517; Percent complete: 62.9%; Average loss: 3.0246\n",
      "Iteration: 2518; Percent complete: 62.9%; Average loss: 2.8949\n",
      "Iteration: 2519; Percent complete: 63.0%; Average loss: 2.8011\n",
      "Iteration: 2520; Percent complete: 63.0%; Average loss: 2.9427\n",
      "Iteration: 2521; Percent complete: 63.0%; Average loss: 2.9891\n",
      "Iteration: 2522; Percent complete: 63.0%; Average loss: 3.0095\n",
      "Iteration: 2523; Percent complete: 63.1%; Average loss: 3.0353\n",
      "Iteration: 2524; Percent complete: 63.1%; Average loss: 3.2749\n",
      "Iteration: 2525; Percent complete: 63.1%; Average loss: 2.9561\n",
      "Iteration: 2526; Percent complete: 63.1%; Average loss: 3.2806\n",
      "Iteration: 2527; Percent complete: 63.2%; Average loss: 3.0784\n",
      "Iteration: 2528; Percent complete: 63.2%; Average loss: 3.1953\n",
      "Iteration: 2529; Percent complete: 63.2%; Average loss: 2.8902\n",
      "Iteration: 2530; Percent complete: 63.2%; Average loss: 2.9831\n",
      "Iteration: 2531; Percent complete: 63.3%; Average loss: 3.0368\n",
      "Iteration: 2532; Percent complete: 63.3%; Average loss: 2.9397\n",
      "Iteration: 2533; Percent complete: 63.3%; Average loss: 3.1506\n",
      "Iteration: 2534; Percent complete: 63.3%; Average loss: 2.8618\n",
      "Iteration: 2535; Percent complete: 63.4%; Average loss: 3.0549\n",
      "Iteration: 2536; Percent complete: 63.4%; Average loss: 3.1664\n",
      "Iteration: 2537; Percent complete: 63.4%; Average loss: 2.7106\n",
      "Iteration: 2538; Percent complete: 63.4%; Average loss: 3.1740\n",
      "Iteration: 2539; Percent complete: 63.5%; Average loss: 3.0385\n",
      "Iteration: 2540; Percent complete: 63.5%; Average loss: 3.2137\n",
      "Iteration: 2541; Percent complete: 63.5%; Average loss: 3.0837\n",
      "Iteration: 2542; Percent complete: 63.5%; Average loss: 3.0074\n",
      "Iteration: 2543; Percent complete: 63.6%; Average loss: 2.6155\n",
      "Iteration: 2544; Percent complete: 63.6%; Average loss: 3.2696\n",
      "Iteration: 2545; Percent complete: 63.6%; Average loss: 2.8813\n",
      "Iteration: 2546; Percent complete: 63.6%; Average loss: 3.0037\n",
      "Iteration: 2547; Percent complete: 63.7%; Average loss: 2.9897\n",
      "Iteration: 2548; Percent complete: 63.7%; Average loss: 3.0735\n",
      "Iteration: 2549; Percent complete: 63.7%; Average loss: 3.0650\n",
      "Iteration: 2550; Percent complete: 63.7%; Average loss: 3.1080\n",
      "Iteration: 2551; Percent complete: 63.8%; Average loss: 2.8200\n",
      "Iteration: 2552; Percent complete: 63.8%; Average loss: 2.9047\n",
      "Iteration: 2553; Percent complete: 63.8%; Average loss: 3.2542\n",
      "Iteration: 2554; Percent complete: 63.8%; Average loss: 2.9342\n",
      "Iteration: 2555; Percent complete: 63.9%; Average loss: 3.0346\n",
      "Iteration: 2556; Percent complete: 63.9%; Average loss: 2.8772\n",
      "Iteration: 2557; Percent complete: 63.9%; Average loss: 3.1414\n",
      "Iteration: 2558; Percent complete: 63.9%; Average loss: 3.0918\n",
      "Iteration: 2559; Percent complete: 64.0%; Average loss: 3.0061\n",
      "Iteration: 2560; Percent complete: 64.0%; Average loss: 2.8662\n",
      "Iteration: 2561; Percent complete: 64.0%; Average loss: 3.2474\n",
      "Iteration: 2562; Percent complete: 64.0%; Average loss: 3.0393\n",
      "Iteration: 2563; Percent complete: 64.1%; Average loss: 3.0809\n",
      "Iteration: 2564; Percent complete: 64.1%; Average loss: 2.8227\n",
      "Iteration: 2565; Percent complete: 64.1%; Average loss: 3.2218\n",
      "Iteration: 2566; Percent complete: 64.1%; Average loss: 2.9595\n",
      "Iteration: 2567; Percent complete: 64.2%; Average loss: 2.9379\n",
      "Iteration: 2568; Percent complete: 64.2%; Average loss: 2.9421\n",
      "Iteration: 2569; Percent complete: 64.2%; Average loss: 3.0058\n",
      "Iteration: 2570; Percent complete: 64.2%; Average loss: 3.0435\n",
      "Iteration: 2571; Percent complete: 64.3%; Average loss: 3.0110\n",
      "Iteration: 2572; Percent complete: 64.3%; Average loss: 2.8702\n",
      "Iteration: 2573; Percent complete: 64.3%; Average loss: 2.9370\n",
      "Iteration: 2574; Percent complete: 64.3%; Average loss: 3.0840\n",
      "Iteration: 2575; Percent complete: 64.4%; Average loss: 2.9967\n",
      "Iteration: 2576; Percent complete: 64.4%; Average loss: 3.0738\n",
      "Iteration: 2577; Percent complete: 64.4%; Average loss: 2.9509\n",
      "Iteration: 2578; Percent complete: 64.5%; Average loss: 2.8010\n",
      "Iteration: 2579; Percent complete: 64.5%; Average loss: 2.8671\n",
      "Iteration: 2580; Percent complete: 64.5%; Average loss: 3.0494\n",
      "Iteration: 2581; Percent complete: 64.5%; Average loss: 3.2313\n",
      "Iteration: 2582; Percent complete: 64.5%; Average loss: 2.8002\n",
      "Iteration: 2583; Percent complete: 64.6%; Average loss: 2.8280\n",
      "Iteration: 2584; Percent complete: 64.6%; Average loss: 2.7542\n",
      "Iteration: 2585; Percent complete: 64.6%; Average loss: 3.0977\n",
      "Iteration: 2586; Percent complete: 64.6%; Average loss: 3.0219\n",
      "Iteration: 2587; Percent complete: 64.7%; Average loss: 3.0494\n",
      "Iteration: 2588; Percent complete: 64.7%; Average loss: 2.8396\n",
      "Iteration: 2589; Percent complete: 64.7%; Average loss: 3.1587\n",
      "Iteration: 2590; Percent complete: 64.8%; Average loss: 3.2286\n",
      "Iteration: 2591; Percent complete: 64.8%; Average loss: 3.1454\n",
      "Iteration: 2592; Percent complete: 64.8%; Average loss: 2.9944\n",
      "Iteration: 2593; Percent complete: 64.8%; Average loss: 3.0932\n",
      "Iteration: 2594; Percent complete: 64.8%; Average loss: 2.8769\n",
      "Iteration: 2595; Percent complete: 64.9%; Average loss: 2.9790\n",
      "Iteration: 2596; Percent complete: 64.9%; Average loss: 3.0198\n",
      "Iteration: 2597; Percent complete: 64.9%; Average loss: 2.8238\n",
      "Iteration: 2598; Percent complete: 65.0%; Average loss: 3.0501\n",
      "Iteration: 2599; Percent complete: 65.0%; Average loss: 3.1038\n",
      "Iteration: 2600; Percent complete: 65.0%; Average loss: 2.9094\n",
      "Iteration: 2601; Percent complete: 65.0%; Average loss: 2.9104\n",
      "Iteration: 2602; Percent complete: 65.0%; Average loss: 3.0460\n",
      "Iteration: 2603; Percent complete: 65.1%; Average loss: 3.0343\n",
      "Iteration: 2604; Percent complete: 65.1%; Average loss: 3.2776\n",
      "Iteration: 2605; Percent complete: 65.1%; Average loss: 3.1113\n",
      "Iteration: 2606; Percent complete: 65.1%; Average loss: 3.2273\n",
      "Iteration: 2607; Percent complete: 65.2%; Average loss: 3.2279\n",
      "Iteration: 2608; Percent complete: 65.2%; Average loss: 3.0195\n",
      "Iteration: 2609; Percent complete: 65.2%; Average loss: 3.2257\n",
      "Iteration: 2610; Percent complete: 65.2%; Average loss: 3.0352\n",
      "Iteration: 2611; Percent complete: 65.3%; Average loss: 3.0399\n",
      "Iteration: 2612; Percent complete: 65.3%; Average loss: 2.9857\n",
      "Iteration: 2613; Percent complete: 65.3%; Average loss: 2.9917\n",
      "Iteration: 2614; Percent complete: 65.3%; Average loss: 3.0639\n",
      "Iteration: 2615; Percent complete: 65.4%; Average loss: 2.6918\n",
      "Iteration: 2616; Percent complete: 65.4%; Average loss: 3.0844\n",
      "Iteration: 2617; Percent complete: 65.4%; Average loss: 2.8985\n",
      "Iteration: 2618; Percent complete: 65.5%; Average loss: 2.9986\n",
      "Iteration: 2619; Percent complete: 65.5%; Average loss: 2.8861\n",
      "Iteration: 2620; Percent complete: 65.5%; Average loss: 3.1542\n",
      "Iteration: 2621; Percent complete: 65.5%; Average loss: 2.9965\n",
      "Iteration: 2622; Percent complete: 65.5%; Average loss: 2.7434\n",
      "Iteration: 2623; Percent complete: 65.6%; Average loss: 3.2364\n",
      "Iteration: 2624; Percent complete: 65.6%; Average loss: 3.0255\n",
      "Iteration: 2625; Percent complete: 65.6%; Average loss: 2.9321\n",
      "Iteration: 2626; Percent complete: 65.6%; Average loss: 3.0955\n",
      "Iteration: 2627; Percent complete: 65.7%; Average loss: 2.8944\n",
      "Iteration: 2628; Percent complete: 65.7%; Average loss: 3.0704\n",
      "Iteration: 2629; Percent complete: 65.7%; Average loss: 2.8900\n",
      "Iteration: 2630; Percent complete: 65.8%; Average loss: 2.8992\n",
      "Iteration: 2631; Percent complete: 65.8%; Average loss: 2.8165\n",
      "Iteration: 2632; Percent complete: 65.8%; Average loss: 2.9634\n",
      "Iteration: 2633; Percent complete: 65.8%; Average loss: 3.3636\n",
      "Iteration: 2634; Percent complete: 65.8%; Average loss: 3.0438\n",
      "Iteration: 2635; Percent complete: 65.9%; Average loss: 2.8746\n",
      "Iteration: 2636; Percent complete: 65.9%; Average loss: 3.1292\n",
      "Iteration: 2637; Percent complete: 65.9%; Average loss: 2.8750\n",
      "Iteration: 2638; Percent complete: 66.0%; Average loss: 2.7047\n",
      "Iteration: 2639; Percent complete: 66.0%; Average loss: 2.9193\n",
      "Iteration: 2640; Percent complete: 66.0%; Average loss: 2.9350\n",
      "Iteration: 2641; Percent complete: 66.0%; Average loss: 2.8696\n",
      "Iteration: 2642; Percent complete: 66.0%; Average loss: 3.2226\n",
      "Iteration: 2643; Percent complete: 66.1%; Average loss: 2.8267\n",
      "Iteration: 2644; Percent complete: 66.1%; Average loss: 2.9209\n",
      "Iteration: 2645; Percent complete: 66.1%; Average loss: 3.1970\n",
      "Iteration: 2646; Percent complete: 66.1%; Average loss: 2.9289\n",
      "Iteration: 2647; Percent complete: 66.2%; Average loss: 2.9753\n",
      "Iteration: 2648; Percent complete: 66.2%; Average loss: 3.0245\n",
      "Iteration: 2649; Percent complete: 66.2%; Average loss: 2.7824\n",
      "Iteration: 2650; Percent complete: 66.2%; Average loss: 2.8589\n",
      "Iteration: 2651; Percent complete: 66.3%; Average loss: 3.2010\n",
      "Iteration: 2652; Percent complete: 66.3%; Average loss: 3.1796\n",
      "Iteration: 2653; Percent complete: 66.3%; Average loss: 3.1595\n",
      "Iteration: 2654; Percent complete: 66.3%; Average loss: 2.9745\n",
      "Iteration: 2655; Percent complete: 66.4%; Average loss: 3.2552\n",
      "Iteration: 2656; Percent complete: 66.4%; Average loss: 3.0038\n",
      "Iteration: 2657; Percent complete: 66.4%; Average loss: 2.9362\n",
      "Iteration: 2658; Percent complete: 66.5%; Average loss: 2.8249\n",
      "Iteration: 2659; Percent complete: 66.5%; Average loss: 3.0315\n",
      "Iteration: 2660; Percent complete: 66.5%; Average loss: 3.2433\n",
      "Iteration: 2661; Percent complete: 66.5%; Average loss: 2.8465\n",
      "Iteration: 2662; Percent complete: 66.5%; Average loss: 3.0026\n",
      "Iteration: 2663; Percent complete: 66.6%; Average loss: 2.7188\n",
      "Iteration: 2664; Percent complete: 66.6%; Average loss: 2.9460\n",
      "Iteration: 2665; Percent complete: 66.6%; Average loss: 3.0766\n",
      "Iteration: 2666; Percent complete: 66.6%; Average loss: 2.9762\n",
      "Iteration: 2667; Percent complete: 66.7%; Average loss: 2.9885\n",
      "Iteration: 2668; Percent complete: 66.7%; Average loss: 2.9136\n",
      "Iteration: 2669; Percent complete: 66.7%; Average loss: 2.9530\n",
      "Iteration: 2670; Percent complete: 66.8%; Average loss: 3.1029\n",
      "Iteration: 2671; Percent complete: 66.8%; Average loss: 2.9581\n",
      "Iteration: 2672; Percent complete: 66.8%; Average loss: 2.8751\n",
      "Iteration: 2673; Percent complete: 66.8%; Average loss: 3.0228\n",
      "Iteration: 2674; Percent complete: 66.8%; Average loss: 2.9980\n",
      "Iteration: 2675; Percent complete: 66.9%; Average loss: 3.1778\n",
      "Iteration: 2676; Percent complete: 66.9%; Average loss: 3.0110\n",
      "Iteration: 2677; Percent complete: 66.9%; Average loss: 2.9999\n",
      "Iteration: 2678; Percent complete: 67.0%; Average loss: 2.8637\n",
      "Iteration: 2679; Percent complete: 67.0%; Average loss: 2.7602\n",
      "Iteration: 2680; Percent complete: 67.0%; Average loss: 2.9435\n",
      "Iteration: 2681; Percent complete: 67.0%; Average loss: 2.9638\n",
      "Iteration: 2682; Percent complete: 67.0%; Average loss: 2.9956\n",
      "Iteration: 2683; Percent complete: 67.1%; Average loss: 2.6761\n",
      "Iteration: 2684; Percent complete: 67.1%; Average loss: 2.9263\n",
      "Iteration: 2685; Percent complete: 67.1%; Average loss: 2.8377\n",
      "Iteration: 2686; Percent complete: 67.2%; Average loss: 2.8527\n",
      "Iteration: 2687; Percent complete: 67.2%; Average loss: 2.9922\n",
      "Iteration: 2688; Percent complete: 67.2%; Average loss: 2.9717\n",
      "Iteration: 2689; Percent complete: 67.2%; Average loss: 3.0173\n",
      "Iteration: 2690; Percent complete: 67.2%; Average loss: 2.9750\n",
      "Iteration: 2691; Percent complete: 67.3%; Average loss: 3.0568\n",
      "Iteration: 2692; Percent complete: 67.3%; Average loss: 2.9489\n",
      "Iteration: 2693; Percent complete: 67.3%; Average loss: 3.0926\n",
      "Iteration: 2694; Percent complete: 67.3%; Average loss: 2.7249\n",
      "Iteration: 2695; Percent complete: 67.4%; Average loss: 3.0322\n",
      "Iteration: 2696; Percent complete: 67.4%; Average loss: 2.9278\n",
      "Iteration: 2697; Percent complete: 67.4%; Average loss: 2.8933\n",
      "Iteration: 2698; Percent complete: 67.5%; Average loss: 3.0013\n",
      "Iteration: 2699; Percent complete: 67.5%; Average loss: 2.9842\n",
      "Iteration: 2700; Percent complete: 67.5%; Average loss: 2.8574\n",
      "Iteration: 2701; Percent complete: 67.5%; Average loss: 2.9005\n",
      "Iteration: 2702; Percent complete: 67.5%; Average loss: 2.7546\n",
      "Iteration: 2703; Percent complete: 67.6%; Average loss: 2.9167\n",
      "Iteration: 2704; Percent complete: 67.6%; Average loss: 2.9049\n",
      "Iteration: 2705; Percent complete: 67.6%; Average loss: 3.0145\n",
      "Iteration: 2706; Percent complete: 67.7%; Average loss: 2.8532\n",
      "Iteration: 2707; Percent complete: 67.7%; Average loss: 3.0567\n",
      "Iteration: 2708; Percent complete: 67.7%; Average loss: 3.2285\n",
      "Iteration: 2709; Percent complete: 67.7%; Average loss: 2.8267\n",
      "Iteration: 2710; Percent complete: 67.8%; Average loss: 3.0982\n",
      "Iteration: 2711; Percent complete: 67.8%; Average loss: 2.8877\n",
      "Iteration: 2712; Percent complete: 67.8%; Average loss: 2.9180\n",
      "Iteration: 2713; Percent complete: 67.8%; Average loss: 3.1380\n",
      "Iteration: 2714; Percent complete: 67.8%; Average loss: 2.7569\n",
      "Iteration: 2715; Percent complete: 67.9%; Average loss: 3.1548\n",
      "Iteration: 2716; Percent complete: 67.9%; Average loss: 2.8605\n",
      "Iteration: 2717; Percent complete: 67.9%; Average loss: 3.0388\n",
      "Iteration: 2718; Percent complete: 68.0%; Average loss: 2.8688\n",
      "Iteration: 2719; Percent complete: 68.0%; Average loss: 2.9155\n",
      "Iteration: 2720; Percent complete: 68.0%; Average loss: 2.9601\n",
      "Iteration: 2721; Percent complete: 68.0%; Average loss: 3.1063\n",
      "Iteration: 2722; Percent complete: 68.0%; Average loss: 2.9606\n",
      "Iteration: 2723; Percent complete: 68.1%; Average loss: 3.0425\n",
      "Iteration: 2724; Percent complete: 68.1%; Average loss: 3.0224\n",
      "Iteration: 2725; Percent complete: 68.1%; Average loss: 2.9436\n",
      "Iteration: 2726; Percent complete: 68.2%; Average loss: 2.9152\n",
      "Iteration: 2727; Percent complete: 68.2%; Average loss: 2.7811\n",
      "Iteration: 2728; Percent complete: 68.2%; Average loss: 2.9955\n",
      "Iteration: 2729; Percent complete: 68.2%; Average loss: 3.0642\n",
      "Iteration: 2730; Percent complete: 68.2%; Average loss: 2.7513\n",
      "Iteration: 2731; Percent complete: 68.3%; Average loss: 2.9346\n",
      "Iteration: 2732; Percent complete: 68.3%; Average loss: 2.8338\n",
      "Iteration: 2733; Percent complete: 68.3%; Average loss: 2.9069\n",
      "Iteration: 2734; Percent complete: 68.3%; Average loss: 3.0149\n",
      "Iteration: 2735; Percent complete: 68.4%; Average loss: 3.1079\n",
      "Iteration: 2736; Percent complete: 68.4%; Average loss: 2.9963\n",
      "Iteration: 2737; Percent complete: 68.4%; Average loss: 2.9656\n",
      "Iteration: 2738; Percent complete: 68.5%; Average loss: 3.0681\n",
      "Iteration: 2739; Percent complete: 68.5%; Average loss: 2.9722\n",
      "Iteration: 2740; Percent complete: 68.5%; Average loss: 2.9638\n",
      "Iteration: 2741; Percent complete: 68.5%; Average loss: 3.0068\n",
      "Iteration: 2742; Percent complete: 68.5%; Average loss: 2.8337\n",
      "Iteration: 2743; Percent complete: 68.6%; Average loss: 2.9058\n",
      "Iteration: 2744; Percent complete: 68.6%; Average loss: 3.0459\n",
      "Iteration: 2745; Percent complete: 68.6%; Average loss: 2.5502\n",
      "Iteration: 2746; Percent complete: 68.7%; Average loss: 3.0915\n",
      "Iteration: 2747; Percent complete: 68.7%; Average loss: 2.9855\n",
      "Iteration: 2748; Percent complete: 68.7%; Average loss: 2.9987\n",
      "Iteration: 2749; Percent complete: 68.7%; Average loss: 2.8893\n",
      "Iteration: 2750; Percent complete: 68.8%; Average loss: 2.7861\n",
      "Iteration: 2751; Percent complete: 68.8%; Average loss: 3.0766\n",
      "Iteration: 2752; Percent complete: 68.8%; Average loss: 2.8763\n",
      "Iteration: 2753; Percent complete: 68.8%; Average loss: 3.0608\n",
      "Iteration: 2754; Percent complete: 68.8%; Average loss: 2.8179\n",
      "Iteration: 2755; Percent complete: 68.9%; Average loss: 2.5586\n",
      "Iteration: 2756; Percent complete: 68.9%; Average loss: 2.8236\n",
      "Iteration: 2757; Percent complete: 68.9%; Average loss: 3.0911\n",
      "Iteration: 2758; Percent complete: 69.0%; Average loss: 3.0338\n",
      "Iteration: 2759; Percent complete: 69.0%; Average loss: 2.9071\n",
      "Iteration: 2760; Percent complete: 69.0%; Average loss: 3.0498\n",
      "Iteration: 2761; Percent complete: 69.0%; Average loss: 2.9858\n",
      "Iteration: 2762; Percent complete: 69.0%; Average loss: 2.8432\n",
      "Iteration: 2763; Percent complete: 69.1%; Average loss: 2.9627\n",
      "Iteration: 2764; Percent complete: 69.1%; Average loss: 3.0823\n",
      "Iteration: 2765; Percent complete: 69.1%; Average loss: 2.8110\n",
      "Iteration: 2766; Percent complete: 69.2%; Average loss: 3.2241\n",
      "Iteration: 2767; Percent complete: 69.2%; Average loss: 2.8854\n",
      "Iteration: 2768; Percent complete: 69.2%; Average loss: 2.9809\n",
      "Iteration: 2769; Percent complete: 69.2%; Average loss: 2.6752\n",
      "Iteration: 2770; Percent complete: 69.2%; Average loss: 2.7684\n",
      "Iteration: 2771; Percent complete: 69.3%; Average loss: 2.6598\n",
      "Iteration: 2772; Percent complete: 69.3%; Average loss: 3.0240\n",
      "Iteration: 2773; Percent complete: 69.3%; Average loss: 2.9068\n",
      "Iteration: 2774; Percent complete: 69.3%; Average loss: 2.9570\n",
      "Iteration: 2775; Percent complete: 69.4%; Average loss: 2.9165\n",
      "Iteration: 2776; Percent complete: 69.4%; Average loss: 2.9637\n",
      "Iteration: 2777; Percent complete: 69.4%; Average loss: 3.2319\n",
      "Iteration: 2778; Percent complete: 69.5%; Average loss: 3.2035\n",
      "Iteration: 2779; Percent complete: 69.5%; Average loss: 2.9817\n",
      "Iteration: 2780; Percent complete: 69.5%; Average loss: 2.9455\n",
      "Iteration: 2781; Percent complete: 69.5%; Average loss: 2.9081\n",
      "Iteration: 2782; Percent complete: 69.5%; Average loss: 2.9686\n",
      "Iteration: 2783; Percent complete: 69.6%; Average loss: 2.8813\n",
      "Iteration: 2784; Percent complete: 69.6%; Average loss: 3.0033\n",
      "Iteration: 2785; Percent complete: 69.6%; Average loss: 2.8987\n",
      "Iteration: 2786; Percent complete: 69.7%; Average loss: 3.1428\n",
      "Iteration: 2787; Percent complete: 69.7%; Average loss: 2.8328\n",
      "Iteration: 2788; Percent complete: 69.7%; Average loss: 2.8144\n",
      "Iteration: 2789; Percent complete: 69.7%; Average loss: 3.1540\n",
      "Iteration: 2790; Percent complete: 69.8%; Average loss: 3.1196\n",
      "Iteration: 2791; Percent complete: 69.8%; Average loss: 3.0040\n",
      "Iteration: 2792; Percent complete: 69.8%; Average loss: 3.0600\n",
      "Iteration: 2793; Percent complete: 69.8%; Average loss: 2.9361\n",
      "Iteration: 2794; Percent complete: 69.8%; Average loss: 3.0799\n",
      "Iteration: 2795; Percent complete: 69.9%; Average loss: 3.0402\n",
      "Iteration: 2796; Percent complete: 69.9%; Average loss: 2.7618\n",
      "Iteration: 2797; Percent complete: 69.9%; Average loss: 2.7964\n",
      "Iteration: 2798; Percent complete: 70.0%; Average loss: 2.8617\n",
      "Iteration: 2799; Percent complete: 70.0%; Average loss: 2.9878\n",
      "Iteration: 2800; Percent complete: 70.0%; Average loss: 2.7504\n",
      "Iteration: 2801; Percent complete: 70.0%; Average loss: 2.8580\n",
      "Iteration: 2802; Percent complete: 70.0%; Average loss: 2.8685\n",
      "Iteration: 2803; Percent complete: 70.1%; Average loss: 2.7516\n",
      "Iteration: 2804; Percent complete: 70.1%; Average loss: 2.7257\n",
      "Iteration: 2805; Percent complete: 70.1%; Average loss: 2.9471\n",
      "Iteration: 2806; Percent complete: 70.2%; Average loss: 2.8982\n",
      "Iteration: 2807; Percent complete: 70.2%; Average loss: 2.9259\n",
      "Iteration: 2808; Percent complete: 70.2%; Average loss: 3.0059\n",
      "Iteration: 2809; Percent complete: 70.2%; Average loss: 2.7959\n",
      "Iteration: 2810; Percent complete: 70.2%; Average loss: 2.6522\n",
      "Iteration: 2811; Percent complete: 70.3%; Average loss: 2.9103\n",
      "Iteration: 2812; Percent complete: 70.3%; Average loss: 3.0946\n",
      "Iteration: 2813; Percent complete: 70.3%; Average loss: 2.8603\n",
      "Iteration: 2814; Percent complete: 70.3%; Average loss: 2.8077\n",
      "Iteration: 2815; Percent complete: 70.4%; Average loss: 2.9464\n",
      "Iteration: 2816; Percent complete: 70.4%; Average loss: 2.8726\n",
      "Iteration: 2817; Percent complete: 70.4%; Average loss: 3.2415\n",
      "Iteration: 2818; Percent complete: 70.5%; Average loss: 2.9972\n",
      "Iteration: 2819; Percent complete: 70.5%; Average loss: 2.8944\n",
      "Iteration: 2820; Percent complete: 70.5%; Average loss: 3.0370\n",
      "Iteration: 2821; Percent complete: 70.5%; Average loss: 2.8722\n",
      "Iteration: 2822; Percent complete: 70.5%; Average loss: 3.0710\n",
      "Iteration: 2823; Percent complete: 70.6%; Average loss: 2.7812\n",
      "Iteration: 2824; Percent complete: 70.6%; Average loss: 2.9932\n",
      "Iteration: 2825; Percent complete: 70.6%; Average loss: 3.0553\n",
      "Iteration: 2826; Percent complete: 70.7%; Average loss: 3.1295\n",
      "Iteration: 2827; Percent complete: 70.7%; Average loss: 3.0668\n",
      "Iteration: 2828; Percent complete: 70.7%; Average loss: 3.0899\n",
      "Iteration: 2829; Percent complete: 70.7%; Average loss: 2.7914\n",
      "Iteration: 2830; Percent complete: 70.8%; Average loss: 2.8199\n",
      "Iteration: 2831; Percent complete: 70.8%; Average loss: 2.9094\n",
      "Iteration: 2832; Percent complete: 70.8%; Average loss: 2.9319\n",
      "Iteration: 2833; Percent complete: 70.8%; Average loss: 3.0194\n",
      "Iteration: 2834; Percent complete: 70.9%; Average loss: 2.6769\n",
      "Iteration: 2835; Percent complete: 70.9%; Average loss: 2.8394\n",
      "Iteration: 2836; Percent complete: 70.9%; Average loss: 3.0220\n",
      "Iteration: 2837; Percent complete: 70.9%; Average loss: 2.8327\n",
      "Iteration: 2838; Percent complete: 71.0%; Average loss: 2.7978\n",
      "Iteration: 2839; Percent complete: 71.0%; Average loss: 2.8368\n",
      "Iteration: 2840; Percent complete: 71.0%; Average loss: 2.9183\n",
      "Iteration: 2841; Percent complete: 71.0%; Average loss: 3.0764\n",
      "Iteration: 2842; Percent complete: 71.0%; Average loss: 2.9923\n",
      "Iteration: 2843; Percent complete: 71.1%; Average loss: 2.9126\n",
      "Iteration: 2844; Percent complete: 71.1%; Average loss: 2.7952\n",
      "Iteration: 2845; Percent complete: 71.1%; Average loss: 3.1327\n",
      "Iteration: 2846; Percent complete: 71.2%; Average loss: 2.9010\n",
      "Iteration: 2847; Percent complete: 71.2%; Average loss: 2.7796\n",
      "Iteration: 2848; Percent complete: 71.2%; Average loss: 3.0164\n",
      "Iteration: 2849; Percent complete: 71.2%; Average loss: 2.9841\n",
      "Iteration: 2850; Percent complete: 71.2%; Average loss: 2.9307\n",
      "Iteration: 2851; Percent complete: 71.3%; Average loss: 2.9832\n",
      "Iteration: 2852; Percent complete: 71.3%; Average loss: 2.9146\n",
      "Iteration: 2853; Percent complete: 71.3%; Average loss: 2.8312\n",
      "Iteration: 2854; Percent complete: 71.4%; Average loss: 2.9593\n",
      "Iteration: 2855; Percent complete: 71.4%; Average loss: 2.7897\n",
      "Iteration: 2856; Percent complete: 71.4%; Average loss: 2.8131\n",
      "Iteration: 2857; Percent complete: 71.4%; Average loss: 2.8403\n",
      "Iteration: 2858; Percent complete: 71.5%; Average loss: 2.7888\n",
      "Iteration: 2859; Percent complete: 71.5%; Average loss: 2.8594\n",
      "Iteration: 2860; Percent complete: 71.5%; Average loss: 2.8666\n",
      "Iteration: 2861; Percent complete: 71.5%; Average loss: 2.9241\n",
      "Iteration: 2862; Percent complete: 71.5%; Average loss: 2.7550\n",
      "Iteration: 2863; Percent complete: 71.6%; Average loss: 2.7998\n",
      "Iteration: 2864; Percent complete: 71.6%; Average loss: 3.0297\n",
      "Iteration: 2865; Percent complete: 71.6%; Average loss: 2.8772\n",
      "Iteration: 2866; Percent complete: 71.7%; Average loss: 3.0335\n",
      "Iteration: 2867; Percent complete: 71.7%; Average loss: 2.9476\n",
      "Iteration: 2868; Percent complete: 71.7%; Average loss: 3.0405\n",
      "Iteration: 2869; Percent complete: 71.7%; Average loss: 2.7103\n",
      "Iteration: 2870; Percent complete: 71.8%; Average loss: 2.8975\n",
      "Iteration: 2871; Percent complete: 71.8%; Average loss: 3.2626\n",
      "Iteration: 2872; Percent complete: 71.8%; Average loss: 2.6274\n",
      "Iteration: 2873; Percent complete: 71.8%; Average loss: 3.0785\n",
      "Iteration: 2874; Percent complete: 71.9%; Average loss: 3.1895\n",
      "Iteration: 2875; Percent complete: 71.9%; Average loss: 2.9454\n",
      "Iteration: 2876; Percent complete: 71.9%; Average loss: 2.9936\n",
      "Iteration: 2877; Percent complete: 71.9%; Average loss: 2.6867\n",
      "Iteration: 2878; Percent complete: 72.0%; Average loss: 2.8551\n",
      "Iteration: 2879; Percent complete: 72.0%; Average loss: 3.0061\n",
      "Iteration: 2880; Percent complete: 72.0%; Average loss: 2.8279\n",
      "Iteration: 2881; Percent complete: 72.0%; Average loss: 2.9551\n",
      "Iteration: 2882; Percent complete: 72.0%; Average loss: 3.1905\n",
      "Iteration: 2883; Percent complete: 72.1%; Average loss: 2.7876\n",
      "Iteration: 2884; Percent complete: 72.1%; Average loss: 2.7943\n",
      "Iteration: 2885; Percent complete: 72.1%; Average loss: 3.0628\n",
      "Iteration: 2886; Percent complete: 72.2%; Average loss: 2.9779\n",
      "Iteration: 2887; Percent complete: 72.2%; Average loss: 3.0812\n",
      "Iteration: 2888; Percent complete: 72.2%; Average loss: 2.9815\n",
      "Iteration: 2889; Percent complete: 72.2%; Average loss: 2.8360\n",
      "Iteration: 2890; Percent complete: 72.2%; Average loss: 2.7097\n",
      "Iteration: 2891; Percent complete: 72.3%; Average loss: 2.9955\n",
      "Iteration: 2892; Percent complete: 72.3%; Average loss: 2.9710\n",
      "Iteration: 2893; Percent complete: 72.3%; Average loss: 2.9034\n",
      "Iteration: 2894; Percent complete: 72.4%; Average loss: 2.8781\n",
      "Iteration: 2895; Percent complete: 72.4%; Average loss: 2.9648\n",
      "Iteration: 2896; Percent complete: 72.4%; Average loss: 2.8218\n",
      "Iteration: 2897; Percent complete: 72.4%; Average loss: 2.9542\n",
      "Iteration: 2898; Percent complete: 72.5%; Average loss: 2.8892\n",
      "Iteration: 2899; Percent complete: 72.5%; Average loss: 3.1090\n",
      "Iteration: 2900; Percent complete: 72.5%; Average loss: 2.9539\n",
      "Iteration: 2901; Percent complete: 72.5%; Average loss: 2.9935\n",
      "Iteration: 2902; Percent complete: 72.5%; Average loss: 2.6629\n",
      "Iteration: 2903; Percent complete: 72.6%; Average loss: 2.9627\n",
      "Iteration: 2904; Percent complete: 72.6%; Average loss: 2.8354\n",
      "Iteration: 2905; Percent complete: 72.6%; Average loss: 2.9876\n",
      "Iteration: 2906; Percent complete: 72.7%; Average loss: 2.8022\n",
      "Iteration: 2907; Percent complete: 72.7%; Average loss: 3.1498\n",
      "Iteration: 2908; Percent complete: 72.7%; Average loss: 2.9000\n",
      "Iteration: 2909; Percent complete: 72.7%; Average loss: 3.0950\n",
      "Iteration: 2910; Percent complete: 72.8%; Average loss: 2.7017\n",
      "Iteration: 2911; Percent complete: 72.8%; Average loss: 2.8750\n",
      "Iteration: 2912; Percent complete: 72.8%; Average loss: 2.9354\n",
      "Iteration: 2913; Percent complete: 72.8%; Average loss: 3.0945\n",
      "Iteration: 2914; Percent complete: 72.9%; Average loss: 3.0731\n",
      "Iteration: 2915; Percent complete: 72.9%; Average loss: 2.9518\n",
      "Iteration: 2916; Percent complete: 72.9%; Average loss: 2.8993\n",
      "Iteration: 2917; Percent complete: 72.9%; Average loss: 2.7700\n",
      "Iteration: 2918; Percent complete: 73.0%; Average loss: 2.9766\n",
      "Iteration: 2919; Percent complete: 73.0%; Average loss: 2.7121\n",
      "Iteration: 2920; Percent complete: 73.0%; Average loss: 2.9228\n",
      "Iteration: 2921; Percent complete: 73.0%; Average loss: 3.0062\n",
      "Iteration: 2922; Percent complete: 73.0%; Average loss: 2.9907\n",
      "Iteration: 2923; Percent complete: 73.1%; Average loss: 2.7383\n",
      "Iteration: 2924; Percent complete: 73.1%; Average loss: 2.8742\n",
      "Iteration: 2925; Percent complete: 73.1%; Average loss: 2.7704\n",
      "Iteration: 2926; Percent complete: 73.2%; Average loss: 3.0878\n",
      "Iteration: 2927; Percent complete: 73.2%; Average loss: 3.0383\n",
      "Iteration: 2928; Percent complete: 73.2%; Average loss: 3.0491\n",
      "Iteration: 2929; Percent complete: 73.2%; Average loss: 2.8969\n",
      "Iteration: 2930; Percent complete: 73.2%; Average loss: 2.8859\n",
      "Iteration: 2931; Percent complete: 73.3%; Average loss: 2.8969\n",
      "Iteration: 2932; Percent complete: 73.3%; Average loss: 3.0829\n",
      "Iteration: 2933; Percent complete: 73.3%; Average loss: 2.8648\n",
      "Iteration: 2934; Percent complete: 73.4%; Average loss: 2.7475\n",
      "Iteration: 2935; Percent complete: 73.4%; Average loss: 3.4020\n",
      "Iteration: 2936; Percent complete: 73.4%; Average loss: 2.7819\n",
      "Iteration: 2937; Percent complete: 73.4%; Average loss: 2.9354\n",
      "Iteration: 2938; Percent complete: 73.5%; Average loss: 2.8160\n",
      "Iteration: 2939; Percent complete: 73.5%; Average loss: 2.7817\n",
      "Iteration: 2940; Percent complete: 73.5%; Average loss: 2.6799\n",
      "Iteration: 2941; Percent complete: 73.5%; Average loss: 2.9063\n",
      "Iteration: 2942; Percent complete: 73.6%; Average loss: 3.0292\n",
      "Iteration: 2943; Percent complete: 73.6%; Average loss: 2.6448\n",
      "Iteration: 2944; Percent complete: 73.6%; Average loss: 3.1482\n",
      "Iteration: 2945; Percent complete: 73.6%; Average loss: 2.8997\n",
      "Iteration: 2946; Percent complete: 73.7%; Average loss: 2.9586\n",
      "Iteration: 2947; Percent complete: 73.7%; Average loss: 2.8941\n",
      "Iteration: 2948; Percent complete: 73.7%; Average loss: 2.8444\n",
      "Iteration: 2949; Percent complete: 73.7%; Average loss: 3.0576\n",
      "Iteration: 2950; Percent complete: 73.8%; Average loss: 3.0507\n",
      "Iteration: 2951; Percent complete: 73.8%; Average loss: 2.7605\n",
      "Iteration: 2952; Percent complete: 73.8%; Average loss: 3.0545\n",
      "Iteration: 2953; Percent complete: 73.8%; Average loss: 2.6876\n",
      "Iteration: 2954; Percent complete: 73.9%; Average loss: 2.8494\n",
      "Iteration: 2955; Percent complete: 73.9%; Average loss: 3.0959\n",
      "Iteration: 2956; Percent complete: 73.9%; Average loss: 2.7438\n",
      "Iteration: 2957; Percent complete: 73.9%; Average loss: 2.7802\n",
      "Iteration: 2958; Percent complete: 74.0%; Average loss: 2.5535\n",
      "Iteration: 2959; Percent complete: 74.0%; Average loss: 3.0118\n",
      "Iteration: 2960; Percent complete: 74.0%; Average loss: 2.7613\n",
      "Iteration: 2961; Percent complete: 74.0%; Average loss: 2.8696\n",
      "Iteration: 2962; Percent complete: 74.1%; Average loss: 2.9938\n",
      "Iteration: 2963; Percent complete: 74.1%; Average loss: 2.9215\n",
      "Iteration: 2964; Percent complete: 74.1%; Average loss: 2.9053\n",
      "Iteration: 2965; Percent complete: 74.1%; Average loss: 3.0314\n",
      "Iteration: 2966; Percent complete: 74.2%; Average loss: 2.9922\n",
      "Iteration: 2967; Percent complete: 74.2%; Average loss: 3.0080\n",
      "Iteration: 2968; Percent complete: 74.2%; Average loss: 2.8914\n",
      "Iteration: 2969; Percent complete: 74.2%; Average loss: 2.7259\n",
      "Iteration: 2970; Percent complete: 74.2%; Average loss: 2.7464\n",
      "Iteration: 2971; Percent complete: 74.3%; Average loss: 3.0716\n",
      "Iteration: 2972; Percent complete: 74.3%; Average loss: 3.0906\n",
      "Iteration: 2973; Percent complete: 74.3%; Average loss: 3.0441\n",
      "Iteration: 2974; Percent complete: 74.4%; Average loss: 2.9178\n",
      "Iteration: 2975; Percent complete: 74.4%; Average loss: 2.8915\n",
      "Iteration: 2976; Percent complete: 74.4%; Average loss: 2.6867\n",
      "Iteration: 2977; Percent complete: 74.4%; Average loss: 2.9638\n",
      "Iteration: 2978; Percent complete: 74.5%; Average loss: 2.7096\n",
      "Iteration: 2979; Percent complete: 74.5%; Average loss: 2.7930\n",
      "Iteration: 2980; Percent complete: 74.5%; Average loss: 3.0344\n",
      "Iteration: 2981; Percent complete: 74.5%; Average loss: 2.9932\n",
      "Iteration: 2982; Percent complete: 74.6%; Average loss: 2.9410\n",
      "Iteration: 2983; Percent complete: 74.6%; Average loss: 2.6728\n",
      "Iteration: 2984; Percent complete: 74.6%; Average loss: 2.6244\n",
      "Iteration: 2985; Percent complete: 74.6%; Average loss: 2.9220\n",
      "Iteration: 2986; Percent complete: 74.7%; Average loss: 2.8158\n",
      "Iteration: 2987; Percent complete: 74.7%; Average loss: 3.0462\n",
      "Iteration: 2988; Percent complete: 74.7%; Average loss: 2.8750\n",
      "Iteration: 2989; Percent complete: 74.7%; Average loss: 2.6633\n",
      "Iteration: 2990; Percent complete: 74.8%; Average loss: 3.1500\n",
      "Iteration: 2991; Percent complete: 74.8%; Average loss: 2.8159\n",
      "Iteration: 2992; Percent complete: 74.8%; Average loss: 2.7437\n",
      "Iteration: 2993; Percent complete: 74.8%; Average loss: 2.9685\n",
      "Iteration: 2994; Percent complete: 74.9%; Average loss: 2.9506\n",
      "Iteration: 2995; Percent complete: 74.9%; Average loss: 3.0977\n",
      "Iteration: 2996; Percent complete: 74.9%; Average loss: 3.0489\n",
      "Iteration: 2997; Percent complete: 74.9%; Average loss: 3.0138\n",
      "Iteration: 2998; Percent complete: 75.0%; Average loss: 2.9891\n",
      "Iteration: 2999; Percent complete: 75.0%; Average loss: 2.9733\n",
      "Iteration: 3000; Percent complete: 75.0%; Average loss: 2.9357\n",
      "Iteration: 3001; Percent complete: 75.0%; Average loss: 2.8092\n",
      "Iteration: 3002; Percent complete: 75.0%; Average loss: 2.8705\n",
      "Iteration: 3003; Percent complete: 75.1%; Average loss: 2.9608\n",
      "Iteration: 3004; Percent complete: 75.1%; Average loss: 2.8782\n",
      "Iteration: 3005; Percent complete: 75.1%; Average loss: 2.9570\n",
      "Iteration: 3006; Percent complete: 75.1%; Average loss: 2.8634\n",
      "Iteration: 3007; Percent complete: 75.2%; Average loss: 2.8878\n",
      "Iteration: 3008; Percent complete: 75.2%; Average loss: 2.8199\n",
      "Iteration: 3009; Percent complete: 75.2%; Average loss: 3.0053\n",
      "Iteration: 3010; Percent complete: 75.2%; Average loss: 2.9324\n",
      "Iteration: 3011; Percent complete: 75.3%; Average loss: 2.9002\n",
      "Iteration: 3012; Percent complete: 75.3%; Average loss: 3.0516\n",
      "Iteration: 3013; Percent complete: 75.3%; Average loss: 2.9159\n",
      "Iteration: 3014; Percent complete: 75.3%; Average loss: 2.9177\n",
      "Iteration: 3015; Percent complete: 75.4%; Average loss: 2.9223\n",
      "Iteration: 3016; Percent complete: 75.4%; Average loss: 2.9078\n",
      "Iteration: 3017; Percent complete: 75.4%; Average loss: 3.0318\n",
      "Iteration: 3018; Percent complete: 75.4%; Average loss: 2.9476\n",
      "Iteration: 3019; Percent complete: 75.5%; Average loss: 2.8563\n",
      "Iteration: 3020; Percent complete: 75.5%; Average loss: 2.9087\n",
      "Iteration: 3021; Percent complete: 75.5%; Average loss: 3.1355\n",
      "Iteration: 3022; Percent complete: 75.5%; Average loss: 2.9919\n",
      "Iteration: 3023; Percent complete: 75.6%; Average loss: 2.8395\n",
      "Iteration: 3024; Percent complete: 75.6%; Average loss: 2.9893\n",
      "Iteration: 3025; Percent complete: 75.6%; Average loss: 3.2082\n",
      "Iteration: 3026; Percent complete: 75.6%; Average loss: 2.8194\n",
      "Iteration: 3027; Percent complete: 75.7%; Average loss: 2.6423\n",
      "Iteration: 3028; Percent complete: 75.7%; Average loss: 2.9622\n",
      "Iteration: 3029; Percent complete: 75.7%; Average loss: 2.7897\n",
      "Iteration: 3030; Percent complete: 75.8%; Average loss: 2.7169\n",
      "Iteration: 3031; Percent complete: 75.8%; Average loss: 2.7786\n",
      "Iteration: 3032; Percent complete: 75.8%; Average loss: 2.8090\n",
      "Iteration: 3033; Percent complete: 75.8%; Average loss: 3.0403\n",
      "Iteration: 3034; Percent complete: 75.8%; Average loss: 2.6833\n",
      "Iteration: 3035; Percent complete: 75.9%; Average loss: 2.7725\n",
      "Iteration: 3036; Percent complete: 75.9%; Average loss: 2.7909\n",
      "Iteration: 3037; Percent complete: 75.9%; Average loss: 2.9215\n",
      "Iteration: 3038; Percent complete: 75.9%; Average loss: 2.8880\n",
      "Iteration: 3039; Percent complete: 76.0%; Average loss: 3.1363\n",
      "Iteration: 3040; Percent complete: 76.0%; Average loss: 2.9210\n",
      "Iteration: 3041; Percent complete: 76.0%; Average loss: 3.1818\n",
      "Iteration: 3042; Percent complete: 76.0%; Average loss: 2.8843\n",
      "Iteration: 3043; Percent complete: 76.1%; Average loss: 2.6322\n",
      "Iteration: 3044; Percent complete: 76.1%; Average loss: 2.8226\n",
      "Iteration: 3045; Percent complete: 76.1%; Average loss: 2.7612\n",
      "Iteration: 3046; Percent complete: 76.1%; Average loss: 2.8491\n",
      "Iteration: 3047; Percent complete: 76.2%; Average loss: 2.8252\n",
      "Iteration: 3048; Percent complete: 76.2%; Average loss: 2.8672\n",
      "Iteration: 3049; Percent complete: 76.2%; Average loss: 3.0725\n",
      "Iteration: 3050; Percent complete: 76.2%; Average loss: 2.6355\n",
      "Iteration: 3051; Percent complete: 76.3%; Average loss: 3.0267\n",
      "Iteration: 3052; Percent complete: 76.3%; Average loss: 2.7756\n",
      "Iteration: 3053; Percent complete: 76.3%; Average loss: 2.8999\n",
      "Iteration: 3054; Percent complete: 76.3%; Average loss: 2.7297\n",
      "Iteration: 3055; Percent complete: 76.4%; Average loss: 2.9017\n",
      "Iteration: 3056; Percent complete: 76.4%; Average loss: 2.8614\n",
      "Iteration: 3057; Percent complete: 76.4%; Average loss: 2.9103\n",
      "Iteration: 3058; Percent complete: 76.4%; Average loss: 2.9228\n",
      "Iteration: 3059; Percent complete: 76.5%; Average loss: 2.9057\n",
      "Iteration: 3060; Percent complete: 76.5%; Average loss: 2.8180\n",
      "Iteration: 3061; Percent complete: 76.5%; Average loss: 2.8708\n",
      "Iteration: 3062; Percent complete: 76.5%; Average loss: 2.8121\n",
      "Iteration: 3063; Percent complete: 76.6%; Average loss: 2.8796\n",
      "Iteration: 3064; Percent complete: 76.6%; Average loss: 2.8903\n",
      "Iteration: 3065; Percent complete: 76.6%; Average loss: 2.9282\n",
      "Iteration: 3066; Percent complete: 76.6%; Average loss: 2.7941\n",
      "Iteration: 3067; Percent complete: 76.7%; Average loss: 2.8311\n",
      "Iteration: 3068; Percent complete: 76.7%; Average loss: 2.7265\n",
      "Iteration: 3069; Percent complete: 76.7%; Average loss: 2.8328\n",
      "Iteration: 3070; Percent complete: 76.8%; Average loss: 2.6190\n",
      "Iteration: 3071; Percent complete: 76.8%; Average loss: 2.8061\n",
      "Iteration: 3072; Percent complete: 76.8%; Average loss: 2.8321\n",
      "Iteration: 3073; Percent complete: 76.8%; Average loss: 3.2295\n",
      "Iteration: 3074; Percent complete: 76.8%; Average loss: 2.9620\n",
      "Iteration: 3075; Percent complete: 76.9%; Average loss: 2.6073\n",
      "Iteration: 3076; Percent complete: 76.9%; Average loss: 2.6937\n",
      "Iteration: 3077; Percent complete: 76.9%; Average loss: 2.7879\n",
      "Iteration: 3078; Percent complete: 77.0%; Average loss: 2.7540\n",
      "Iteration: 3079; Percent complete: 77.0%; Average loss: 2.8467\n",
      "Iteration: 3080; Percent complete: 77.0%; Average loss: 2.9061\n",
      "Iteration: 3081; Percent complete: 77.0%; Average loss: 2.8316\n",
      "Iteration: 3082; Percent complete: 77.0%; Average loss: 2.6672\n",
      "Iteration: 3083; Percent complete: 77.1%; Average loss: 2.8990\n",
      "Iteration: 3084; Percent complete: 77.1%; Average loss: 2.7778\n",
      "Iteration: 3085; Percent complete: 77.1%; Average loss: 2.9400\n",
      "Iteration: 3086; Percent complete: 77.1%; Average loss: 2.6451\n",
      "Iteration: 3087; Percent complete: 77.2%; Average loss: 2.6923\n",
      "Iteration: 3088; Percent complete: 77.2%; Average loss: 2.8971\n",
      "Iteration: 3089; Percent complete: 77.2%; Average loss: 2.7108\n",
      "Iteration: 3090; Percent complete: 77.2%; Average loss: 2.9312\n",
      "Iteration: 3091; Percent complete: 77.3%; Average loss: 2.8065\n",
      "Iteration: 3092; Percent complete: 77.3%; Average loss: 2.6729\n",
      "Iteration: 3093; Percent complete: 77.3%; Average loss: 2.7770\n",
      "Iteration: 3094; Percent complete: 77.3%; Average loss: 2.9211\n",
      "Iteration: 3095; Percent complete: 77.4%; Average loss: 2.8852\n",
      "Iteration: 3096; Percent complete: 77.4%; Average loss: 2.7850\n",
      "Iteration: 3097; Percent complete: 77.4%; Average loss: 2.7957\n",
      "Iteration: 3098; Percent complete: 77.5%; Average loss: 2.7621\n",
      "Iteration: 3099; Percent complete: 77.5%; Average loss: 2.8050\n",
      "Iteration: 3100; Percent complete: 77.5%; Average loss: 2.7617\n",
      "Iteration: 3101; Percent complete: 77.5%; Average loss: 2.9096\n",
      "Iteration: 3102; Percent complete: 77.5%; Average loss: 2.7998\n",
      "Iteration: 3103; Percent complete: 77.6%; Average loss: 2.7245\n",
      "Iteration: 3104; Percent complete: 77.6%; Average loss: 2.9060\n",
      "Iteration: 3105; Percent complete: 77.6%; Average loss: 2.7620\n",
      "Iteration: 3106; Percent complete: 77.6%; Average loss: 3.0188\n",
      "Iteration: 3107; Percent complete: 77.7%; Average loss: 2.6290\n",
      "Iteration: 3108; Percent complete: 77.7%; Average loss: 2.7612\n",
      "Iteration: 3109; Percent complete: 77.7%; Average loss: 2.8992\n",
      "Iteration: 3110; Percent complete: 77.8%; Average loss: 3.1011\n",
      "Iteration: 3111; Percent complete: 77.8%; Average loss: 2.8471\n",
      "Iteration: 3112; Percent complete: 77.8%; Average loss: 2.8335\n",
      "Iteration: 3113; Percent complete: 77.8%; Average loss: 2.9999\n",
      "Iteration: 3114; Percent complete: 77.8%; Average loss: 3.1837\n",
      "Iteration: 3115; Percent complete: 77.9%; Average loss: 2.7911\n",
      "Iteration: 3116; Percent complete: 77.9%; Average loss: 2.8297\n",
      "Iteration: 3117; Percent complete: 77.9%; Average loss: 2.8399\n",
      "Iteration: 3118; Percent complete: 78.0%; Average loss: 2.7940\n",
      "Iteration: 3119; Percent complete: 78.0%; Average loss: 2.6527\n",
      "Iteration: 3120; Percent complete: 78.0%; Average loss: 2.9140\n",
      "Iteration: 3121; Percent complete: 78.0%; Average loss: 2.6164\n",
      "Iteration: 3122; Percent complete: 78.0%; Average loss: 3.0743\n",
      "Iteration: 3123; Percent complete: 78.1%; Average loss: 2.6136\n",
      "Iteration: 3124; Percent complete: 78.1%; Average loss: 2.7134\n",
      "Iteration: 3125; Percent complete: 78.1%; Average loss: 2.7049\n",
      "Iteration: 3126; Percent complete: 78.1%; Average loss: 2.8565\n",
      "Iteration: 3127; Percent complete: 78.2%; Average loss: 2.9278\n",
      "Iteration: 3128; Percent complete: 78.2%; Average loss: 2.7772\n",
      "Iteration: 3129; Percent complete: 78.2%; Average loss: 2.8107\n",
      "Iteration: 3130; Percent complete: 78.2%; Average loss: 2.8486\n",
      "Iteration: 3131; Percent complete: 78.3%; Average loss: 2.7065\n",
      "Iteration: 3132; Percent complete: 78.3%; Average loss: 2.6814\n",
      "Iteration: 3133; Percent complete: 78.3%; Average loss: 2.8686\n",
      "Iteration: 3134; Percent complete: 78.3%; Average loss: 3.1442\n",
      "Iteration: 3135; Percent complete: 78.4%; Average loss: 2.8334\n",
      "Iteration: 3136; Percent complete: 78.4%; Average loss: 2.7880\n",
      "Iteration: 3137; Percent complete: 78.4%; Average loss: 2.9166\n",
      "Iteration: 3138; Percent complete: 78.5%; Average loss: 2.7405\n",
      "Iteration: 3139; Percent complete: 78.5%; Average loss: 3.0819\n",
      "Iteration: 3140; Percent complete: 78.5%; Average loss: 2.9483\n",
      "Iteration: 3141; Percent complete: 78.5%; Average loss: 2.7527\n",
      "Iteration: 3142; Percent complete: 78.5%; Average loss: 2.8566\n",
      "Iteration: 3143; Percent complete: 78.6%; Average loss: 2.8262\n",
      "Iteration: 3144; Percent complete: 78.6%; Average loss: 2.8635\n",
      "Iteration: 3145; Percent complete: 78.6%; Average loss: 2.7892\n",
      "Iteration: 3146; Percent complete: 78.6%; Average loss: 2.7291\n",
      "Iteration: 3147; Percent complete: 78.7%; Average loss: 2.9425\n",
      "Iteration: 3148; Percent complete: 78.7%; Average loss: 2.6925\n",
      "Iteration: 3149; Percent complete: 78.7%; Average loss: 2.6886\n",
      "Iteration: 3150; Percent complete: 78.8%; Average loss: 2.8279\n",
      "Iteration: 3151; Percent complete: 78.8%; Average loss: 2.7638\n",
      "Iteration: 3152; Percent complete: 78.8%; Average loss: 2.7155\n",
      "Iteration: 3153; Percent complete: 78.8%; Average loss: 2.6350\n",
      "Iteration: 3154; Percent complete: 78.8%; Average loss: 3.0614\n",
      "Iteration: 3155; Percent complete: 78.9%; Average loss: 2.8030\n",
      "Iteration: 3156; Percent complete: 78.9%; Average loss: 2.8196\n",
      "Iteration: 3157; Percent complete: 78.9%; Average loss: 2.8922\n",
      "Iteration: 3158; Percent complete: 79.0%; Average loss: 2.8866\n",
      "Iteration: 3159; Percent complete: 79.0%; Average loss: 2.8563\n",
      "Iteration: 3160; Percent complete: 79.0%; Average loss: 2.7527\n",
      "Iteration: 3161; Percent complete: 79.0%; Average loss: 2.8517\n",
      "Iteration: 3162; Percent complete: 79.0%; Average loss: 2.5093\n",
      "Iteration: 3163; Percent complete: 79.1%; Average loss: 3.0855\n",
      "Iteration: 3164; Percent complete: 79.1%; Average loss: 2.8036\n",
      "Iteration: 3165; Percent complete: 79.1%; Average loss: 3.0055\n",
      "Iteration: 3166; Percent complete: 79.1%; Average loss: 2.7585\n",
      "Iteration: 3167; Percent complete: 79.2%; Average loss: 2.9728\n",
      "Iteration: 3168; Percent complete: 79.2%; Average loss: 2.8109\n",
      "Iteration: 3169; Percent complete: 79.2%; Average loss: 2.6927\n",
      "Iteration: 3170; Percent complete: 79.2%; Average loss: 2.9480\n",
      "Iteration: 3171; Percent complete: 79.3%; Average loss: 2.8216\n",
      "Iteration: 3172; Percent complete: 79.3%; Average loss: 2.7929\n",
      "Iteration: 3173; Percent complete: 79.3%; Average loss: 2.9728\n",
      "Iteration: 3174; Percent complete: 79.3%; Average loss: 2.7576\n",
      "Iteration: 3175; Percent complete: 79.4%; Average loss: 2.8780\n",
      "Iteration: 3176; Percent complete: 79.4%; Average loss: 2.8704\n",
      "Iteration: 3177; Percent complete: 79.4%; Average loss: 2.7198\n",
      "Iteration: 3178; Percent complete: 79.5%; Average loss: 3.0021\n",
      "Iteration: 3179; Percent complete: 79.5%; Average loss: 2.7362\n",
      "Iteration: 3180; Percent complete: 79.5%; Average loss: 2.8147\n",
      "Iteration: 3181; Percent complete: 79.5%; Average loss: 2.6615\n",
      "Iteration: 3182; Percent complete: 79.5%; Average loss: 2.7305\n",
      "Iteration: 3183; Percent complete: 79.6%; Average loss: 2.7453\n",
      "Iteration: 3184; Percent complete: 79.6%; Average loss: 2.8089\n",
      "Iteration: 3185; Percent complete: 79.6%; Average loss: 2.9210\n",
      "Iteration: 3186; Percent complete: 79.7%; Average loss: 2.5632\n",
      "Iteration: 3187; Percent complete: 79.7%; Average loss: 2.9106\n",
      "Iteration: 3188; Percent complete: 79.7%; Average loss: 3.0693\n",
      "Iteration: 3189; Percent complete: 79.7%; Average loss: 2.7385\n",
      "Iteration: 3190; Percent complete: 79.8%; Average loss: 3.0175\n",
      "Iteration: 3191; Percent complete: 79.8%; Average loss: 2.9093\n",
      "Iteration: 3192; Percent complete: 79.8%; Average loss: 2.8568\n",
      "Iteration: 3193; Percent complete: 79.8%; Average loss: 2.7054\n",
      "Iteration: 3194; Percent complete: 79.8%; Average loss: 2.9797\n",
      "Iteration: 3195; Percent complete: 79.9%; Average loss: 2.9680\n",
      "Iteration: 3196; Percent complete: 79.9%; Average loss: 2.8626\n",
      "Iteration: 3197; Percent complete: 79.9%; Average loss: 2.7779\n",
      "Iteration: 3198; Percent complete: 80.0%; Average loss: 3.0058\n",
      "Iteration: 3199; Percent complete: 80.0%; Average loss: 2.7425\n",
      "Iteration: 3200; Percent complete: 80.0%; Average loss: 2.8558\n",
      "Iteration: 3201; Percent complete: 80.0%; Average loss: 3.0021\n",
      "Iteration: 3202; Percent complete: 80.0%; Average loss: 2.8705\n",
      "Iteration: 3203; Percent complete: 80.1%; Average loss: 2.8362\n",
      "Iteration: 3204; Percent complete: 80.1%; Average loss: 2.8670\n",
      "Iteration: 3205; Percent complete: 80.1%; Average loss: 2.6027\n",
      "Iteration: 3206; Percent complete: 80.2%; Average loss: 2.7443\n",
      "Iteration: 3207; Percent complete: 80.2%; Average loss: 2.8722\n",
      "Iteration: 3208; Percent complete: 80.2%; Average loss: 3.0095\n",
      "Iteration: 3209; Percent complete: 80.2%; Average loss: 3.0660\n",
      "Iteration: 3210; Percent complete: 80.2%; Average loss: 2.9273\n",
      "Iteration: 3211; Percent complete: 80.3%; Average loss: 2.8697\n",
      "Iteration: 3212; Percent complete: 80.3%; Average loss: 2.9546\n",
      "Iteration: 3213; Percent complete: 80.3%; Average loss: 2.8880\n",
      "Iteration: 3214; Percent complete: 80.3%; Average loss: 2.8072\n",
      "Iteration: 3215; Percent complete: 80.4%; Average loss: 2.9747\n",
      "Iteration: 3216; Percent complete: 80.4%; Average loss: 2.7713\n",
      "Iteration: 3217; Percent complete: 80.4%; Average loss: 2.8272\n",
      "Iteration: 3218; Percent complete: 80.5%; Average loss: 2.8666\n",
      "Iteration: 3219; Percent complete: 80.5%; Average loss: 2.6254\n",
      "Iteration: 3220; Percent complete: 80.5%; Average loss: 2.8812\n",
      "Iteration: 3221; Percent complete: 80.5%; Average loss: 2.9393\n",
      "Iteration: 3222; Percent complete: 80.5%; Average loss: 2.8712\n",
      "Iteration: 3223; Percent complete: 80.6%; Average loss: 2.7416\n",
      "Iteration: 3224; Percent complete: 80.6%; Average loss: 2.6847\n",
      "Iteration: 3225; Percent complete: 80.6%; Average loss: 2.8571\n",
      "Iteration: 3226; Percent complete: 80.7%; Average loss: 2.6676\n",
      "Iteration: 3227; Percent complete: 80.7%; Average loss: 2.7207\n",
      "Iteration: 3228; Percent complete: 80.7%; Average loss: 2.8412\n",
      "Iteration: 3229; Percent complete: 80.7%; Average loss: 2.7326\n",
      "Iteration: 3230; Percent complete: 80.8%; Average loss: 2.7722\n",
      "Iteration: 3231; Percent complete: 80.8%; Average loss: 2.6594\n",
      "Iteration: 3232; Percent complete: 80.8%; Average loss: 2.7645\n",
      "Iteration: 3233; Percent complete: 80.8%; Average loss: 2.6013\n",
      "Iteration: 3234; Percent complete: 80.8%; Average loss: 2.7871\n",
      "Iteration: 3235; Percent complete: 80.9%; Average loss: 2.9532\n",
      "Iteration: 3236; Percent complete: 80.9%; Average loss: 2.7464\n",
      "Iteration: 3237; Percent complete: 80.9%; Average loss: 2.7431\n",
      "Iteration: 3238; Percent complete: 81.0%; Average loss: 2.6413\n",
      "Iteration: 3239; Percent complete: 81.0%; Average loss: 2.8418\n",
      "Iteration: 3240; Percent complete: 81.0%; Average loss: 2.6745\n",
      "Iteration: 3241; Percent complete: 81.0%; Average loss: 2.7505\n",
      "Iteration: 3242; Percent complete: 81.0%; Average loss: 2.7462\n",
      "Iteration: 3243; Percent complete: 81.1%; Average loss: 2.7887\n",
      "Iteration: 3244; Percent complete: 81.1%; Average loss: 2.6753\n",
      "Iteration: 3245; Percent complete: 81.1%; Average loss: 2.7981\n",
      "Iteration: 3246; Percent complete: 81.2%; Average loss: 2.9032\n",
      "Iteration: 3247; Percent complete: 81.2%; Average loss: 2.7923\n",
      "Iteration: 3248; Percent complete: 81.2%; Average loss: 2.5653\n",
      "Iteration: 3249; Percent complete: 81.2%; Average loss: 2.5290\n",
      "Iteration: 3250; Percent complete: 81.2%; Average loss: 2.6837\n",
      "Iteration: 3251; Percent complete: 81.3%; Average loss: 2.8940\n",
      "Iteration: 3252; Percent complete: 81.3%; Average loss: 2.6113\n",
      "Iteration: 3253; Percent complete: 81.3%; Average loss: 2.9735\n",
      "Iteration: 3254; Percent complete: 81.3%; Average loss: 2.8283\n",
      "Iteration: 3255; Percent complete: 81.4%; Average loss: 2.9087\n",
      "Iteration: 3256; Percent complete: 81.4%; Average loss: 2.8201\n",
      "Iteration: 3257; Percent complete: 81.4%; Average loss: 2.8443\n",
      "Iteration: 3258; Percent complete: 81.5%; Average loss: 2.8271\n",
      "Iteration: 3259; Percent complete: 81.5%; Average loss: 2.8334\n",
      "Iteration: 3260; Percent complete: 81.5%; Average loss: 2.8674\n",
      "Iteration: 3261; Percent complete: 81.5%; Average loss: 2.7372\n",
      "Iteration: 3262; Percent complete: 81.5%; Average loss: 2.9765\n",
      "Iteration: 3263; Percent complete: 81.6%; Average loss: 2.9380\n",
      "Iteration: 3264; Percent complete: 81.6%; Average loss: 2.5100\n",
      "Iteration: 3265; Percent complete: 81.6%; Average loss: 2.6849\n",
      "Iteration: 3266; Percent complete: 81.7%; Average loss: 2.6896\n",
      "Iteration: 3267; Percent complete: 81.7%; Average loss: 2.8358\n",
      "Iteration: 3268; Percent complete: 81.7%; Average loss: 2.6404\n",
      "Iteration: 3269; Percent complete: 81.7%; Average loss: 2.6790\n",
      "Iteration: 3270; Percent complete: 81.8%; Average loss: 2.8264\n",
      "Iteration: 3271; Percent complete: 81.8%; Average loss: 2.7410\n",
      "Iteration: 3272; Percent complete: 81.8%; Average loss: 2.5339\n",
      "Iteration: 3273; Percent complete: 81.8%; Average loss: 2.7553\n",
      "Iteration: 3274; Percent complete: 81.8%; Average loss: 3.1105\n",
      "Iteration: 3275; Percent complete: 81.9%; Average loss: 2.7710\n",
      "Iteration: 3276; Percent complete: 81.9%; Average loss: 2.7339\n",
      "Iteration: 3277; Percent complete: 81.9%; Average loss: 2.6729\n",
      "Iteration: 3278; Percent complete: 82.0%; Average loss: 2.6078\n",
      "Iteration: 3279; Percent complete: 82.0%; Average loss: 2.9693\n",
      "Iteration: 3280; Percent complete: 82.0%; Average loss: 3.0510\n",
      "Iteration: 3281; Percent complete: 82.0%; Average loss: 3.0771\n",
      "Iteration: 3282; Percent complete: 82.0%; Average loss: 2.5780\n",
      "Iteration: 3283; Percent complete: 82.1%; Average loss: 2.8725\n",
      "Iteration: 3284; Percent complete: 82.1%; Average loss: 2.6944\n",
      "Iteration: 3285; Percent complete: 82.1%; Average loss: 2.6317\n",
      "Iteration: 3286; Percent complete: 82.2%; Average loss: 2.7456\n",
      "Iteration: 3287; Percent complete: 82.2%; Average loss: 2.7917\n",
      "Iteration: 3288; Percent complete: 82.2%; Average loss: 2.6939\n",
      "Iteration: 3289; Percent complete: 82.2%; Average loss: 2.7856\n",
      "Iteration: 3290; Percent complete: 82.2%; Average loss: 2.9281\n",
      "Iteration: 3291; Percent complete: 82.3%; Average loss: 2.8005\n",
      "Iteration: 3292; Percent complete: 82.3%; Average loss: 2.7644\n",
      "Iteration: 3293; Percent complete: 82.3%; Average loss: 2.7684\n",
      "Iteration: 3294; Percent complete: 82.3%; Average loss: 2.8228\n",
      "Iteration: 3295; Percent complete: 82.4%; Average loss: 2.8956\n",
      "Iteration: 3296; Percent complete: 82.4%; Average loss: 2.7739\n",
      "Iteration: 3297; Percent complete: 82.4%; Average loss: 2.7526\n",
      "Iteration: 3298; Percent complete: 82.5%; Average loss: 2.6945\n",
      "Iteration: 3299; Percent complete: 82.5%; Average loss: 2.8824\n",
      "Iteration: 3300; Percent complete: 82.5%; Average loss: 2.8571\n",
      "Iteration: 3301; Percent complete: 82.5%; Average loss: 2.6536\n",
      "Iteration: 3302; Percent complete: 82.5%; Average loss: 2.9658\n",
      "Iteration: 3303; Percent complete: 82.6%; Average loss: 2.9487\n",
      "Iteration: 3304; Percent complete: 82.6%; Average loss: 2.9744\n",
      "Iteration: 3305; Percent complete: 82.6%; Average loss: 2.7595\n",
      "Iteration: 3306; Percent complete: 82.7%; Average loss: 2.8810\n",
      "Iteration: 3307; Percent complete: 82.7%; Average loss: 2.6865\n",
      "Iteration: 3308; Percent complete: 82.7%; Average loss: 2.7194\n",
      "Iteration: 3309; Percent complete: 82.7%; Average loss: 2.7930\n",
      "Iteration: 3310; Percent complete: 82.8%; Average loss: 2.7958\n",
      "Iteration: 3311; Percent complete: 82.8%; Average loss: 2.8537\n",
      "Iteration: 3312; Percent complete: 82.8%; Average loss: 2.7709\n",
      "Iteration: 3313; Percent complete: 82.8%; Average loss: 2.8710\n",
      "Iteration: 3314; Percent complete: 82.8%; Average loss: 2.5551\n",
      "Iteration: 3315; Percent complete: 82.9%; Average loss: 2.7790\n",
      "Iteration: 3316; Percent complete: 82.9%; Average loss: 2.6726\n",
      "Iteration: 3317; Percent complete: 82.9%; Average loss: 2.7081\n",
      "Iteration: 3318; Percent complete: 83.0%; Average loss: 2.9245\n",
      "Iteration: 3319; Percent complete: 83.0%; Average loss: 2.7310\n",
      "Iteration: 3320; Percent complete: 83.0%; Average loss: 2.6148\n",
      "Iteration: 3321; Percent complete: 83.0%; Average loss: 2.7530\n",
      "Iteration: 3322; Percent complete: 83.0%; Average loss: 2.9128\n",
      "Iteration: 3323; Percent complete: 83.1%; Average loss: 2.7109\n",
      "Iteration: 3324; Percent complete: 83.1%; Average loss: 2.9249\n",
      "Iteration: 3325; Percent complete: 83.1%; Average loss: 2.7082\n",
      "Iteration: 3326; Percent complete: 83.2%; Average loss: 2.8828\n",
      "Iteration: 3327; Percent complete: 83.2%; Average loss: 2.6030\n",
      "Iteration: 3328; Percent complete: 83.2%; Average loss: 2.6886\n",
      "Iteration: 3329; Percent complete: 83.2%; Average loss: 2.6496\n",
      "Iteration: 3330; Percent complete: 83.2%; Average loss: 2.7618\n",
      "Iteration: 3331; Percent complete: 83.3%; Average loss: 2.5974\n",
      "Iteration: 3332; Percent complete: 83.3%; Average loss: 2.6716\n",
      "Iteration: 3333; Percent complete: 83.3%; Average loss: 2.7390\n",
      "Iteration: 3334; Percent complete: 83.4%; Average loss: 2.9533\n",
      "Iteration: 3335; Percent complete: 83.4%; Average loss: 2.9526\n",
      "Iteration: 3336; Percent complete: 83.4%; Average loss: 2.9923\n",
      "Iteration: 3337; Percent complete: 83.4%; Average loss: 2.5338\n",
      "Iteration: 3338; Percent complete: 83.5%; Average loss: 2.8745\n",
      "Iteration: 3339; Percent complete: 83.5%; Average loss: 2.9527\n",
      "Iteration: 3340; Percent complete: 83.5%; Average loss: 2.5320\n",
      "Iteration: 3341; Percent complete: 83.5%; Average loss: 2.9352\n",
      "Iteration: 3342; Percent complete: 83.5%; Average loss: 2.9315\n",
      "Iteration: 3343; Percent complete: 83.6%; Average loss: 2.6279\n",
      "Iteration: 3344; Percent complete: 83.6%; Average loss: 2.7975\n",
      "Iteration: 3345; Percent complete: 83.6%; Average loss: 2.8075\n",
      "Iteration: 3346; Percent complete: 83.7%; Average loss: 2.8766\n",
      "Iteration: 3347; Percent complete: 83.7%; Average loss: 2.7700\n",
      "Iteration: 3348; Percent complete: 83.7%; Average loss: 2.6275\n",
      "Iteration: 3349; Percent complete: 83.7%; Average loss: 2.8007\n",
      "Iteration: 3350; Percent complete: 83.8%; Average loss: 2.7294\n",
      "Iteration: 3351; Percent complete: 83.8%; Average loss: 2.8822\n",
      "Iteration: 3352; Percent complete: 83.8%; Average loss: 2.6167\n",
      "Iteration: 3353; Percent complete: 83.8%; Average loss: 2.6327\n",
      "Iteration: 3354; Percent complete: 83.9%; Average loss: 2.8003\n",
      "Iteration: 3355; Percent complete: 83.9%; Average loss: 2.7561\n",
      "Iteration: 3356; Percent complete: 83.9%; Average loss: 2.7685\n",
      "Iteration: 3357; Percent complete: 83.9%; Average loss: 2.5949\n",
      "Iteration: 3358; Percent complete: 84.0%; Average loss: 2.7598\n",
      "Iteration: 3359; Percent complete: 84.0%; Average loss: 2.8619\n",
      "Iteration: 3360; Percent complete: 84.0%; Average loss: 2.6904\n",
      "Iteration: 3361; Percent complete: 84.0%; Average loss: 2.4538\n",
      "Iteration: 3362; Percent complete: 84.0%; Average loss: 2.9059\n",
      "Iteration: 3363; Percent complete: 84.1%; Average loss: 2.6084\n",
      "Iteration: 3364; Percent complete: 84.1%; Average loss: 2.8299\n",
      "Iteration: 3365; Percent complete: 84.1%; Average loss: 2.7287\n",
      "Iteration: 3366; Percent complete: 84.2%; Average loss: 2.9264\n",
      "Iteration: 3367; Percent complete: 84.2%; Average loss: 2.7792\n",
      "Iteration: 3368; Percent complete: 84.2%; Average loss: 2.9716\n",
      "Iteration: 3369; Percent complete: 84.2%; Average loss: 2.7664\n",
      "Iteration: 3370; Percent complete: 84.2%; Average loss: 2.6142\n",
      "Iteration: 3371; Percent complete: 84.3%; Average loss: 2.9256\n",
      "Iteration: 3372; Percent complete: 84.3%; Average loss: 2.7091\n",
      "Iteration: 3373; Percent complete: 84.3%; Average loss: 2.8418\n",
      "Iteration: 3374; Percent complete: 84.4%; Average loss: 2.5683\n",
      "Iteration: 3375; Percent complete: 84.4%; Average loss: 2.8068\n",
      "Iteration: 3376; Percent complete: 84.4%; Average loss: 2.4184\n",
      "Iteration: 3377; Percent complete: 84.4%; Average loss: 2.6956\n",
      "Iteration: 3378; Percent complete: 84.5%; Average loss: 2.7040\n",
      "Iteration: 3379; Percent complete: 84.5%; Average loss: 2.7223\n",
      "Iteration: 3380; Percent complete: 84.5%; Average loss: 2.8612\n",
      "Iteration: 3381; Percent complete: 84.5%; Average loss: 2.6737\n",
      "Iteration: 3382; Percent complete: 84.5%; Average loss: 2.9890\n",
      "Iteration: 3383; Percent complete: 84.6%; Average loss: 2.9207\n",
      "Iteration: 3384; Percent complete: 84.6%; Average loss: 2.9666\n",
      "Iteration: 3385; Percent complete: 84.6%; Average loss: 2.5636\n",
      "Iteration: 3386; Percent complete: 84.7%; Average loss: 2.8154\n",
      "Iteration: 3387; Percent complete: 84.7%; Average loss: 2.7641\n",
      "Iteration: 3388; Percent complete: 84.7%; Average loss: 2.7416\n",
      "Iteration: 3389; Percent complete: 84.7%; Average loss: 2.6718\n",
      "Iteration: 3390; Percent complete: 84.8%; Average loss: 2.9008\n",
      "Iteration: 3391; Percent complete: 84.8%; Average loss: 2.7515\n",
      "Iteration: 3392; Percent complete: 84.8%; Average loss: 2.6745\n",
      "Iteration: 3393; Percent complete: 84.8%; Average loss: 3.0190\n",
      "Iteration: 3394; Percent complete: 84.9%; Average loss: 2.7931\n",
      "Iteration: 3395; Percent complete: 84.9%; Average loss: 2.8146\n",
      "Iteration: 3396; Percent complete: 84.9%; Average loss: 2.6754\n",
      "Iteration: 3397; Percent complete: 84.9%; Average loss: 2.6769\n",
      "Iteration: 3398; Percent complete: 85.0%; Average loss: 2.6979\n",
      "Iteration: 3399; Percent complete: 85.0%; Average loss: 2.8452\n",
      "Iteration: 3400; Percent complete: 85.0%; Average loss: 2.7310\n",
      "Iteration: 3401; Percent complete: 85.0%; Average loss: 2.8965\n",
      "Iteration: 3402; Percent complete: 85.0%; Average loss: 3.0748\n",
      "Iteration: 3403; Percent complete: 85.1%; Average loss: 2.8856\n",
      "Iteration: 3404; Percent complete: 85.1%; Average loss: 2.5991\n",
      "Iteration: 3405; Percent complete: 85.1%; Average loss: 2.6787\n",
      "Iteration: 3406; Percent complete: 85.2%; Average loss: 2.6551\n",
      "Iteration: 3407; Percent complete: 85.2%; Average loss: 2.7821\n",
      "Iteration: 3408; Percent complete: 85.2%; Average loss: 2.8974\n",
      "Iteration: 3409; Percent complete: 85.2%; Average loss: 2.9564\n",
      "Iteration: 3410; Percent complete: 85.2%; Average loss: 2.6635\n",
      "Iteration: 3411; Percent complete: 85.3%; Average loss: 2.7594\n",
      "Iteration: 3412; Percent complete: 85.3%; Average loss: 2.6535\n",
      "Iteration: 3413; Percent complete: 85.3%; Average loss: 2.8085\n",
      "Iteration: 3414; Percent complete: 85.4%; Average loss: 2.9373\n",
      "Iteration: 3415; Percent complete: 85.4%; Average loss: 2.6269\n",
      "Iteration: 3416; Percent complete: 85.4%; Average loss: 2.8624\n",
      "Iteration: 3417; Percent complete: 85.4%; Average loss: 2.9595\n",
      "Iteration: 3418; Percent complete: 85.5%; Average loss: 2.5837\n",
      "Iteration: 3419; Percent complete: 85.5%; Average loss: 2.7707\n",
      "Iteration: 3420; Percent complete: 85.5%; Average loss: 2.8404\n",
      "Iteration: 3421; Percent complete: 85.5%; Average loss: 2.7980\n",
      "Iteration: 3422; Percent complete: 85.5%; Average loss: 3.0416\n",
      "Iteration: 3423; Percent complete: 85.6%; Average loss: 2.7625\n",
      "Iteration: 3424; Percent complete: 85.6%; Average loss: 2.8074\n",
      "Iteration: 3425; Percent complete: 85.6%; Average loss: 2.7947\n",
      "Iteration: 3426; Percent complete: 85.7%; Average loss: 2.7064\n",
      "Iteration: 3427; Percent complete: 85.7%; Average loss: 3.0650\n",
      "Iteration: 3428; Percent complete: 85.7%; Average loss: 2.8685\n",
      "Iteration: 3429; Percent complete: 85.7%; Average loss: 2.8462\n",
      "Iteration: 3430; Percent complete: 85.8%; Average loss: 2.7492\n",
      "Iteration: 3431; Percent complete: 85.8%; Average loss: 2.7039\n",
      "Iteration: 3432; Percent complete: 85.8%; Average loss: 2.8781\n",
      "Iteration: 3433; Percent complete: 85.8%; Average loss: 2.6406\n",
      "Iteration: 3434; Percent complete: 85.9%; Average loss: 2.8070\n",
      "Iteration: 3435; Percent complete: 85.9%; Average loss: 2.5837\n",
      "Iteration: 3436; Percent complete: 85.9%; Average loss: 2.9474\n",
      "Iteration: 3437; Percent complete: 85.9%; Average loss: 2.7634\n",
      "Iteration: 3438; Percent complete: 86.0%; Average loss: 2.8880\n",
      "Iteration: 3439; Percent complete: 86.0%; Average loss: 2.8609\n",
      "Iteration: 3440; Percent complete: 86.0%; Average loss: 2.7405\n",
      "Iteration: 3441; Percent complete: 86.0%; Average loss: 2.6488\n",
      "Iteration: 3442; Percent complete: 86.1%; Average loss: 2.8511\n",
      "Iteration: 3443; Percent complete: 86.1%; Average loss: 2.6294\n",
      "Iteration: 3444; Percent complete: 86.1%; Average loss: 2.6564\n",
      "Iteration: 3445; Percent complete: 86.1%; Average loss: 2.6365\n",
      "Iteration: 3446; Percent complete: 86.2%; Average loss: 2.5888\n",
      "Iteration: 3447; Percent complete: 86.2%; Average loss: 2.7230\n",
      "Iteration: 3448; Percent complete: 86.2%; Average loss: 2.4821\n",
      "Iteration: 3449; Percent complete: 86.2%; Average loss: 3.0519\n",
      "Iteration: 3450; Percent complete: 86.2%; Average loss: 2.8094\n",
      "Iteration: 3451; Percent complete: 86.3%; Average loss: 2.8395\n",
      "Iteration: 3452; Percent complete: 86.3%; Average loss: 2.8834\n",
      "Iteration: 3453; Percent complete: 86.3%; Average loss: 2.8109\n",
      "Iteration: 3454; Percent complete: 86.4%; Average loss: 2.8134\n",
      "Iteration: 3455; Percent complete: 86.4%; Average loss: 2.7765\n",
      "Iteration: 3456; Percent complete: 86.4%; Average loss: 2.5413\n",
      "Iteration: 3457; Percent complete: 86.4%; Average loss: 2.8004\n",
      "Iteration: 3458; Percent complete: 86.5%; Average loss: 2.6987\n",
      "Iteration: 3459; Percent complete: 86.5%; Average loss: 3.0946\n",
      "Iteration: 3460; Percent complete: 86.5%; Average loss: 2.8857\n",
      "Iteration: 3461; Percent complete: 86.5%; Average loss: 2.5598\n",
      "Iteration: 3462; Percent complete: 86.6%; Average loss: 2.8451\n",
      "Iteration: 3463; Percent complete: 86.6%; Average loss: 2.8108\n",
      "Iteration: 3464; Percent complete: 86.6%; Average loss: 2.6672\n",
      "Iteration: 3465; Percent complete: 86.6%; Average loss: 2.6177\n",
      "Iteration: 3466; Percent complete: 86.7%; Average loss: 2.6013\n",
      "Iteration: 3467; Percent complete: 86.7%; Average loss: 2.7564\n",
      "Iteration: 3468; Percent complete: 86.7%; Average loss: 2.6710\n",
      "Iteration: 3469; Percent complete: 86.7%; Average loss: 2.7328\n",
      "Iteration: 3470; Percent complete: 86.8%; Average loss: 2.7745\n",
      "Iteration: 3471; Percent complete: 86.8%; Average loss: 2.5268\n",
      "Iteration: 3472; Percent complete: 86.8%; Average loss: 2.6877\n",
      "Iteration: 3473; Percent complete: 86.8%; Average loss: 2.7586\n",
      "Iteration: 3474; Percent complete: 86.9%; Average loss: 2.9320\n",
      "Iteration: 3475; Percent complete: 86.9%; Average loss: 2.7742\n",
      "Iteration: 3476; Percent complete: 86.9%; Average loss: 2.7361\n",
      "Iteration: 3477; Percent complete: 86.9%; Average loss: 2.6517\n",
      "Iteration: 3478; Percent complete: 87.0%; Average loss: 2.6035\n",
      "Iteration: 3479; Percent complete: 87.0%; Average loss: 2.8535\n",
      "Iteration: 3480; Percent complete: 87.0%; Average loss: 2.7606\n",
      "Iteration: 3481; Percent complete: 87.0%; Average loss: 2.7198\n",
      "Iteration: 3482; Percent complete: 87.1%; Average loss: 2.6336\n",
      "Iteration: 3483; Percent complete: 87.1%; Average loss: 2.5265\n",
      "Iteration: 3484; Percent complete: 87.1%; Average loss: 2.8110\n",
      "Iteration: 3485; Percent complete: 87.1%; Average loss: 3.0392\n",
      "Iteration: 3486; Percent complete: 87.2%; Average loss: 2.7315\n",
      "Iteration: 3487; Percent complete: 87.2%; Average loss: 2.8930\n",
      "Iteration: 3488; Percent complete: 87.2%; Average loss: 2.7499\n",
      "Iteration: 3489; Percent complete: 87.2%; Average loss: 2.9192\n",
      "Iteration: 3490; Percent complete: 87.2%; Average loss: 2.4131\n",
      "Iteration: 3491; Percent complete: 87.3%; Average loss: 2.8195\n",
      "Iteration: 3492; Percent complete: 87.3%; Average loss: 2.6261\n",
      "Iteration: 3493; Percent complete: 87.3%; Average loss: 2.6877\n",
      "Iteration: 3494; Percent complete: 87.4%; Average loss: 2.9134\n",
      "Iteration: 3495; Percent complete: 87.4%; Average loss: 3.0331\n",
      "Iteration: 3496; Percent complete: 87.4%; Average loss: 2.8177\n",
      "Iteration: 3497; Percent complete: 87.4%; Average loss: 2.7524\n",
      "Iteration: 3498; Percent complete: 87.5%; Average loss: 2.8604\n",
      "Iteration: 3499; Percent complete: 87.5%; Average loss: 2.7868\n",
      "Iteration: 3500; Percent complete: 87.5%; Average loss: 2.8101\n",
      "Iteration: 3501; Percent complete: 87.5%; Average loss: 2.6919\n",
      "Iteration: 3502; Percent complete: 87.5%; Average loss: 2.6421\n",
      "Iteration: 3503; Percent complete: 87.6%; Average loss: 2.7526\n",
      "Iteration: 3504; Percent complete: 87.6%; Average loss: 2.8567\n",
      "Iteration: 3505; Percent complete: 87.6%; Average loss: 2.8137\n",
      "Iteration: 3506; Percent complete: 87.6%; Average loss: 2.7189\n",
      "Iteration: 3507; Percent complete: 87.7%; Average loss: 2.8170\n",
      "Iteration: 3508; Percent complete: 87.7%; Average loss: 2.6677\n",
      "Iteration: 3509; Percent complete: 87.7%; Average loss: 2.7455\n",
      "Iteration: 3510; Percent complete: 87.8%; Average loss: 2.6448\n",
      "Iteration: 3511; Percent complete: 87.8%; Average loss: 2.7990\n",
      "Iteration: 3512; Percent complete: 87.8%; Average loss: 2.7411\n",
      "Iteration: 3513; Percent complete: 87.8%; Average loss: 2.8946\n",
      "Iteration: 3514; Percent complete: 87.8%; Average loss: 2.5619\n",
      "Iteration: 3515; Percent complete: 87.9%; Average loss: 2.7954\n",
      "Iteration: 3516; Percent complete: 87.9%; Average loss: 2.7614\n",
      "Iteration: 3517; Percent complete: 87.9%; Average loss: 2.8210\n",
      "Iteration: 3518; Percent complete: 87.9%; Average loss: 2.5165\n",
      "Iteration: 3519; Percent complete: 88.0%; Average loss: 2.9331\n",
      "Iteration: 3520; Percent complete: 88.0%; Average loss: 2.8895\n",
      "Iteration: 3521; Percent complete: 88.0%; Average loss: 2.6333\n",
      "Iteration: 3522; Percent complete: 88.0%; Average loss: 2.7865\n",
      "Iteration: 3523; Percent complete: 88.1%; Average loss: 2.8571\n",
      "Iteration: 3524; Percent complete: 88.1%; Average loss: 2.7569\n",
      "Iteration: 3525; Percent complete: 88.1%; Average loss: 2.7661\n",
      "Iteration: 3526; Percent complete: 88.1%; Average loss: 2.8462\n",
      "Iteration: 3527; Percent complete: 88.2%; Average loss: 2.9266\n",
      "Iteration: 3528; Percent complete: 88.2%; Average loss: 2.5955\n",
      "Iteration: 3529; Percent complete: 88.2%; Average loss: 2.7975\n",
      "Iteration: 3530; Percent complete: 88.2%; Average loss: 2.8836\n",
      "Iteration: 3531; Percent complete: 88.3%; Average loss: 2.7054\n",
      "Iteration: 3532; Percent complete: 88.3%; Average loss: 2.7210\n",
      "Iteration: 3533; Percent complete: 88.3%; Average loss: 2.6846\n",
      "Iteration: 3534; Percent complete: 88.3%; Average loss: 2.6646\n",
      "Iteration: 3535; Percent complete: 88.4%; Average loss: 2.8414\n",
      "Iteration: 3536; Percent complete: 88.4%; Average loss: 2.6424\n",
      "Iteration: 3537; Percent complete: 88.4%; Average loss: 2.8802\n",
      "Iteration: 3538; Percent complete: 88.4%; Average loss: 2.6915\n",
      "Iteration: 3539; Percent complete: 88.5%; Average loss: 2.8430\n",
      "Iteration: 3540; Percent complete: 88.5%; Average loss: 2.9332\n",
      "Iteration: 3541; Percent complete: 88.5%; Average loss: 2.8082\n",
      "Iteration: 3542; Percent complete: 88.5%; Average loss: 2.7314\n",
      "Iteration: 3543; Percent complete: 88.6%; Average loss: 2.5753\n",
      "Iteration: 3544; Percent complete: 88.6%; Average loss: 2.9192\n",
      "Iteration: 3545; Percent complete: 88.6%; Average loss: 2.6688\n",
      "Iteration: 3546; Percent complete: 88.6%; Average loss: 2.6843\n",
      "Iteration: 3547; Percent complete: 88.7%; Average loss: 2.8122\n",
      "Iteration: 3548; Percent complete: 88.7%; Average loss: 2.6978\n",
      "Iteration: 3549; Percent complete: 88.7%; Average loss: 2.7366\n",
      "Iteration: 3550; Percent complete: 88.8%; Average loss: 2.8988\n",
      "Iteration: 3551; Percent complete: 88.8%; Average loss: 2.6629\n",
      "Iteration: 3552; Percent complete: 88.8%; Average loss: 2.8440\n",
      "Iteration: 3553; Percent complete: 88.8%; Average loss: 2.7957\n",
      "Iteration: 3554; Percent complete: 88.8%; Average loss: 3.0217\n",
      "Iteration: 3555; Percent complete: 88.9%; Average loss: 2.7490\n",
      "Iteration: 3556; Percent complete: 88.9%; Average loss: 2.8884\n",
      "Iteration: 3557; Percent complete: 88.9%; Average loss: 2.9393\n",
      "Iteration: 3558; Percent complete: 88.9%; Average loss: 2.8683\n",
      "Iteration: 3559; Percent complete: 89.0%; Average loss: 2.9548\n",
      "Iteration: 3560; Percent complete: 89.0%; Average loss: 2.6712\n",
      "Iteration: 3561; Percent complete: 89.0%; Average loss: 2.6861\n",
      "Iteration: 3562; Percent complete: 89.0%; Average loss: 2.4478\n",
      "Iteration: 3563; Percent complete: 89.1%; Average loss: 2.7216\n",
      "Iteration: 3564; Percent complete: 89.1%; Average loss: 2.7814\n",
      "Iteration: 3565; Percent complete: 89.1%; Average loss: 2.8691\n",
      "Iteration: 3566; Percent complete: 89.1%; Average loss: 2.7201\n",
      "Iteration: 3567; Percent complete: 89.2%; Average loss: 2.8213\n",
      "Iteration: 3568; Percent complete: 89.2%; Average loss: 2.8969\n",
      "Iteration: 3569; Percent complete: 89.2%; Average loss: 2.7880\n",
      "Iteration: 3570; Percent complete: 89.2%; Average loss: 2.8587\n",
      "Iteration: 3571; Percent complete: 89.3%; Average loss: 2.7468\n",
      "Iteration: 3572; Percent complete: 89.3%; Average loss: 2.7664\n",
      "Iteration: 3573; Percent complete: 89.3%; Average loss: 2.6145\n",
      "Iteration: 3574; Percent complete: 89.3%; Average loss: 2.7998\n",
      "Iteration: 3575; Percent complete: 89.4%; Average loss: 2.9450\n",
      "Iteration: 3576; Percent complete: 89.4%; Average loss: 2.7980\n",
      "Iteration: 3577; Percent complete: 89.4%; Average loss: 2.8749\n",
      "Iteration: 3578; Percent complete: 89.5%; Average loss: 2.6039\n",
      "Iteration: 3579; Percent complete: 89.5%; Average loss: 2.7327\n",
      "Iteration: 3580; Percent complete: 89.5%; Average loss: 2.7637\n",
      "Iteration: 3581; Percent complete: 89.5%; Average loss: 2.5677\n",
      "Iteration: 3582; Percent complete: 89.5%; Average loss: 2.6359\n",
      "Iteration: 3583; Percent complete: 89.6%; Average loss: 2.8550\n",
      "Iteration: 3584; Percent complete: 89.6%; Average loss: 2.7408\n",
      "Iteration: 3585; Percent complete: 89.6%; Average loss: 2.6209\n",
      "Iteration: 3586; Percent complete: 89.6%; Average loss: 2.7148\n",
      "Iteration: 3587; Percent complete: 89.7%; Average loss: 2.8705\n",
      "Iteration: 3588; Percent complete: 89.7%; Average loss: 2.9079\n",
      "Iteration: 3589; Percent complete: 89.7%; Average loss: 2.8261\n",
      "Iteration: 3590; Percent complete: 89.8%; Average loss: 2.7317\n",
      "Iteration: 3591; Percent complete: 89.8%; Average loss: 2.5852\n",
      "Iteration: 3592; Percent complete: 89.8%; Average loss: 2.5261\n",
      "Iteration: 3593; Percent complete: 89.8%; Average loss: 2.8429\n",
      "Iteration: 3594; Percent complete: 89.8%; Average loss: 2.8071\n",
      "Iteration: 3595; Percent complete: 89.9%; Average loss: 2.5704\n",
      "Iteration: 3596; Percent complete: 89.9%; Average loss: 2.6715\n",
      "Iteration: 3597; Percent complete: 89.9%; Average loss: 2.7706\n",
      "Iteration: 3598; Percent complete: 90.0%; Average loss: 2.7544\n",
      "Iteration: 3599; Percent complete: 90.0%; Average loss: 2.6661\n",
      "Iteration: 3600; Percent complete: 90.0%; Average loss: 2.7660\n",
      "Iteration: 3601; Percent complete: 90.0%; Average loss: 2.6500\n",
      "Iteration: 3602; Percent complete: 90.0%; Average loss: 2.6437\n",
      "Iteration: 3603; Percent complete: 90.1%; Average loss: 2.6360\n",
      "Iteration: 3604; Percent complete: 90.1%; Average loss: 2.7389\n",
      "Iteration: 3605; Percent complete: 90.1%; Average loss: 2.8445\n",
      "Iteration: 3606; Percent complete: 90.1%; Average loss: 2.6361\n",
      "Iteration: 3607; Percent complete: 90.2%; Average loss: 2.7655\n",
      "Iteration: 3608; Percent complete: 90.2%; Average loss: 2.5592\n",
      "Iteration: 3609; Percent complete: 90.2%; Average loss: 2.7872\n",
      "Iteration: 3610; Percent complete: 90.2%; Average loss: 2.5624\n",
      "Iteration: 3611; Percent complete: 90.3%; Average loss: 2.7962\n",
      "Iteration: 3612; Percent complete: 90.3%; Average loss: 2.7204\n",
      "Iteration: 3613; Percent complete: 90.3%; Average loss: 2.7911\n",
      "Iteration: 3614; Percent complete: 90.3%; Average loss: 2.6070\n",
      "Iteration: 3615; Percent complete: 90.4%; Average loss: 2.7184\n",
      "Iteration: 3616; Percent complete: 90.4%; Average loss: 2.7040\n",
      "Iteration: 3617; Percent complete: 90.4%; Average loss: 2.6034\n",
      "Iteration: 3618; Percent complete: 90.5%; Average loss: 2.5909\n",
      "Iteration: 3619; Percent complete: 90.5%; Average loss: 2.7891\n",
      "Iteration: 3620; Percent complete: 90.5%; Average loss: 2.7941\n",
      "Iteration: 3621; Percent complete: 90.5%; Average loss: 2.7387\n",
      "Iteration: 3622; Percent complete: 90.5%; Average loss: 2.8106\n",
      "Iteration: 3623; Percent complete: 90.6%; Average loss: 2.8161\n",
      "Iteration: 3624; Percent complete: 90.6%; Average loss: 2.6772\n",
      "Iteration: 3625; Percent complete: 90.6%; Average loss: 2.8693\n",
      "Iteration: 3626; Percent complete: 90.6%; Average loss: 2.6609\n",
      "Iteration: 3627; Percent complete: 90.7%; Average loss: 2.2583\n",
      "Iteration: 3628; Percent complete: 90.7%; Average loss: 2.5550\n",
      "Iteration: 3629; Percent complete: 90.7%; Average loss: 2.6270\n",
      "Iteration: 3630; Percent complete: 90.8%; Average loss: 2.6131\n",
      "Iteration: 3631; Percent complete: 90.8%; Average loss: 2.7411\n",
      "Iteration: 3632; Percent complete: 90.8%; Average loss: 2.8756\n",
      "Iteration: 3633; Percent complete: 90.8%; Average loss: 2.7440\n",
      "Iteration: 3634; Percent complete: 90.8%; Average loss: 2.6204\n",
      "Iteration: 3635; Percent complete: 90.9%; Average loss: 2.7481\n",
      "Iteration: 3636; Percent complete: 90.9%; Average loss: 2.4324\n",
      "Iteration: 3637; Percent complete: 90.9%; Average loss: 2.6290\n",
      "Iteration: 3638; Percent complete: 91.0%; Average loss: 2.5657\n",
      "Iteration: 3639; Percent complete: 91.0%; Average loss: 2.7277\n",
      "Iteration: 3640; Percent complete: 91.0%; Average loss: 2.8937\n",
      "Iteration: 3641; Percent complete: 91.0%; Average loss: 2.3627\n",
      "Iteration: 3642; Percent complete: 91.0%; Average loss: 2.7155\n",
      "Iteration: 3643; Percent complete: 91.1%; Average loss: 2.7697\n",
      "Iteration: 3644; Percent complete: 91.1%; Average loss: 2.8136\n",
      "Iteration: 3645; Percent complete: 91.1%; Average loss: 2.8715\n",
      "Iteration: 3646; Percent complete: 91.1%; Average loss: 2.6719\n",
      "Iteration: 3647; Percent complete: 91.2%; Average loss: 2.6676\n",
      "Iteration: 3648; Percent complete: 91.2%; Average loss: 2.5993\n",
      "Iteration: 3649; Percent complete: 91.2%; Average loss: 2.7738\n",
      "Iteration: 3650; Percent complete: 91.2%; Average loss: 2.8756\n",
      "Iteration: 3651; Percent complete: 91.3%; Average loss: 2.8535\n",
      "Iteration: 3652; Percent complete: 91.3%; Average loss: 2.7332\n",
      "Iteration: 3653; Percent complete: 91.3%; Average loss: 2.9763\n",
      "Iteration: 3654; Percent complete: 91.3%; Average loss: 2.6252\n",
      "Iteration: 3655; Percent complete: 91.4%; Average loss: 2.6605\n",
      "Iteration: 3656; Percent complete: 91.4%; Average loss: 2.6673\n",
      "Iteration: 3657; Percent complete: 91.4%; Average loss: 2.7444\n",
      "Iteration: 3658; Percent complete: 91.5%; Average loss: 2.5654\n",
      "Iteration: 3659; Percent complete: 91.5%; Average loss: 2.3670\n",
      "Iteration: 3660; Percent complete: 91.5%; Average loss: 2.9667\n",
      "Iteration: 3661; Percent complete: 91.5%; Average loss: 2.7091\n",
      "Iteration: 3662; Percent complete: 91.5%; Average loss: 2.6378\n",
      "Iteration: 3663; Percent complete: 91.6%; Average loss: 2.5715\n",
      "Iteration: 3664; Percent complete: 91.6%; Average loss: 2.4035\n",
      "Iteration: 3665; Percent complete: 91.6%; Average loss: 2.6691\n",
      "Iteration: 3666; Percent complete: 91.6%; Average loss: 2.8368\n",
      "Iteration: 3667; Percent complete: 91.7%; Average loss: 2.5952\n",
      "Iteration: 3668; Percent complete: 91.7%; Average loss: 3.0498\n",
      "Iteration: 3669; Percent complete: 91.7%; Average loss: 2.6671\n",
      "Iteration: 3670; Percent complete: 91.8%; Average loss: 2.7720\n",
      "Iteration: 3671; Percent complete: 91.8%; Average loss: 2.7269\n",
      "Iteration: 3672; Percent complete: 91.8%; Average loss: 2.8617\n",
      "Iteration: 3673; Percent complete: 91.8%; Average loss: 2.6387\n",
      "Iteration: 3674; Percent complete: 91.8%; Average loss: 2.7025\n",
      "Iteration: 3675; Percent complete: 91.9%; Average loss: 2.7508\n",
      "Iteration: 3676; Percent complete: 91.9%; Average loss: 2.7247\n",
      "Iteration: 3677; Percent complete: 91.9%; Average loss: 3.0049\n",
      "Iteration: 3678; Percent complete: 92.0%; Average loss: 2.6115\n",
      "Iteration: 3679; Percent complete: 92.0%; Average loss: 2.7385\n",
      "Iteration: 3680; Percent complete: 92.0%; Average loss: 2.5090\n",
      "Iteration: 3681; Percent complete: 92.0%; Average loss: 2.7184\n",
      "Iteration: 3682; Percent complete: 92.0%; Average loss: 2.5811\n",
      "Iteration: 3683; Percent complete: 92.1%; Average loss: 2.5861\n",
      "Iteration: 3684; Percent complete: 92.1%; Average loss: 2.6464\n",
      "Iteration: 3685; Percent complete: 92.1%; Average loss: 2.4681\n",
      "Iteration: 3686; Percent complete: 92.2%; Average loss: 2.7413\n",
      "Iteration: 3687; Percent complete: 92.2%; Average loss: 2.6202\n",
      "Iteration: 3688; Percent complete: 92.2%; Average loss: 2.6965\n",
      "Iteration: 3689; Percent complete: 92.2%; Average loss: 2.5116\n",
      "Iteration: 3690; Percent complete: 92.2%; Average loss: 2.7124\n",
      "Iteration: 3691; Percent complete: 92.3%; Average loss: 2.8565\n",
      "Iteration: 3692; Percent complete: 92.3%; Average loss: 2.8379\n",
      "Iteration: 3693; Percent complete: 92.3%; Average loss: 2.7236\n",
      "Iteration: 3694; Percent complete: 92.3%; Average loss: 2.9059\n",
      "Iteration: 3695; Percent complete: 92.4%; Average loss: 2.6912\n",
      "Iteration: 3696; Percent complete: 92.4%; Average loss: 2.7722\n",
      "Iteration: 3697; Percent complete: 92.4%; Average loss: 2.7468\n",
      "Iteration: 3698; Percent complete: 92.5%; Average loss: 2.7573\n",
      "Iteration: 3699; Percent complete: 92.5%; Average loss: 2.5251\n",
      "Iteration: 3700; Percent complete: 92.5%; Average loss: 2.5587\n",
      "Iteration: 3701; Percent complete: 92.5%; Average loss: 2.8658\n",
      "Iteration: 3702; Percent complete: 92.5%; Average loss: 2.7020\n",
      "Iteration: 3703; Percent complete: 92.6%; Average loss: 2.6218\n",
      "Iteration: 3704; Percent complete: 92.6%; Average loss: 2.7208\n",
      "Iteration: 3705; Percent complete: 92.6%; Average loss: 2.5934\n",
      "Iteration: 3706; Percent complete: 92.7%; Average loss: 2.8950\n",
      "Iteration: 3707; Percent complete: 92.7%; Average loss: 2.4966\n",
      "Iteration: 3708; Percent complete: 92.7%; Average loss: 2.5085\n",
      "Iteration: 3709; Percent complete: 92.7%; Average loss: 2.7147\n",
      "Iteration: 3710; Percent complete: 92.8%; Average loss: 2.5579\n",
      "Iteration: 3711; Percent complete: 92.8%; Average loss: 2.8422\n",
      "Iteration: 3712; Percent complete: 92.8%; Average loss: 2.6113\n",
      "Iteration: 3713; Percent complete: 92.8%; Average loss: 2.6717\n",
      "Iteration: 3714; Percent complete: 92.8%; Average loss: 2.5341\n",
      "Iteration: 3715; Percent complete: 92.9%; Average loss: 2.6218\n",
      "Iteration: 3716; Percent complete: 92.9%; Average loss: 2.6519\n",
      "Iteration: 3717; Percent complete: 92.9%; Average loss: 2.4849\n",
      "Iteration: 3718; Percent complete: 93.0%; Average loss: 2.6524\n",
      "Iteration: 3719; Percent complete: 93.0%; Average loss: 2.4739\n",
      "Iteration: 3720; Percent complete: 93.0%; Average loss: 2.7633\n",
      "Iteration: 3721; Percent complete: 93.0%; Average loss: 2.4064\n",
      "Iteration: 3722; Percent complete: 93.0%; Average loss: 2.7249\n",
      "Iteration: 3723; Percent complete: 93.1%; Average loss: 2.5313\n",
      "Iteration: 3724; Percent complete: 93.1%; Average loss: 2.6195\n",
      "Iteration: 3725; Percent complete: 93.1%; Average loss: 2.7112\n",
      "Iteration: 3726; Percent complete: 93.2%; Average loss: 2.9204\n",
      "Iteration: 3727; Percent complete: 93.2%; Average loss: 2.6928\n",
      "Iteration: 3728; Percent complete: 93.2%; Average loss: 2.6325\n",
      "Iteration: 3729; Percent complete: 93.2%; Average loss: 2.6230\n",
      "Iteration: 3730; Percent complete: 93.2%; Average loss: 2.7028\n",
      "Iteration: 3731; Percent complete: 93.3%; Average loss: 2.7023\n",
      "Iteration: 3732; Percent complete: 93.3%; Average loss: 2.7067\n",
      "Iteration: 3733; Percent complete: 93.3%; Average loss: 2.7280\n",
      "Iteration: 3734; Percent complete: 93.3%; Average loss: 2.6250\n",
      "Iteration: 3735; Percent complete: 93.4%; Average loss: 2.3916\n",
      "Iteration: 3736; Percent complete: 93.4%; Average loss: 2.4029\n",
      "Iteration: 3737; Percent complete: 93.4%; Average loss: 2.4762\n",
      "Iteration: 3738; Percent complete: 93.5%; Average loss: 2.6466\n",
      "Iteration: 3739; Percent complete: 93.5%; Average loss: 2.6428\n",
      "Iteration: 3740; Percent complete: 93.5%; Average loss: 2.6117\n",
      "Iteration: 3741; Percent complete: 93.5%; Average loss: 2.5662\n",
      "Iteration: 3742; Percent complete: 93.5%; Average loss: 2.6060\n",
      "Iteration: 3743; Percent complete: 93.6%; Average loss: 2.6598\n",
      "Iteration: 3744; Percent complete: 93.6%; Average loss: 2.6716\n",
      "Iteration: 3745; Percent complete: 93.6%; Average loss: 2.6250\n",
      "Iteration: 3746; Percent complete: 93.7%; Average loss: 2.5523\n",
      "Iteration: 3747; Percent complete: 93.7%; Average loss: 2.6362\n",
      "Iteration: 3748; Percent complete: 93.7%; Average loss: 2.7859\n",
      "Iteration: 3749; Percent complete: 93.7%; Average loss: 2.7047\n",
      "Iteration: 3750; Percent complete: 93.8%; Average loss: 2.6173\n",
      "Iteration: 3751; Percent complete: 93.8%; Average loss: 2.5027\n",
      "Iteration: 3752; Percent complete: 93.8%; Average loss: 2.6918\n",
      "Iteration: 3753; Percent complete: 93.8%; Average loss: 3.0341\n",
      "Iteration: 3754; Percent complete: 93.8%; Average loss: 2.6777\n",
      "Iteration: 3755; Percent complete: 93.9%; Average loss: 2.5369\n",
      "Iteration: 3756; Percent complete: 93.9%; Average loss: 2.6036\n",
      "Iteration: 3757; Percent complete: 93.9%; Average loss: 2.8520\n",
      "Iteration: 3758; Percent complete: 94.0%; Average loss: 2.6455\n",
      "Iteration: 3759; Percent complete: 94.0%; Average loss: 2.7668\n",
      "Iteration: 3760; Percent complete: 94.0%; Average loss: 2.4912\n",
      "Iteration: 3761; Percent complete: 94.0%; Average loss: 2.7218\n",
      "Iteration: 3762; Percent complete: 94.0%; Average loss: 2.9150\n",
      "Iteration: 3763; Percent complete: 94.1%; Average loss: 2.8503\n",
      "Iteration: 3764; Percent complete: 94.1%; Average loss: 2.8348\n",
      "Iteration: 3765; Percent complete: 94.1%; Average loss: 2.6052\n",
      "Iteration: 3766; Percent complete: 94.2%; Average loss: 2.5784\n",
      "Iteration: 3767; Percent complete: 94.2%; Average loss: 2.6383\n",
      "Iteration: 3768; Percent complete: 94.2%; Average loss: 2.5500\n",
      "Iteration: 3769; Percent complete: 94.2%; Average loss: 2.4657\n",
      "Iteration: 3770; Percent complete: 94.2%; Average loss: 2.6778\n",
      "Iteration: 3771; Percent complete: 94.3%; Average loss: 2.5614\n",
      "Iteration: 3772; Percent complete: 94.3%; Average loss: 2.7583\n",
      "Iteration: 3773; Percent complete: 94.3%; Average loss: 2.5660\n",
      "Iteration: 3774; Percent complete: 94.3%; Average loss: 2.6402\n",
      "Iteration: 3775; Percent complete: 94.4%; Average loss: 2.6572\n",
      "Iteration: 3776; Percent complete: 94.4%; Average loss: 2.7160\n",
      "Iteration: 3777; Percent complete: 94.4%; Average loss: 2.7647\n",
      "Iteration: 3778; Percent complete: 94.5%; Average loss: 2.7438\n",
      "Iteration: 3779; Percent complete: 94.5%; Average loss: 2.6466\n",
      "Iteration: 3780; Percent complete: 94.5%; Average loss: 2.5878\n",
      "Iteration: 3781; Percent complete: 94.5%; Average loss: 2.4100\n",
      "Iteration: 3782; Percent complete: 94.5%; Average loss: 2.6912\n",
      "Iteration: 3783; Percent complete: 94.6%; Average loss: 2.6480\n",
      "Iteration: 3784; Percent complete: 94.6%; Average loss: 2.7136\n",
      "Iteration: 3785; Percent complete: 94.6%; Average loss: 2.5206\n",
      "Iteration: 3786; Percent complete: 94.7%; Average loss: 2.6126\n",
      "Iteration: 3787; Percent complete: 94.7%; Average loss: 2.7213\n",
      "Iteration: 3788; Percent complete: 94.7%; Average loss: 2.4696\n",
      "Iteration: 3789; Percent complete: 94.7%; Average loss: 2.7261\n",
      "Iteration: 3790; Percent complete: 94.8%; Average loss: 2.6836\n",
      "Iteration: 3791; Percent complete: 94.8%; Average loss: 2.7555\n",
      "Iteration: 3792; Percent complete: 94.8%; Average loss: 2.8439\n",
      "Iteration: 3793; Percent complete: 94.8%; Average loss: 2.4288\n",
      "Iteration: 3794; Percent complete: 94.8%; Average loss: 2.8137\n",
      "Iteration: 3795; Percent complete: 94.9%; Average loss: 2.8264\n",
      "Iteration: 3796; Percent complete: 94.9%; Average loss: 2.4946\n",
      "Iteration: 3797; Percent complete: 94.9%; Average loss: 2.8219\n",
      "Iteration: 3798; Percent complete: 95.0%; Average loss: 2.5639\n",
      "Iteration: 3799; Percent complete: 95.0%; Average loss: 2.8002\n",
      "Iteration: 3800; Percent complete: 95.0%; Average loss: 2.6819\n",
      "Iteration: 3801; Percent complete: 95.0%; Average loss: 2.7871\n",
      "Iteration: 3802; Percent complete: 95.0%; Average loss: 2.5175\n",
      "Iteration: 3803; Percent complete: 95.1%; Average loss: 2.5202\n",
      "Iteration: 3804; Percent complete: 95.1%; Average loss: 2.6545\n",
      "Iteration: 3805; Percent complete: 95.1%; Average loss: 2.6961\n",
      "Iteration: 3806; Percent complete: 95.2%; Average loss: 2.5205\n",
      "Iteration: 3807; Percent complete: 95.2%; Average loss: 2.6703\n",
      "Iteration: 3808; Percent complete: 95.2%; Average loss: 2.6644\n",
      "Iteration: 3809; Percent complete: 95.2%; Average loss: 2.5069\n",
      "Iteration: 3810; Percent complete: 95.2%; Average loss: 2.6489\n",
      "Iteration: 3811; Percent complete: 95.3%; Average loss: 2.9117\n",
      "Iteration: 3812; Percent complete: 95.3%; Average loss: 2.7419\n",
      "Iteration: 3813; Percent complete: 95.3%; Average loss: 2.6565\n",
      "Iteration: 3814; Percent complete: 95.3%; Average loss: 2.6431\n",
      "Iteration: 3815; Percent complete: 95.4%; Average loss: 2.4354\n",
      "Iteration: 3816; Percent complete: 95.4%; Average loss: 2.3492\n",
      "Iteration: 3817; Percent complete: 95.4%; Average loss: 2.5975\n",
      "Iteration: 3818; Percent complete: 95.5%; Average loss: 2.8249\n",
      "Iteration: 3819; Percent complete: 95.5%; Average loss: 2.8128\n",
      "Iteration: 3820; Percent complete: 95.5%; Average loss: 2.6498\n",
      "Iteration: 3821; Percent complete: 95.5%; Average loss: 2.7396\n",
      "Iteration: 3822; Percent complete: 95.5%; Average loss: 2.6298\n",
      "Iteration: 3823; Percent complete: 95.6%; Average loss: 2.7593\n",
      "Iteration: 3824; Percent complete: 95.6%; Average loss: 2.4111\n",
      "Iteration: 3825; Percent complete: 95.6%; Average loss: 2.5952\n",
      "Iteration: 3826; Percent complete: 95.7%; Average loss: 2.5228\n",
      "Iteration: 3827; Percent complete: 95.7%; Average loss: 2.5803\n",
      "Iteration: 3828; Percent complete: 95.7%; Average loss: 2.5323\n",
      "Iteration: 3829; Percent complete: 95.7%; Average loss: 2.5916\n",
      "Iteration: 3830; Percent complete: 95.8%; Average loss: 2.5924\n",
      "Iteration: 3831; Percent complete: 95.8%; Average loss: 2.4993\n",
      "Iteration: 3832; Percent complete: 95.8%; Average loss: 2.8020\n",
      "Iteration: 3833; Percent complete: 95.8%; Average loss: 2.9128\n",
      "Iteration: 3834; Percent complete: 95.9%; Average loss: 2.6753\n",
      "Iteration: 3835; Percent complete: 95.9%; Average loss: 2.5177\n",
      "Iteration: 3836; Percent complete: 95.9%; Average loss: 2.6892\n",
      "Iteration: 3837; Percent complete: 95.9%; Average loss: 2.5647\n",
      "Iteration: 3838; Percent complete: 96.0%; Average loss: 2.7260\n",
      "Iteration: 3839; Percent complete: 96.0%; Average loss: 2.7435\n",
      "Iteration: 3840; Percent complete: 96.0%; Average loss: 2.6940\n",
      "Iteration: 3841; Percent complete: 96.0%; Average loss: 2.7308\n",
      "Iteration: 3842; Percent complete: 96.0%; Average loss: 2.4757\n",
      "Iteration: 3843; Percent complete: 96.1%; Average loss: 2.9029\n",
      "Iteration: 3844; Percent complete: 96.1%; Average loss: 2.4683\n",
      "Iteration: 3845; Percent complete: 96.1%; Average loss: 2.4489\n",
      "Iteration: 3846; Percent complete: 96.2%; Average loss: 2.6549\n",
      "Iteration: 3847; Percent complete: 96.2%; Average loss: 2.6728\n",
      "Iteration: 3848; Percent complete: 96.2%; Average loss: 2.6637\n",
      "Iteration: 3849; Percent complete: 96.2%; Average loss: 2.5499\n",
      "Iteration: 3850; Percent complete: 96.2%; Average loss: 2.4308\n",
      "Iteration: 3851; Percent complete: 96.3%; Average loss: 2.6762\n",
      "Iteration: 3852; Percent complete: 96.3%; Average loss: 2.5643\n",
      "Iteration: 3853; Percent complete: 96.3%; Average loss: 2.7090\n",
      "Iteration: 3854; Percent complete: 96.4%; Average loss: 2.5415\n",
      "Iteration: 3855; Percent complete: 96.4%; Average loss: 2.7316\n",
      "Iteration: 3856; Percent complete: 96.4%; Average loss: 2.8635\n",
      "Iteration: 3857; Percent complete: 96.4%; Average loss: 2.5885\n",
      "Iteration: 3858; Percent complete: 96.5%; Average loss: 2.5194\n",
      "Iteration: 3859; Percent complete: 96.5%; Average loss: 2.5740\n",
      "Iteration: 3860; Percent complete: 96.5%; Average loss: 2.4419\n",
      "Iteration: 3861; Percent complete: 96.5%; Average loss: 2.7156\n",
      "Iteration: 3862; Percent complete: 96.5%; Average loss: 2.7024\n",
      "Iteration: 3863; Percent complete: 96.6%; Average loss: 2.5988\n",
      "Iteration: 3864; Percent complete: 96.6%; Average loss: 2.5606\n",
      "Iteration: 3865; Percent complete: 96.6%; Average loss: 2.6909\n",
      "Iteration: 3866; Percent complete: 96.7%; Average loss: 2.7817\n",
      "Iteration: 3867; Percent complete: 96.7%; Average loss: 2.4599\n",
      "Iteration: 3868; Percent complete: 96.7%; Average loss: 2.5629\n",
      "Iteration: 3869; Percent complete: 96.7%; Average loss: 2.6829\n",
      "Iteration: 3870; Percent complete: 96.8%; Average loss: 2.5845\n",
      "Iteration: 3871; Percent complete: 96.8%; Average loss: 2.7375\n",
      "Iteration: 3872; Percent complete: 96.8%; Average loss: 2.6716\n",
      "Iteration: 3873; Percent complete: 96.8%; Average loss: 2.6114\n",
      "Iteration: 3874; Percent complete: 96.9%; Average loss: 2.6976\n",
      "Iteration: 3875; Percent complete: 96.9%; Average loss: 2.5456\n",
      "Iteration: 3876; Percent complete: 96.9%; Average loss: 2.7874\n",
      "Iteration: 3877; Percent complete: 96.9%; Average loss: 2.8360\n",
      "Iteration: 3878; Percent complete: 97.0%; Average loss: 2.7745\n",
      "Iteration: 3879; Percent complete: 97.0%; Average loss: 2.9649\n",
      "Iteration: 3880; Percent complete: 97.0%; Average loss: 2.6135\n",
      "Iteration: 3881; Percent complete: 97.0%; Average loss: 2.5413\n",
      "Iteration: 3882; Percent complete: 97.0%; Average loss: 2.9062\n",
      "Iteration: 3883; Percent complete: 97.1%; Average loss: 2.7175\n",
      "Iteration: 3884; Percent complete: 97.1%; Average loss: 2.9140\n",
      "Iteration: 3885; Percent complete: 97.1%; Average loss: 2.7382\n",
      "Iteration: 3886; Percent complete: 97.2%; Average loss: 2.4912\n",
      "Iteration: 3887; Percent complete: 97.2%; Average loss: 2.7386\n",
      "Iteration: 3888; Percent complete: 97.2%; Average loss: 2.6930\n",
      "Iteration: 3889; Percent complete: 97.2%; Average loss: 2.5423\n",
      "Iteration: 3890; Percent complete: 97.2%; Average loss: 2.6614\n",
      "Iteration: 3891; Percent complete: 97.3%; Average loss: 2.8658\n",
      "Iteration: 3892; Percent complete: 97.3%; Average loss: 2.7217\n",
      "Iteration: 3893; Percent complete: 97.3%; Average loss: 2.5815\n",
      "Iteration: 3894; Percent complete: 97.4%; Average loss: 2.4968\n",
      "Iteration: 3895; Percent complete: 97.4%; Average loss: 2.6752\n",
      "Iteration: 3896; Percent complete: 97.4%; Average loss: 2.7592\n",
      "Iteration: 3897; Percent complete: 97.4%; Average loss: 2.7382\n",
      "Iteration: 3898; Percent complete: 97.5%; Average loss: 2.7946\n",
      "Iteration: 3899; Percent complete: 97.5%; Average loss: 2.6107\n",
      "Iteration: 3900; Percent complete: 97.5%; Average loss: 2.6435\n",
      "Iteration: 3901; Percent complete: 97.5%; Average loss: 2.6608\n",
      "Iteration: 3902; Percent complete: 97.5%; Average loss: 2.5030\n",
      "Iteration: 3903; Percent complete: 97.6%; Average loss: 2.6083\n",
      "Iteration: 3904; Percent complete: 97.6%; Average loss: 2.5874\n",
      "Iteration: 3905; Percent complete: 97.6%; Average loss: 2.6836\n",
      "Iteration: 3906; Percent complete: 97.7%; Average loss: 2.6553\n",
      "Iteration: 3907; Percent complete: 97.7%; Average loss: 2.7086\n",
      "Iteration: 3908; Percent complete: 97.7%; Average loss: 2.5893\n",
      "Iteration: 3909; Percent complete: 97.7%; Average loss: 2.6382\n",
      "Iteration: 3910; Percent complete: 97.8%; Average loss: 2.5498\n",
      "Iteration: 3911; Percent complete: 97.8%; Average loss: 2.4810\n",
      "Iteration: 3912; Percent complete: 97.8%; Average loss: 2.6768\n",
      "Iteration: 3913; Percent complete: 97.8%; Average loss: 2.4554\n",
      "Iteration: 3914; Percent complete: 97.9%; Average loss: 2.6367\n",
      "Iteration: 3915; Percent complete: 97.9%; Average loss: 2.5724\n",
      "Iteration: 3916; Percent complete: 97.9%; Average loss: 2.6495\n",
      "Iteration: 3917; Percent complete: 97.9%; Average loss: 2.4811\n",
      "Iteration: 3918; Percent complete: 98.0%; Average loss: 2.4607\n",
      "Iteration: 3919; Percent complete: 98.0%; Average loss: 2.8312\n",
      "Iteration: 3920; Percent complete: 98.0%; Average loss: 2.7209\n",
      "Iteration: 3921; Percent complete: 98.0%; Average loss: 2.7160\n",
      "Iteration: 3922; Percent complete: 98.0%; Average loss: 2.8307\n",
      "Iteration: 3923; Percent complete: 98.1%; Average loss: 2.7633\n",
      "Iteration: 3924; Percent complete: 98.1%; Average loss: 2.9466\n",
      "Iteration: 3925; Percent complete: 98.1%; Average loss: 2.5440\n",
      "Iteration: 3926; Percent complete: 98.2%; Average loss: 2.4603\n",
      "Iteration: 3927; Percent complete: 98.2%; Average loss: 2.5636\n",
      "Iteration: 3928; Percent complete: 98.2%; Average loss: 2.9691\n",
      "Iteration: 3929; Percent complete: 98.2%; Average loss: 2.6196\n",
      "Iteration: 3930; Percent complete: 98.2%; Average loss: 2.5323\n",
      "Iteration: 3931; Percent complete: 98.3%; Average loss: 2.3430\n",
      "Iteration: 3932; Percent complete: 98.3%; Average loss: 2.9050\n",
      "Iteration: 3933; Percent complete: 98.3%; Average loss: 2.5606\n",
      "Iteration: 3934; Percent complete: 98.4%; Average loss: 2.7507\n",
      "Iteration: 3935; Percent complete: 98.4%; Average loss: 2.7561\n",
      "Iteration: 3936; Percent complete: 98.4%; Average loss: 2.6409\n",
      "Iteration: 3937; Percent complete: 98.4%; Average loss: 2.8119\n",
      "Iteration: 3938; Percent complete: 98.5%; Average loss: 2.5014\n",
      "Iteration: 3939; Percent complete: 98.5%; Average loss: 2.7470\n",
      "Iteration: 3940; Percent complete: 98.5%; Average loss: 2.6831\n",
      "Iteration: 3941; Percent complete: 98.5%; Average loss: 2.6739\n",
      "Iteration: 3942; Percent complete: 98.6%; Average loss: 2.5648\n",
      "Iteration: 3943; Percent complete: 98.6%; Average loss: 2.7060\n",
      "Iteration: 3944; Percent complete: 98.6%; Average loss: 2.7278\n",
      "Iteration: 3945; Percent complete: 98.6%; Average loss: 2.7134\n",
      "Iteration: 3946; Percent complete: 98.7%; Average loss: 2.5586\n",
      "Iteration: 3947; Percent complete: 98.7%; Average loss: 2.6631\n",
      "Iteration: 3948; Percent complete: 98.7%; Average loss: 2.4562\n",
      "Iteration: 3949; Percent complete: 98.7%; Average loss: 2.6221\n",
      "Iteration: 3950; Percent complete: 98.8%; Average loss: 2.5409\n",
      "Iteration: 3951; Percent complete: 98.8%; Average loss: 2.7434\n",
      "Iteration: 3952; Percent complete: 98.8%; Average loss: 2.6169\n",
      "Iteration: 3953; Percent complete: 98.8%; Average loss: 2.3909\n",
      "Iteration: 3954; Percent complete: 98.9%; Average loss: 2.6249\n",
      "Iteration: 3955; Percent complete: 98.9%; Average loss: 2.7647\n",
      "Iteration: 3956; Percent complete: 98.9%; Average loss: 2.6571\n",
      "Iteration: 3957; Percent complete: 98.9%; Average loss: 2.4930\n",
      "Iteration: 3958; Percent complete: 99.0%; Average loss: 2.4042\n",
      "Iteration: 3959; Percent complete: 99.0%; Average loss: 2.9591\n",
      "Iteration: 3960; Percent complete: 99.0%; Average loss: 2.6932\n",
      "Iteration: 3961; Percent complete: 99.0%; Average loss: 2.5330\n",
      "Iteration: 3962; Percent complete: 99.1%; Average loss: 2.7501\n",
      "Iteration: 3963; Percent complete: 99.1%; Average loss: 2.7160\n",
      "Iteration: 3964; Percent complete: 99.1%; Average loss: 2.5589\n",
      "Iteration: 3965; Percent complete: 99.1%; Average loss: 2.5702\n",
      "Iteration: 3966; Percent complete: 99.2%; Average loss: 2.7847\n",
      "Iteration: 3967; Percent complete: 99.2%; Average loss: 2.6711\n",
      "Iteration: 3968; Percent complete: 99.2%; Average loss: 2.6549\n",
      "Iteration: 3969; Percent complete: 99.2%; Average loss: 2.7142\n",
      "Iteration: 3970; Percent complete: 99.2%; Average loss: 2.5803\n",
      "Iteration: 3971; Percent complete: 99.3%; Average loss: 2.5902\n",
      "Iteration: 3972; Percent complete: 99.3%; Average loss: 2.5613\n",
      "Iteration: 3973; Percent complete: 99.3%; Average loss: 2.6055\n",
      "Iteration: 3974; Percent complete: 99.4%; Average loss: 2.6768\n",
      "Iteration: 3975; Percent complete: 99.4%; Average loss: 2.5305\n",
      "Iteration: 3976; Percent complete: 99.4%; Average loss: 2.8735\n",
      "Iteration: 3977; Percent complete: 99.4%; Average loss: 2.6139\n",
      "Iteration: 3978; Percent complete: 99.5%; Average loss: 2.5500\n",
      "Iteration: 3979; Percent complete: 99.5%; Average loss: 2.3924\n",
      "Iteration: 3980; Percent complete: 99.5%; Average loss: 2.4942\n",
      "Iteration: 3981; Percent complete: 99.5%; Average loss: 2.5486\n",
      "Iteration: 3982; Percent complete: 99.6%; Average loss: 2.6154\n",
      "Iteration: 3983; Percent complete: 99.6%; Average loss: 2.5299\n",
      "Iteration: 3984; Percent complete: 99.6%; Average loss: 2.5456\n",
      "Iteration: 3985; Percent complete: 99.6%; Average loss: 2.6009\n",
      "Iteration: 3986; Percent complete: 99.7%; Average loss: 2.8824\n",
      "Iteration: 3987; Percent complete: 99.7%; Average loss: 2.6323\n",
      "Iteration: 3988; Percent complete: 99.7%; Average loss: 2.5172\n",
      "Iteration: 3989; Percent complete: 99.7%; Average loss: 2.6723\n",
      "Iteration: 3990; Percent complete: 99.8%; Average loss: 2.7110\n",
      "Iteration: 3991; Percent complete: 99.8%; Average loss: 2.7118\n",
      "Iteration: 3992; Percent complete: 99.8%; Average loss: 2.4058\n",
      "Iteration: 3993; Percent complete: 99.8%; Average loss: 2.3599\n",
      "Iteration: 3994; Percent complete: 99.9%; Average loss: 2.4839\n",
      "Iteration: 3995; Percent complete: 99.9%; Average loss: 2.4875\n",
      "Iteration: 3996; Percent complete: 99.9%; Average loss: 2.5872\n",
      "Iteration: 3997; Percent complete: 99.9%; Average loss: 2.6011\n",
      "Iteration: 3998; Percent complete: 100.0%; Average loss: 2.6643\n",
      "Iteration: 3999; Percent complete: 100.0%; Average loss: 2.6179\n",
      "Iteration: 4000; Percent complete: 100.0%; Average loss: 2.4628\n"
     ]
    }
   ],
   "source": [
    "# Configure training/optimization\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 1.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 4000\n",
    "print_every = 1\n",
    "save_every = 500\n",
    "\n",
    "# Ensure dropout layers are in train mode\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "# Initialize optimizers\n",
    "print('Building optimizers ...')\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "if loadFilename:\n",
    "    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n",
    "    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n",
    "\n",
    "# Run training iterations\n",
    "print(\"Starting Training!\")\n",
    "trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
    "           print_every, save_every, clip, corpus_name, loadFilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 运行评估\n",
    "\n",
    "要和这个模型聊天，运行下面的代码块。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set dropout layers to eval mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Initialize search module\n",
    "searcher = GreedySearchDecoder(encoder, decoder)\n",
    "\n",
    "# Begin chatting (uncomment and run the following line to begin)\n",
    "# evaluateInput(encoder, decoder, searcher, voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结论\n",
    "\n",
    "伙计们，这就是这一切。恭喜你，现在知道了构建生成聊天机器人模型的基础知识！如果有兴趣，可以尝试通过调整模型和训练参数以及自定义训练模型的数据来定制聊天机器人的行为。\n",
    "\n",
    "查看其他教程，了解PyTorch中更酷的深度学习应用程序！\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-tutorials",
   "language": "python",
   "name": "pytorch-tutorials"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
