{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"pytorch-tutorials-notebooks-zhs PyTorch tutorials \u7684\u4e2d\u6587\u7ffb\u8bd1\u7b14\u8bb0\u3002 \u70b9\u51fb\u8fd9\u4e2a\u94fe\u63a5\u76f4\u63a5\u8bbf\u95ee\u5176Web\u6587\u6863\uff1a https://tanbro.github.io/pytorch-tutorials-notebooks-zhs/ \u5b98\u65b9\u6559\u7a0b\u4ee5 \u5e26\u6709 Sphinx-Doc \u6269\u5c55 rST \u683c\u5f0f\u6ce8\u91ca\u7684Python\u6e90\u4ee3\u7801 \u7684\u5f62\u5f0f\u5236\u4f5c\u4e86Web\u6587\u6863\u5e76\u5bfc\u51fa Jupyter \u7b14\u8bb0\u3002 \u800c\u8fd9\u4e2a\u9879\u76ee\u9664\u4e86\u7ffb\u8bd1\uff0c\u4fee\u6539\u8fd8\u6709: \u4f7f\u7528 Jupyter Notebook \u4fdd\u5b58\u8bf4\u660e\u548c\u4ee3\u7801\u7247\u6bb5 \u7531 Jupyter Notebook \u5bfc\u51faMarkdown\u6587\u4ef6\uff0c\u5e76\u5728\u5176\u57fa\u7840\u4e0a\u6784\u5efaWeb\u6587\u6863 \u8fd9\u662f\u4e2a\u4eba\u7684\u7ffb\u8bd1\u7b14\u8bb0\uff0c\u7528\u4e8e\u4e2a\u4eba\u5b66\u4e60 PyTorch\u3002 \u76ee\u524d\u53ea\u7ffb\u8bd1\u548c\u8f6c\u6362\u4e86\u90e8\u5206 *.py \u6587\u4ef6(\u7528 Sphinx-Gallery \u5236\u4f5c\u4e86 Jupyter Notebook) \uff0c\u6ca1\u6709\u5904\u7406\u4efb\u4f55 *.rst (\u5355\u7eaf\u7684 Sphinx-Doc \u6587\u6863) \u73af\u5883 \u8fd9\u4e2a\u5de5\u7a0b\u91c7\u5728 Ubuntu 1604, 1804 \u4e0b\uff0c\u4f7f\u7528 Python 3.6 \u8fd0\u884c\u548c\u6784\u5efa\uff0c\u6ca1\u6709\u6d4b\u8bd5\u8fc7\u5176\u5b83\u73af\u5883\u3002 \u5f3a\u70c8 \u5efa\u8bae\u4e3a\u8fd9\u4e2a\u9879\u76ee\u5355\u72ec\u65b0\u5efa\u4e00\u4e2a\u4e13\u7528\u7684 venv \u6216 Conda \u73af\u5883 pip : 1 pip install -r requirements.txt Pipenv : 1 pipenv install Conda : 1 2 3 conda install -y jupyter tqdm pandas matplotlib scikit-image pygments conda install -y pytorch torchvision cudatoolkit=9.0 -c pytorch pip install pymdown-extensions mkdocs-material \u8fd0\u884c Jupyter Notebook \u5165\u95e8\u6307\u5357\u7684\u7ffb\u8bd1\u4ee5 Jupyter \u7b14\u8bb0\u7684\u5f62\u5f0f\u4fdd\u5b58\u5728 notebooks \u76ee\u5f55\uff0c\u542f\u52a8 Jupyter notebooks: 1 jupyter-notebook \u5728 notebooks \u76ee\u5f55\u53ef\u4ee5\u627e\u5230\u6240\u6709\u7b14\u8bb0\u3002 \u6784\u5efa Web \u6587\u6863 \u8fd9\u4e2a\u9879\u76ee\u4f7f\u7528 MkDocs \u5c06\u591a\u4e2a\u7531\u7b14\u8bb0\u672c\u5bfc\u51fa Markdown \u6587\u6863\u751f\u6210\u4e00\u4e2a Web \u6587\u6863\u3002 \u628a\u7b14\u8bb0\u5bfc\u51fa\u4e3aMarkdown\u6587\u4ef6: 1 python tools/nb_export_mk.py \u6784\u5efaWeb\u6587\u6863 1 mkdocs build \u8fd0\u884cWeb\u6587\u6863\u670d\u52a1\u5668\uff0c\u8bbf\u95ee http://localhost:8000/ \u67e5\u770b 1 mkdocs serve Jupyter Notebook \u65e0\u6cd5\u5bfc\u51fa\u542b\u6709\u4e2d\u6587 latex/pdf \u7684\u95ee\u9898 \u91c7\u7528\u6765\u81ea https://github.com/jupyter/notebook/issues/2848#issuecomment-372736199 \u7684\u65b9\u6cd5\uff1a \u5b89\u88c5 texlive 1 sudo apt install texlive-xetex \u5b89\u88c5 pandoc 1 sudo apt install pandoc \u4fee\u6539 Aritcal tex \u6a21\u677f \u627e\u5230\u6587\u4ef6 site-packages/nbconvert/templates/latex/article.tplx , \u5728 \\documentclass[11pt]{article} \u4e4b\u540e\u52a0\u4e0a\u4e2d\u6587\u5b57\u4f53\u5b9a\u4e49: 1 2 3 4 5 6 7 ((* block docclass *)) \\documentclass [11pt] { article } % \u4e2d\u6587\u95ee\u9898: https://github.com/jupyter/notebook/issues/2848#issuecomment-372736199 \\usepackage { xeCJK } \\setCJKmainfont { Noto Sans CJK SC } \\setCJKmonofont { Noto Sans Mono CJK SC } ((* endblock docclass *)) \u5177\u4f53\u91c7\u7528\u54ea\u4e2a\u7684\u5b57\u4f53\u5e94\u4ee5\u5b9e\u9645\u60c5\u51b5\u4e3a\u51c6","title":"README"},{"location":"#pytorch-tutorials-notebooks-zhs","text":"PyTorch tutorials \u7684\u4e2d\u6587\u7ffb\u8bd1\u7b14\u8bb0\u3002 \u70b9\u51fb\u8fd9\u4e2a\u94fe\u63a5\u76f4\u63a5\u8bbf\u95ee\u5176Web\u6587\u6863\uff1a https://tanbro.github.io/pytorch-tutorials-notebooks-zhs/ \u5b98\u65b9\u6559\u7a0b\u4ee5 \u5e26\u6709 Sphinx-Doc \u6269\u5c55 rST \u683c\u5f0f\u6ce8\u91ca\u7684Python\u6e90\u4ee3\u7801 \u7684\u5f62\u5f0f\u5236\u4f5c\u4e86Web\u6587\u6863\u5e76\u5bfc\u51fa Jupyter \u7b14\u8bb0\u3002 \u800c\u8fd9\u4e2a\u9879\u76ee\u9664\u4e86\u7ffb\u8bd1\uff0c\u4fee\u6539\u8fd8\u6709: \u4f7f\u7528 Jupyter Notebook \u4fdd\u5b58\u8bf4\u660e\u548c\u4ee3\u7801\u7247\u6bb5 \u7531 Jupyter Notebook \u5bfc\u51faMarkdown\u6587\u4ef6\uff0c\u5e76\u5728\u5176\u57fa\u7840\u4e0a\u6784\u5efaWeb\u6587\u6863 \u8fd9\u662f\u4e2a\u4eba\u7684\u7ffb\u8bd1\u7b14\u8bb0\uff0c\u7528\u4e8e\u4e2a\u4eba\u5b66\u4e60 PyTorch\u3002 \u76ee\u524d\u53ea\u7ffb\u8bd1\u548c\u8f6c\u6362\u4e86\u90e8\u5206 *.py \u6587\u4ef6(\u7528 Sphinx-Gallery \u5236\u4f5c\u4e86 Jupyter Notebook) \uff0c\u6ca1\u6709\u5904\u7406\u4efb\u4f55 *.rst (\u5355\u7eaf\u7684 Sphinx-Doc \u6587\u6863)","title":"pytorch-tutorials-notebooks-zhs"},{"location":"#_1","text":"\u8fd9\u4e2a\u5de5\u7a0b\u91c7\u5728 Ubuntu 1604, 1804 \u4e0b\uff0c\u4f7f\u7528 Python 3.6 \u8fd0\u884c\u548c\u6784\u5efa\uff0c\u6ca1\u6709\u6d4b\u8bd5\u8fc7\u5176\u5b83\u73af\u5883\u3002 \u5f3a\u70c8 \u5efa\u8bae\u4e3a\u8fd9\u4e2a\u9879\u76ee\u5355\u72ec\u65b0\u5efa\u4e00\u4e2a\u4e13\u7528\u7684 venv \u6216 Conda \u73af\u5883 pip : 1 pip install -r requirements.txt Pipenv : 1 pipenv install Conda : 1 2 3 conda install -y jupyter tqdm pandas matplotlib scikit-image pygments conda install -y pytorch torchvision cudatoolkit=9.0 -c pytorch pip install pymdown-extensions mkdocs-material","title":"\u73af\u5883"},{"location":"#jupyter-notebook","text":"\u5165\u95e8\u6307\u5357\u7684\u7ffb\u8bd1\u4ee5 Jupyter \u7b14\u8bb0\u7684\u5f62\u5f0f\u4fdd\u5b58\u5728 notebooks \u76ee\u5f55\uff0c\u542f\u52a8 Jupyter notebooks: 1 jupyter-notebook \u5728 notebooks \u76ee\u5f55\u53ef\u4ee5\u627e\u5230\u6240\u6709\u7b14\u8bb0\u3002","title":"\u8fd0\u884c Jupyter Notebook"},{"location":"#web","text":"\u8fd9\u4e2a\u9879\u76ee\u4f7f\u7528 MkDocs \u5c06\u591a\u4e2a\u7531\u7b14\u8bb0\u672c\u5bfc\u51fa Markdown \u6587\u6863\u751f\u6210\u4e00\u4e2a Web \u6587\u6863\u3002 \u628a\u7b14\u8bb0\u5bfc\u51fa\u4e3aMarkdown\u6587\u4ef6: 1 python tools/nb_export_mk.py \u6784\u5efaWeb\u6587\u6863 1 mkdocs build \u8fd0\u884cWeb\u6587\u6863\u670d\u52a1\u5668\uff0c\u8bbf\u95ee http://localhost:8000/ \u67e5\u770b 1 mkdocs serve","title":"\u6784\u5efa Web \u6587\u6863"},{"location":"#jupyter-notebook-latexpdf","text":"\u91c7\u7528\u6765\u81ea https://github.com/jupyter/notebook/issues/2848#issuecomment-372736199 \u7684\u65b9\u6cd5\uff1a \u5b89\u88c5 texlive 1 sudo apt install texlive-xetex \u5b89\u88c5 pandoc 1 sudo apt install pandoc \u4fee\u6539 Aritcal tex \u6a21\u677f \u627e\u5230\u6587\u4ef6 site-packages/nbconvert/templates/latex/article.tplx , \u5728 \\documentclass[11pt]{article} \u4e4b\u540e\u52a0\u4e0a\u4e2d\u6587\u5b57\u4f53\u5b9a\u4e49: 1 2 3 4 5 6 7 ((* block docclass *)) \\documentclass [11pt] { article } % \u4e2d\u6587\u95ee\u9898: https://github.com/jupyter/notebook/issues/2848#issuecomment-372736199 \\usepackage { xeCJK } \\setCJKmainfont { Noto Sans CJK SC } \\setCJKmonofont { Noto Sans Mono CJK SC } ((* endblock docclass *)) \u5177\u4f53\u91c7\u7528\u54ea\u4e2a\u7684\u5b57\u4f53\u5e94\u4ee5\u5b9e\u9645\u60c5\u51b5\u4e3a\u51c6","title":"Jupyter Notebook \u65e0\u6cd5\u5bfc\u51fa\u542b\u6709\u4e2d\u6587 latex/pdf \u7684\u95ee\u9898"},{"location":"beginner/blitz/autograd_tutorial/","text":"1 % matplotlib inline Autograd: \u81ea\u52a8\u5fae\u5206(Automatic differentiation) autograd \u5305 \u662f PyTorch \u4e2d\u6240\u6709\u795e\u7ecf\u7f51\u7edc\u7684\u4e2d\u5fc3\u3002 \u6211\u4eec\u9996\u5148\u7b80\u8981\u67e5\u770b\uff0c\u7136\u540e\u8bad\u7ec3\u7b2c\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u3002 autograd \u5305\u4e3a Tensor \u4e0a\u7684\u6240\u6709\u8fd0\u7b97\u63d0\u4f9b\u81ea\u52a8\u5fae\u5206(automatic differentiation)\u3002 \u5b83\u662f\u4e00\u4e2a\u201c\u8fd0\u884c\u4e2d\u5b9a\u4e49\u201d(define-by-run)\u7684\u6846\u67b6\uff0c\u8fd9\u610f\u5473\u7740\u53cd\u5411\u4f20\u64ad(backpropagation)\u7b97\u6cd5\u7531\u4ee3\u7801\u5728\u8fd0\u884c\u65f6\u5b9a\u4e49\uff0c\u5e76\u4e14\u6bcf\u4e2a\u8fed\u4ee3\u90fd\u53ef\u4ee5\u4e0d\u540c\u3002 \u6211\u4eec\u901a\u8fc7\u66f4\u7b80\u5355\u7684\u672f\u8bed\u7684\u4f8b\u5b50\u6765\u770b\u770b\u8fd9\u4e9b\u3002 \u5f20\u91cf(Tensor) torch.Tensor \u662f\u8fd9\u4e2a\u5305\u7684\u4e2d\u5fc3\u7c7b\u3002 \u5c06\u5b83\u7684 .requires_grad \u5c5e\u6027\u8bbe\u7f6e\u4e3a True \uff0c\u5373\u5f00\u59cb\u8ddf\u8e2a\u5176\u4e0a\u7684\u6240\u6709\u8fd0\u7b97\u3002 \u5b8c\u6210\u8ba1\u7b97\u540e\u8c03\u7528 .backward() \u5373\u53ef\u81ea\u52a8\u5b8c\u6210\u68af\u5ea6\u8ba1\u7b97\u3002 \u8be5 tensor \u68af\u5ea6\u7684\u7d2f\u8ba1\u548c\u8bb0\u5f55\u5728 .grad \u5c5e\u6027\u3002 \u8981\u505c\u6b62 tensor \u7684\u5386\u53f2\u8ddf\u8e2a\uff0c\u53ef\u8c03\u7528 .detach() \uff0c\u5c06\u5b83\u4ece\u8ba1\u7b97\u5386\u53f2\u4e2d\u5206\u79bb\u51fa\u6765\uff0c\u9632\u6b62\u5b83\u5728\u5c06\u6765\u7684\u8ba1\u7b97\u4e2d\u88ab\u8ddf\u8e2a\u3002 \u8981\u9632\u6b62\u5386\u53f2\u8ddf\u8e2a\uff08\u548c\u5185\u5b58\u7684\u4f7f\u7528\uff09\uff0c\u8fd8\u53ef\u4ee5\u5c06\u4ee3\u7801\u5757\u653e\u7f6e\u5728 with torch.no_grad(): \u4e2d\u3002 \u8fd9\u5728\u8bc4\u4f30\u6a21\u578b\u65f6\u5c24\u5176\u6709\u7528\uff0c\u56e0\u4e3a\u6a21\u578b\u53ef\u80fd\u5177\u6709\u53ef\u8bad\u7ec3\u7684\u53c2\u6570 requires_grad=True \uff0c\u4f46\u8fdb\u884c\u8bc4\u4f30\u65f6\u4e0d\u9700\u8981\u68af\u5ea6\u3002 \u8fd8\u6709\u4e00\u4e2a\u7c7b\u5bf9\u4e8e autograd \u5b9e\u73b0\u975e\u5e38\u91cd\u8981\u2014\u2014 Function \u3002 Tensor \u548c Function \u4e92\u76f8\u8fde\u63a5\u5e76\u6784\u5efa\u4e00\u4e2a\u975e\u5faa\u73af\u56fe\uff0c\u5b83\u5c06\u5b8c\u6574\u7684\u8ba1\u7b97\u5386\u53f2\u8fdb\u884c\u4e86\u7f16\u7801\u8bb0\u5f55\u3002 \u6bcf\u4e2a tensor \u90fd\u6709\u4e00\u4e2a .grad_fn \u5c5e\u6027\uff0c\u8be5\u5c5e\u6027\u6307\u5411\u521b\u5efa\u8fd9\u4e2a Tensor \u7684 Function \uff08\u9664\u4e86\u7528\u6237\u521b\u5efa\u7684 Tensor\u2014\u2014\u4ed6\u4eec\u7684 grand_fn \u662f None \uff09 \u5982\u9700\u8ba1\u7b97\u5bfc\u6570(derivatives)\uff0c\u53ef\u4ee5\u8c03\u7528 Tensor \u7684 .backward() \u65b9\u6cd5\u3002 \u5982\u679c Tensor \u662f\u6807\u91cf\uff08\u5373\u5b83\u5305\u53ea\u542b\u5355\u5143\u7d20\u6570\u636e\uff09\uff0c\u5219 backward() \u4e0d\u9700\u8981\u6307\u5b9a\u53c2\u6570\uff0c\u4f46\u662f\u5982\u679c\u5b83\u6709\u591a\u4e2a\u5143\u7d20\uff0c\u5219\u9700\u8981\u6307\u5b9a\u4e00\u4e2a\u5f62\u72b6\u5339\u914d\u7684 tensor \u4f5c\u4e3a gradient \u53c2\u6570\u3002 1 import torch \u521b\u5efa\u4e00\u4e2a tensor\uff0c\u8bbe\u7f6e requires_grad=True \u8ddf\u8e2a\u5b83\u7684\u8ba1\u7b97 1 2 x = torch . ones ( 2 , 2 , requires_grad = True ) print ( x ) 1 2 tensor([[1., 1.], [1., 1.]], requires_grad=True) \u8fdb\u884c\u4e00\u6b21 tensor \u8fd0\u7b97\uff1a 1 2 y = x + 2 print ( y ) 1 2 tensor([[3., 3.], [3., 3.]], grad_fn=<AddBackward0>) y \u662f\u8fd9\u4e2a\u8fd0\u7b97\u7684\u7ed3\u679c\u5f20\u91cf\uff0c\u6240\u4ee5\u5b83\u4e5f\u6709 grad_fn \u3002 1 print ( y . grad_fn ) 1 <AddBackward0 object at 0x7f0e0159a438> \u5bf9 y \u505a\u66f4\u591a\u8fd0\u7b97 1 2 3 4 z = y * y * 3 out = z . mean () print ( z , out ) 1 2 tensor([[27., 27.], [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward1>) .requires_grad_( ... ) \u539f\u4f4d\u6539\u53d8\u4e86\u5df2\u6709 Tensor \u7684 requires_grad \u6807\u5fd7\u3002\u8be5\u8f93\u5165\u6807\u5fd7\u7684\u9ed8\u8ba4\u503c\u662f False \u3002 1 2 3 4 5 6 7 a = torch . randn ( 2 , 2 ) a = (( a * 3 ) / ( a - 1 )) print ( a . requires_grad ) a . requires_grad_ ( True ) print ( a . requires_grad ) b = ( a * a ) . sum () print ( b . grad_fn ) 1 2 3 False True <SumBackward0 object at 0x7f0d577bce80> \u68af\u5ea6(Gradients) \u73b0\u5728\u8fdb\u884c\u53cd\u5411\u4f20\u64ad(backprop)\u3002 \u7531\u4e8e out \u5305\u542b\u5355\u4e2a\u6807\u91cf\uff0c out.backward() \u76f8\u5f53\u4e8e out.backward(torch.tensor(1.)) \u3002 1 out . backward () \u8f93\u51fa\u68af\u5ea6 d(out)/dx 1 print ( x . grad ) 1 2 tensor([[4.5000, 4.5000], [4.5000, 4.5000]]) \u5f97\u5230\u4e00\u4e2a 4.5 \u77e9\u9635\u3002 \u5c06 out Tensor \u8bbe\u4e3a \u201c o o \u201d\u3002 \u6211\u4eec\u6709 o = \\frac{1}{4}\\sum_i z_i o = \\frac{1}{4}\\sum_i z_i z_i = 3(x_i+2)^2 z_i = 3(x_i+2)^2 \u4ee5\u53ca z_i\\bigr\\rvert_{x_i=1} = 27 z_i\\bigr\\rvert_{x_i=1} = 27 \u6240\u4ee5\uff0c \\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2) \\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2) \u90a3\u4e48 \\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5 \\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5 \u5728\u6570\u5b66\u4e0a\uff0c\u82e5\u6709\u5411\u91cf\u503c\u51fd\u6570 \\vec{y}=f(\\vec{x}) \\vec{y}=f(\\vec{x}) \uff0c \u5219 \\vec{y} \\vec{y} \u7684\u68af\u5ea6\u662f\u5173\u4e8e \\vec{x} \\vec{x} \u7684\u96c5\u53ef\u6bd4\u77e9\u9635\uff1a \\begin{align}J=\\left(\\begin{array}{ccc} \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{1}}{\\partial x_{n}}\\\\ \\vdots & \\ddots & \\vdots\\\\ \\frac{\\partial y_{m}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}} \\end{array}\\right)\\end{align} \\begin{align}J=\\left(\\begin{array}{ccc} \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{1}}{\\partial x_{n}}\\\\ \\vdots & \\ddots & \\vdots\\\\ \\frac{\\partial y_{m}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}} \\end{array}\\right)\\end{align} \u4e00\u822c\u6765\u8bf4\uff0c torch.autograd \u5c31\u662f\u4e00\u4e2a\u8ba1\u7b97\u5411\u91cf\u96c5\u53ef\u6bd4\u79ef\u7684\u5f15\u64ce\u3002 \u4e5f\u5c31\u662f\u8bf4\uff0c\u5bf9\u7ed9\u5b9a\u7684\u4efb\u610f\u5411\u91cf v=\\left(\\begin{array}{cccc} v_{1} & v_{2} & \\cdots & v_{m}\\end{array}\\right)^{T} v=\\left(\\begin{array}{cccc} v_{1} & v_{2} & \\cdots & v_{m}\\end{array}\\right)^{T} \uff0c \u8ba1\u7b97 v^{T}\\cdot J v^{T}\\cdot J \u7684\u79ef\u3002 \u5982\u679c v v \u6070\u597d\u662f\u6807\u91cf\u51fd\u6570 l=g\\left(\\vec{y}\\right) l=g\\left(\\vec{y}\\right) \u7684\u68af\u5ea6\uff0c\u6362\u800c\u8a00\u4e4b\uff0c v=\\left(\\begin{array}{ccc}\\frac{\\partial l}{\\partial y_{1}} & \\cdots & \\frac{\\partial l}{\\partial y_{m}}\\end{array}\\right)^{T} v=\\left(\\begin{array}{ccc}\\frac{\\partial l}{\\partial y_{1}} & \\cdots & \\frac{\\partial l}{\\partial y_{m}}\\end{array}\\right)^{T} \uff0c \u90a3\u4e48\uff0c\u7531\u94fe\u89c4\u5219(chain rule)\u53ef\u77e5\uff0c\u5411\u91cf\u96c5\u53ef\u6bd4\u79ef\u662f l l \u5173\u4e8e \\vec{x} \\vec{x} \u7684\u68af\u5ea6\uff1a \\begin{align}J^{T}\\cdot v=\\left(\\begin{array}{ccc} \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{1}}\\\\ \\vdots & \\ddots & \\vdots\\\\ \\frac{\\partial y_{1}}{\\partial x_{n}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}} \\end{array}\\right)\\left(\\begin{array}{c} \\frac{\\partial l}{\\partial y_{1}}\\\\ \\vdots\\\\ \\frac{\\partial l}{\\partial y_{m}} \\end{array}\\right)=\\left(\\begin{array}{c} \\frac{\\partial l}{\\partial x_{1}}\\\\ \\vdots\\\\ \\frac{\\partial l}{\\partial x_{n}} \\end{array}\\right)\\end{align} \\begin{align}J^{T}\\cdot v=\\left(\\begin{array}{ccc} \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{1}}\\\\ \\vdots & \\ddots & \\vdots\\\\ \\frac{\\partial y_{1}}{\\partial x_{n}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}} \\end{array}\\right)\\left(\\begin{array}{c} \\frac{\\partial l}{\\partial y_{1}}\\\\ \\vdots\\\\ \\frac{\\partial l}{\\partial y_{m}} \\end{array}\\right)=\\left(\\begin{array}{c} \\frac{\\partial l}{\\partial x_{1}}\\\\ \\vdots\\\\ \\frac{\\partial l}{\\partial x_{n}} \\end{array}\\right)\\end{align} (\u6ce8\u610f v^{T}\\cdot J v^{T}\\cdot J \u7ed9\u51fa\u4e86\u4e00\u4e2a\u884c\u5411\u91cf\uff0c\u5b83\u53ef\u88ab\u89c6\u4f5c J^{T}\\cdot v J^{T}\\cdot v \u5217\u5411\u91cf\u3002) \u5411\u91cf\u96c5\u53ef\u6bd4\u79ef\u7684\u8fd9\u4e9b\u6027\u8d28\u4f7f\u5f97\u5c06\u5916\u90e8\u68af\u5ea6\u9001\u5230\u975e\u6807\u91cf\u8f93\u51fa\u6a21\u578b\u4e2d\u53d8\u5f97\u975e\u5e38\u65b9\u4fbf\u3002 \u73b0\u5728\uff0c\u6211\u4eec\u770b\u4e00\u4e2a\u5411\u91cf\u96c5\u53ef\u6bd4\u79ef\u7684\u4f8b\u5b50\uff1a 1 2 3 4 5 6 7 x = torch . randn ( 3 , requires_grad = True ) y = x * 2 while y . data . norm () < 1000 : y = y * 2 print ( y ) 1 tensor([ -195.7767, -1443.5500, 69.6174], grad_fn=<MulBackward0>) \u73b0\u5728\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c y \u4e0d\u518d\u662f\u6807\u91cf\u4e86\u3002 torch.autograd \u65e0\u6cd5\u76f4\u63a5\u8ba1\u7b97\u5b8c\u6574\u7684\u5411\u91cf\u96c5\u53ef\u6bd4\u884c\u5217\u5f0f\uff0c \u4f46\u662f\u5982\u679c\u6211\u4eec\u53ea\u662f\u9700\u8981\u5411\u91cf-\u5411\u91cf-\u96c5\u53ef\u6bd4\u79ef, \u53ea\u8981\u628a\u5411\u91cf\u4f20\u7ed9\u53c2\u6570 backward : 1 2 3 4 v = torch . tensor ([ 0.1 , 1.0 , 0.0001 ], dtype = torch . float ) y . backward ( v ) print ( x . grad ) 1 tensor([2.0480e+02, 2.0480e+03, 2.0480e-01]) \u53e6\u5916\uff0c\u7528 .requires_grad=True: \u5305\u542b\u4ee3\u7801\u5757\u53ef\u4ee5\u8ba9 autograd \u505c\u6b62\u8ddf\u8e2a Tensor \u7684\u5386\u53f2 1 2 3 4 5 print ( x . requires_grad ) print (( x ** 2 ) . requires_grad ) with torch . no_grad (): print (( x ** 2 ) . requires_grad ) 1 2 3 True True False \u5ef6\u540e\u9605\u8bfb: autograd \u548c Function \u7684\u6587\u6863\u5728 https://pytorch.org/docs/autograd","title":"Autograd\uff1a\u81ea\u52a8\u5fae\u5206"},{"location":"beginner/blitz/autograd_tutorial/#autograd-automatic-differentiation","text":"autograd \u5305 \u662f PyTorch \u4e2d\u6240\u6709\u795e\u7ecf\u7f51\u7edc\u7684\u4e2d\u5fc3\u3002 \u6211\u4eec\u9996\u5148\u7b80\u8981\u67e5\u770b\uff0c\u7136\u540e\u8bad\u7ec3\u7b2c\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u3002 autograd \u5305\u4e3a Tensor \u4e0a\u7684\u6240\u6709\u8fd0\u7b97\u63d0\u4f9b\u81ea\u52a8\u5fae\u5206(automatic differentiation)\u3002 \u5b83\u662f\u4e00\u4e2a\u201c\u8fd0\u884c\u4e2d\u5b9a\u4e49\u201d(define-by-run)\u7684\u6846\u67b6\uff0c\u8fd9\u610f\u5473\u7740\u53cd\u5411\u4f20\u64ad(backpropagation)\u7b97\u6cd5\u7531\u4ee3\u7801\u5728\u8fd0\u884c\u65f6\u5b9a\u4e49\uff0c\u5e76\u4e14\u6bcf\u4e2a\u8fed\u4ee3\u90fd\u53ef\u4ee5\u4e0d\u540c\u3002 \u6211\u4eec\u901a\u8fc7\u66f4\u7b80\u5355\u7684\u672f\u8bed\u7684\u4f8b\u5b50\u6765\u770b\u770b\u8fd9\u4e9b\u3002","title":"Autograd: \u81ea\u52a8\u5fae\u5206(Automatic differentiation)"},{"location":"beginner/blitz/autograd_tutorial/#tensor","text":"torch.Tensor \u662f\u8fd9\u4e2a\u5305\u7684\u4e2d\u5fc3\u7c7b\u3002 \u5c06\u5b83\u7684 .requires_grad \u5c5e\u6027\u8bbe\u7f6e\u4e3a True \uff0c\u5373\u5f00\u59cb\u8ddf\u8e2a\u5176\u4e0a\u7684\u6240\u6709\u8fd0\u7b97\u3002 \u5b8c\u6210\u8ba1\u7b97\u540e\u8c03\u7528 .backward() \u5373\u53ef\u81ea\u52a8\u5b8c\u6210\u68af\u5ea6\u8ba1\u7b97\u3002 \u8be5 tensor \u68af\u5ea6\u7684\u7d2f\u8ba1\u548c\u8bb0\u5f55\u5728 .grad \u5c5e\u6027\u3002 \u8981\u505c\u6b62 tensor \u7684\u5386\u53f2\u8ddf\u8e2a\uff0c\u53ef\u8c03\u7528 .detach() \uff0c\u5c06\u5b83\u4ece\u8ba1\u7b97\u5386\u53f2\u4e2d\u5206\u79bb\u51fa\u6765\uff0c\u9632\u6b62\u5b83\u5728\u5c06\u6765\u7684\u8ba1\u7b97\u4e2d\u88ab\u8ddf\u8e2a\u3002 \u8981\u9632\u6b62\u5386\u53f2\u8ddf\u8e2a\uff08\u548c\u5185\u5b58\u7684\u4f7f\u7528\uff09\uff0c\u8fd8\u53ef\u4ee5\u5c06\u4ee3\u7801\u5757\u653e\u7f6e\u5728 with torch.no_grad(): \u4e2d\u3002 \u8fd9\u5728\u8bc4\u4f30\u6a21\u578b\u65f6\u5c24\u5176\u6709\u7528\uff0c\u56e0\u4e3a\u6a21\u578b\u53ef\u80fd\u5177\u6709\u53ef\u8bad\u7ec3\u7684\u53c2\u6570 requires_grad=True \uff0c\u4f46\u8fdb\u884c\u8bc4\u4f30\u65f6\u4e0d\u9700\u8981\u68af\u5ea6\u3002 \u8fd8\u6709\u4e00\u4e2a\u7c7b\u5bf9\u4e8e autograd \u5b9e\u73b0\u975e\u5e38\u91cd\u8981\u2014\u2014 Function \u3002 Tensor \u548c Function \u4e92\u76f8\u8fde\u63a5\u5e76\u6784\u5efa\u4e00\u4e2a\u975e\u5faa\u73af\u56fe\uff0c\u5b83\u5c06\u5b8c\u6574\u7684\u8ba1\u7b97\u5386\u53f2\u8fdb\u884c\u4e86\u7f16\u7801\u8bb0\u5f55\u3002 \u6bcf\u4e2a tensor \u90fd\u6709\u4e00\u4e2a .grad_fn \u5c5e\u6027\uff0c\u8be5\u5c5e\u6027\u6307\u5411\u521b\u5efa\u8fd9\u4e2a Tensor \u7684 Function \uff08\u9664\u4e86\u7528\u6237\u521b\u5efa\u7684 Tensor\u2014\u2014\u4ed6\u4eec\u7684 grand_fn \u662f None \uff09 \u5982\u9700\u8ba1\u7b97\u5bfc\u6570(derivatives)\uff0c\u53ef\u4ee5\u8c03\u7528 Tensor \u7684 .backward() \u65b9\u6cd5\u3002 \u5982\u679c Tensor \u662f\u6807\u91cf\uff08\u5373\u5b83\u5305\u53ea\u542b\u5355\u5143\u7d20\u6570\u636e\uff09\uff0c\u5219 backward() \u4e0d\u9700\u8981\u6307\u5b9a\u53c2\u6570\uff0c\u4f46\u662f\u5982\u679c\u5b83\u6709\u591a\u4e2a\u5143\u7d20\uff0c\u5219\u9700\u8981\u6307\u5b9a\u4e00\u4e2a\u5f62\u72b6\u5339\u914d\u7684 tensor \u4f5c\u4e3a gradient \u53c2\u6570\u3002 1 import torch \u521b\u5efa\u4e00\u4e2a tensor\uff0c\u8bbe\u7f6e requires_grad=True \u8ddf\u8e2a\u5b83\u7684\u8ba1\u7b97 1 2 x = torch . ones ( 2 , 2 , requires_grad = True ) print ( x ) 1 2 tensor([[1., 1.], [1., 1.]], requires_grad=True) \u8fdb\u884c\u4e00\u6b21 tensor \u8fd0\u7b97\uff1a 1 2 y = x + 2 print ( y ) 1 2 tensor([[3., 3.], [3., 3.]], grad_fn=<AddBackward0>) y \u662f\u8fd9\u4e2a\u8fd0\u7b97\u7684\u7ed3\u679c\u5f20\u91cf\uff0c\u6240\u4ee5\u5b83\u4e5f\u6709 grad_fn \u3002 1 print ( y . grad_fn ) 1 <AddBackward0 object at 0x7f0e0159a438> \u5bf9 y \u505a\u66f4\u591a\u8fd0\u7b97 1 2 3 4 z = y * y * 3 out = z . mean () print ( z , out ) 1 2 tensor([[27., 27.], [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward1>) .requires_grad_( ... ) \u539f\u4f4d\u6539\u53d8\u4e86\u5df2\u6709 Tensor \u7684 requires_grad \u6807\u5fd7\u3002\u8be5\u8f93\u5165\u6807\u5fd7\u7684\u9ed8\u8ba4\u503c\u662f False \u3002 1 2 3 4 5 6 7 a = torch . randn ( 2 , 2 ) a = (( a * 3 ) / ( a - 1 )) print ( a . requires_grad ) a . requires_grad_ ( True ) print ( a . requires_grad ) b = ( a * a ) . sum () print ( b . grad_fn ) 1 2 3 False True <SumBackward0 object at 0x7f0d577bce80>","title":"\u5f20\u91cf(Tensor)"},{"location":"beginner/blitz/autograd_tutorial/#gradients","text":"\u73b0\u5728\u8fdb\u884c\u53cd\u5411\u4f20\u64ad(backprop)\u3002 \u7531\u4e8e out \u5305\u542b\u5355\u4e2a\u6807\u91cf\uff0c out.backward() \u76f8\u5f53\u4e8e out.backward(torch.tensor(1.)) \u3002 1 out . backward () \u8f93\u51fa\u68af\u5ea6 d(out)/dx 1 print ( x . grad ) 1 2 tensor([[4.5000, 4.5000], [4.5000, 4.5000]]) \u5f97\u5230\u4e00\u4e2a 4.5 \u77e9\u9635\u3002 \u5c06 out Tensor \u8bbe\u4e3a \u201c o o \u201d\u3002 \u6211\u4eec\u6709 o = \\frac{1}{4}\\sum_i z_i o = \\frac{1}{4}\\sum_i z_i z_i = 3(x_i+2)^2 z_i = 3(x_i+2)^2 \u4ee5\u53ca z_i\\bigr\\rvert_{x_i=1} = 27 z_i\\bigr\\rvert_{x_i=1} = 27 \u6240\u4ee5\uff0c \\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2) \\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2) \u90a3\u4e48 \\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5 \\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5 \u5728\u6570\u5b66\u4e0a\uff0c\u82e5\u6709\u5411\u91cf\u503c\u51fd\u6570 \\vec{y}=f(\\vec{x}) \\vec{y}=f(\\vec{x}) \uff0c \u5219 \\vec{y} \\vec{y} \u7684\u68af\u5ea6\u662f\u5173\u4e8e \\vec{x} \\vec{x} \u7684\u96c5\u53ef\u6bd4\u77e9\u9635\uff1a \\begin{align}J=\\left(\\begin{array}{ccc} \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{1}}{\\partial x_{n}}\\\\ \\vdots & \\ddots & \\vdots\\\\ \\frac{\\partial y_{m}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}} \\end{array}\\right)\\end{align} \\begin{align}J=\\left(\\begin{array}{ccc} \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{1}}{\\partial x_{n}}\\\\ \\vdots & \\ddots & \\vdots\\\\ \\frac{\\partial y_{m}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}} \\end{array}\\right)\\end{align} \u4e00\u822c\u6765\u8bf4\uff0c torch.autograd \u5c31\u662f\u4e00\u4e2a\u8ba1\u7b97\u5411\u91cf\u96c5\u53ef\u6bd4\u79ef\u7684\u5f15\u64ce\u3002 \u4e5f\u5c31\u662f\u8bf4\uff0c\u5bf9\u7ed9\u5b9a\u7684\u4efb\u610f\u5411\u91cf v=\\left(\\begin{array}{cccc} v_{1} & v_{2} & \\cdots & v_{m}\\end{array}\\right)^{T} v=\\left(\\begin{array}{cccc} v_{1} & v_{2} & \\cdots & v_{m}\\end{array}\\right)^{T} \uff0c \u8ba1\u7b97 v^{T}\\cdot J v^{T}\\cdot J \u7684\u79ef\u3002 \u5982\u679c v v \u6070\u597d\u662f\u6807\u91cf\u51fd\u6570 l=g\\left(\\vec{y}\\right) l=g\\left(\\vec{y}\\right) \u7684\u68af\u5ea6\uff0c\u6362\u800c\u8a00\u4e4b\uff0c v=\\left(\\begin{array}{ccc}\\frac{\\partial l}{\\partial y_{1}} & \\cdots & \\frac{\\partial l}{\\partial y_{m}}\\end{array}\\right)^{T} v=\\left(\\begin{array}{ccc}\\frac{\\partial l}{\\partial y_{1}} & \\cdots & \\frac{\\partial l}{\\partial y_{m}}\\end{array}\\right)^{T} \uff0c \u90a3\u4e48\uff0c\u7531\u94fe\u89c4\u5219(chain rule)\u53ef\u77e5\uff0c\u5411\u91cf\u96c5\u53ef\u6bd4\u79ef\u662f l l \u5173\u4e8e \\vec{x} \\vec{x} \u7684\u68af\u5ea6\uff1a \\begin{align}J^{T}\\cdot v=\\left(\\begin{array}{ccc} \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{1}}\\\\ \\vdots & \\ddots & \\vdots\\\\ \\frac{\\partial y_{1}}{\\partial x_{n}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}} \\end{array}\\right)\\left(\\begin{array}{c} \\frac{\\partial l}{\\partial y_{1}}\\\\ \\vdots\\\\ \\frac{\\partial l}{\\partial y_{m}} \\end{array}\\right)=\\left(\\begin{array}{c} \\frac{\\partial l}{\\partial x_{1}}\\\\ \\vdots\\\\ \\frac{\\partial l}{\\partial x_{n}} \\end{array}\\right)\\end{align} \\begin{align}J^{T}\\cdot v=\\left(\\begin{array}{ccc} \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{1}}\\\\ \\vdots & \\ddots & \\vdots\\\\ \\frac{\\partial y_{1}}{\\partial x_{n}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}} \\end{array}\\right)\\left(\\begin{array}{c} \\frac{\\partial l}{\\partial y_{1}}\\\\ \\vdots\\\\ \\frac{\\partial l}{\\partial y_{m}} \\end{array}\\right)=\\left(\\begin{array}{c} \\frac{\\partial l}{\\partial x_{1}}\\\\ \\vdots\\\\ \\frac{\\partial l}{\\partial x_{n}} \\end{array}\\right)\\end{align} (\u6ce8\u610f v^{T}\\cdot J v^{T}\\cdot J \u7ed9\u51fa\u4e86\u4e00\u4e2a\u884c\u5411\u91cf\uff0c\u5b83\u53ef\u88ab\u89c6\u4f5c J^{T}\\cdot v J^{T}\\cdot v \u5217\u5411\u91cf\u3002) \u5411\u91cf\u96c5\u53ef\u6bd4\u79ef\u7684\u8fd9\u4e9b\u6027\u8d28\u4f7f\u5f97\u5c06\u5916\u90e8\u68af\u5ea6\u9001\u5230\u975e\u6807\u91cf\u8f93\u51fa\u6a21\u578b\u4e2d\u53d8\u5f97\u975e\u5e38\u65b9\u4fbf\u3002 \u73b0\u5728\uff0c\u6211\u4eec\u770b\u4e00\u4e2a\u5411\u91cf\u96c5\u53ef\u6bd4\u79ef\u7684\u4f8b\u5b50\uff1a 1 2 3 4 5 6 7 x = torch . randn ( 3 , requires_grad = True ) y = x * 2 while y . data . norm () < 1000 : y = y * 2 print ( y ) 1 tensor([ -195.7767, -1443.5500, 69.6174], grad_fn=<MulBackward0>) \u73b0\u5728\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c y \u4e0d\u518d\u662f\u6807\u91cf\u4e86\u3002 torch.autograd \u65e0\u6cd5\u76f4\u63a5\u8ba1\u7b97\u5b8c\u6574\u7684\u5411\u91cf\u96c5\u53ef\u6bd4\u884c\u5217\u5f0f\uff0c \u4f46\u662f\u5982\u679c\u6211\u4eec\u53ea\u662f\u9700\u8981\u5411\u91cf-\u5411\u91cf-\u96c5\u53ef\u6bd4\u79ef, \u53ea\u8981\u628a\u5411\u91cf\u4f20\u7ed9\u53c2\u6570 backward : 1 2 3 4 v = torch . tensor ([ 0.1 , 1.0 , 0.0001 ], dtype = torch . float ) y . backward ( v ) print ( x . grad ) 1 tensor([2.0480e+02, 2.0480e+03, 2.0480e-01]) \u53e6\u5916\uff0c\u7528 .requires_grad=True: \u5305\u542b\u4ee3\u7801\u5757\u53ef\u4ee5\u8ba9 autograd \u505c\u6b62\u8ddf\u8e2a Tensor \u7684\u5386\u53f2 1 2 3 4 5 print ( x . requires_grad ) print (( x ** 2 ) . requires_grad ) with torch . no_grad (): print (( x ** 2 ) . requires_grad ) 1 2 3 True True False \u5ef6\u540e\u9605\u8bfb: autograd \u548c Function \u7684\u6587\u6863\u5728 https://pytorch.org/docs/autograd","title":"\u68af\u5ea6(Gradients)"},{"location":"beginner/blitz/cifar10_tutorial/","text":"1 % matplotlib inline Training a Classifier This is it. You have seen how to define neural networks, compute loss and make updates to the weights of the network. Now you might be thinking, What about data? Generally, when you have to deal with image, text, audio or video data, you can use standard python packages that load data into a numpy array. Then you can convert this array into a torch.*Tensor . For images, packages such as Pillow, OpenCV are useful For audio, packages such as scipy and librosa For text, either raw Python or Cython based loading, or NLTK and SpaCy are useful Specifically for vision, we have created a package called torchvision , that has data loaders for common datasets such as Imagenet, CIFAR10, MNIST, etc. and data transformers for images, viz., torchvision.datasets and torch.utils.data.DataLoader . This provides a huge convenience and avoids writing boilerplate code. For this tutorial, we will use the CIFAR10 dataset. It has the classes: \u2018airplane\u2019, \u2018automobile\u2019, \u2018bird\u2019, \u2018cat\u2019, \u2018deer\u2019, \u2018dog\u2019, \u2018frog\u2019, \u2018horse\u2019, \u2018ship\u2019, \u2018truck\u2019. The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size. .. figure:: /_static/img/cifar10.png :alt: cifar10 cifar10 Training an image classifier We will do the following steps in order: Load and normalizing the CIFAR10 training and test datasets using torchvision Define a Convolutional Neural Network Define a loss function Train the network on the training data Test the network on the test data Loading and normalizing CIFAR10 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Using torchvision , it\u2019s extremely easy to load CIFAR10. 1 2 3 import torch import torchvision import torchvision.transforms as transforms The output of torchvision datasets are PILImage images of range [0, 1]. We transform them to Tensors of normalized range [-1, 1]. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 transform = transforms . Compose ( [ transforms . ToTensor (), transforms . Normalize (( 0.5 , 0.5 , 0.5 ), ( 0.5 , 0.5 , 0.5 ))]) trainset = torchvision . datasets . CIFAR10 ( root = './data' , train = True , download = True , transform = transform ) trainloader = torch . utils . data . DataLoader ( trainset , batch_size = 4 , shuffle = True , num_workers = 2 ) testset = torchvision . datasets . CIFAR10 ( root = './data' , train = False , download = True , transform = transform ) testloader = torch . utils . data . DataLoader ( testset , batch_size = 4 , shuffle = False , num_workers = 2 ) classes = ( 'plane' , 'car' , 'bird' , 'cat' , 'deer' , 'dog' , 'frog' , 'horse' , 'ship' , 'truck' ) Let us show some of the training images, for fun. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import matplotlib.pyplot as plt import numpy as np # functions to show an image def imshow ( img ): img = img / 2 + 0.5 # unnormalize npimg = img . numpy () plt . imshow ( np . transpose ( npimg , ( 1 , 2 , 0 ))) plt . show () # get some random training images dataiter = iter ( trainloader ) images , labels = dataiter . next () # show images imshow ( torchvision . utils . make_grid ( images )) # print labels print ( ' ' . join ( ' %5s ' % classes [ labels [ j ]] for j in range ( 4 ))) Define a Convolutional Neural Network ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Copy the neural network from the Neural Networks section before and modify it to take 3-channel images (instead of 1-channel images as it was defined). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 import torch.nn as nn import torch.nn.functional as F class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . conv1 = nn . Conv2d ( 3 , 6 , 5 ) self . pool = nn . MaxPool2d ( 2 , 2 ) self . conv2 = nn . Conv2d ( 6 , 16 , 5 ) self . fc1 = nn . Linear ( 16 * 5 * 5 , 120 ) self . fc2 = nn . Linear ( 120 , 84 ) self . fc3 = nn . Linear ( 84 , 10 ) def forward ( self , x ): x = self . pool ( F . relu ( self . conv1 ( x ))) x = self . pool ( F . relu ( self . conv2 ( x ))) x = x . view ( - 1 , 16 * 5 * 5 ) x = F . relu ( self . fc1 ( x )) x = F . relu ( self . fc2 ( x )) x = self . fc3 ( x ) return x net = Net () Define a Loss function and optimizer ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Let\u2019s use a Classification Cross-Entropy loss and SGD with momentum. 1 2 3 4 import torch.optim as optim criterion = nn . CrossEntropyLoss () optimizer = optim . SGD ( net . parameters (), lr = 0.001 , momentum = 0.9 ) Train the network ^^^^^^^^^^^^^^^^^^^^ This is when things start to get interesting. We simply have to loop over our data iterator, and feed the inputs to the network and optimize. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 for epoch in range ( 2 ): # loop over the dataset multiple times running_loss = 0.0 for i , data in enumerate ( trainloader , 0 ): # get the inputs inputs , labels = data # zero the parameter gradients optimizer . zero_grad () # forward + backward + optimize outputs = net ( inputs ) loss = criterion ( outputs , labels ) loss . backward () optimizer . step () # print statistics running_loss += loss . item () if i % 2000 == 1999 : # print every 2000 mini-batches print ( '[ %d , %5d ] loss: %.3f ' % ( epoch + 1 , i + 1 , running_loss / 2000 )) running_loss = 0.0 print ( 'Finished Training' ) Test the network on the test data ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ We have trained the network for 2 passes over the training dataset. But we need to check if the network has learnt anything at all. We will check this by predicting the class label that the neural network outputs, and checking it against the ground-truth. If the prediction is correct, we add the sample to the list of correct predictions. Okay, first step. Let us display an image from the test set to get familiar. 1 2 3 4 5 6 dataiter = iter ( testloader ) images , labels = dataiter . next () # print images imshow ( torchvision . utils . make_grid ( images )) print ( 'GroundTruth: ' , ' ' . join ( ' %5s ' % classes [ labels [ j ]] for j in range ( 4 ))) Okay, now let us see what the neural network thinks these examples above are: 1 outputs = net ( images ) The outputs are energies for the 10 classes. The higher the energy for a class, the more the network thinks that the image is of the particular class. So, let\u2019s get the index of the highest energy: 1 2 3 4 _ , predicted = torch . max ( outputs , 1 ) print ( 'Predicted: ' , ' ' . join ( ' %5s ' % classes [ predicted [ j ]] for j in range ( 4 ))) The results seem pretty good. Let us look at how the network performs on the whole dataset. 1 2 3 4 5 6 7 8 9 10 11 12 correct = 0 total = 0 with torch . no_grad (): for data in testloader : images , labels = data outputs = net ( images ) _ , predicted = torch . max ( outputs . data , 1 ) total += labels . size ( 0 ) correct += ( predicted == labels ) . sum () . item () print ( 'Accuracy of the network on the 10000 test images: %d %% ' % ( 100 * correct / total )) That looks waaay better than chance, which is 10% accuracy (randomly picking a class out of 10 classes). Seems like the network learnt something. Hmmm, what are the classes that performed well, and the classes that did not perform well: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class_correct = list ( 0. for i in range ( 10 )) class_total = list ( 0. for i in range ( 10 )) with torch . no_grad (): for data in testloader : images , labels = data outputs = net ( images ) _ , predicted = torch . max ( outputs , 1 ) c = ( predicted == labels ) . squeeze () for i in range ( 4 ): label = labels [ i ] class_correct [ label ] += c [ i ] . item () class_total [ label ] += 1 for i in range ( 10 ): print ( 'Accuracy of %5s : %2d %% ' % ( classes [ i ], 100 * class_correct [ i ] / class_total [ i ])) Okay, so what next? How do we run these neural networks on the GPU? Training on GPU Just like how you transfer a Tensor onto the GPU, you transfer the neural net onto the GPU. Let\u2019s first define our device as the first visible cuda device if we have CUDA available: 1 2 3 4 5 device = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" ) # Assuming that we are on a CUDA machine, this should print a CUDA device: print ( device ) The rest of this section assumes that device is a CUDA device. Then these methods will recursively go over all modules and convert their parameters and buffers to CUDA tensors: .. code:: python 1 net.to(device) Remember that you will have to send the inputs and targets at every step to the GPU too: .. code:: python 1 inputs, labels = inputs.to(device), labels.to(device) Why dont I notice MASSIVE speedup compared to CPU? Because your network is realllly small. Exercise: Try increasing the width of your network (argument 2 of the first nn.Conv2d , and argument 1 of the second nn.Conv2d \u2013 they need to be the same number), see what kind of speedup you get. Goals achieved : Understanding PyTorch\u2019s Tensor library and neural networks at a high level. Train a small neural network to classify images Training on multiple GPUs If you want to see even more MASSIVE speedup using all of your GPUs, please check out :doc: data_parallel_tutorial . Where do I go next? :doc: Train neural nets to play video games </intermediate/reinforcement_q_learning> Train a state-of-the-art ResNet network on imagenet _ Train a face generator using Generative Adversarial Networks _ Train a word-level language model using Recurrent LSTM networks _ More examples _ More tutorials _ Discuss PyTorch on the Forums _ Chat with other users on Slack _ 1","title":"Cifar10 tutorial"},{"location":"beginner/blitz/cifar10_tutorial/#training-a-classifier","text":"This is it. You have seen how to define neural networks, compute loss and make updates to the weights of the network. Now you might be thinking,","title":"Training a Classifier"},{"location":"beginner/blitz/cifar10_tutorial/#what-about-data","text":"Generally, when you have to deal with image, text, audio or video data, you can use standard python packages that load data into a numpy array. Then you can convert this array into a torch.*Tensor . For images, packages such as Pillow, OpenCV are useful For audio, packages such as scipy and librosa For text, either raw Python or Cython based loading, or NLTK and SpaCy are useful Specifically for vision, we have created a package called torchvision , that has data loaders for common datasets such as Imagenet, CIFAR10, MNIST, etc. and data transformers for images, viz., torchvision.datasets and torch.utils.data.DataLoader . This provides a huge convenience and avoids writing boilerplate code. For this tutorial, we will use the CIFAR10 dataset. It has the classes: \u2018airplane\u2019, \u2018automobile\u2019, \u2018bird\u2019, \u2018cat\u2019, \u2018deer\u2019, \u2018dog\u2019, \u2018frog\u2019, \u2018horse\u2019, \u2018ship\u2019, \u2018truck\u2019. The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size. .. figure:: /_static/img/cifar10.png :alt: cifar10 cifar10","title":"What about data?"},{"location":"beginner/blitz/cifar10_tutorial/#training-an-image-classifier","text":"We will do the following steps in order: Load and normalizing the CIFAR10 training and test datasets using torchvision Define a Convolutional Neural Network Define a loss function Train the network on the training data Test the network on the test data Loading and normalizing CIFAR10 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Using torchvision , it\u2019s extremely easy to load CIFAR10. 1 2 3 import torch import torchvision import torchvision.transforms as transforms The output of torchvision datasets are PILImage images of range [0, 1]. We transform them to Tensors of normalized range [-1, 1]. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 transform = transforms . Compose ( [ transforms . ToTensor (), transforms . Normalize (( 0.5 , 0.5 , 0.5 ), ( 0.5 , 0.5 , 0.5 ))]) trainset = torchvision . datasets . CIFAR10 ( root = './data' , train = True , download = True , transform = transform ) trainloader = torch . utils . data . DataLoader ( trainset , batch_size = 4 , shuffle = True , num_workers = 2 ) testset = torchvision . datasets . CIFAR10 ( root = './data' , train = False , download = True , transform = transform ) testloader = torch . utils . data . DataLoader ( testset , batch_size = 4 , shuffle = False , num_workers = 2 ) classes = ( 'plane' , 'car' , 'bird' , 'cat' , 'deer' , 'dog' , 'frog' , 'horse' , 'ship' , 'truck' ) Let us show some of the training images, for fun. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import matplotlib.pyplot as plt import numpy as np # functions to show an image def imshow ( img ): img = img / 2 + 0.5 # unnormalize npimg = img . numpy () plt . imshow ( np . transpose ( npimg , ( 1 , 2 , 0 ))) plt . show () # get some random training images dataiter = iter ( trainloader ) images , labels = dataiter . next () # show images imshow ( torchvision . utils . make_grid ( images )) # print labels print ( ' ' . join ( ' %5s ' % classes [ labels [ j ]] for j in range ( 4 ))) Define a Convolutional Neural Network ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Copy the neural network from the Neural Networks section before and modify it to take 3-channel images (instead of 1-channel images as it was defined). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 import torch.nn as nn import torch.nn.functional as F class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . conv1 = nn . Conv2d ( 3 , 6 , 5 ) self . pool = nn . MaxPool2d ( 2 , 2 ) self . conv2 = nn . Conv2d ( 6 , 16 , 5 ) self . fc1 = nn . Linear ( 16 * 5 * 5 , 120 ) self . fc2 = nn . Linear ( 120 , 84 ) self . fc3 = nn . Linear ( 84 , 10 ) def forward ( self , x ): x = self . pool ( F . relu ( self . conv1 ( x ))) x = self . pool ( F . relu ( self . conv2 ( x ))) x = x . view ( - 1 , 16 * 5 * 5 ) x = F . relu ( self . fc1 ( x )) x = F . relu ( self . fc2 ( x )) x = self . fc3 ( x ) return x net = Net () Define a Loss function and optimizer ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Let\u2019s use a Classification Cross-Entropy loss and SGD with momentum. 1 2 3 4 import torch.optim as optim criterion = nn . CrossEntropyLoss () optimizer = optim . SGD ( net . parameters (), lr = 0.001 , momentum = 0.9 ) Train the network ^^^^^^^^^^^^^^^^^^^^ This is when things start to get interesting. We simply have to loop over our data iterator, and feed the inputs to the network and optimize. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 for epoch in range ( 2 ): # loop over the dataset multiple times running_loss = 0.0 for i , data in enumerate ( trainloader , 0 ): # get the inputs inputs , labels = data # zero the parameter gradients optimizer . zero_grad () # forward + backward + optimize outputs = net ( inputs ) loss = criterion ( outputs , labels ) loss . backward () optimizer . step () # print statistics running_loss += loss . item () if i % 2000 == 1999 : # print every 2000 mini-batches print ( '[ %d , %5d ] loss: %.3f ' % ( epoch + 1 , i + 1 , running_loss / 2000 )) running_loss = 0.0 print ( 'Finished Training' ) Test the network on the test data ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ We have trained the network for 2 passes over the training dataset. But we need to check if the network has learnt anything at all. We will check this by predicting the class label that the neural network outputs, and checking it against the ground-truth. If the prediction is correct, we add the sample to the list of correct predictions. Okay, first step. Let us display an image from the test set to get familiar. 1 2 3 4 5 6 dataiter = iter ( testloader ) images , labels = dataiter . next () # print images imshow ( torchvision . utils . make_grid ( images )) print ( 'GroundTruth: ' , ' ' . join ( ' %5s ' % classes [ labels [ j ]] for j in range ( 4 ))) Okay, now let us see what the neural network thinks these examples above are: 1 outputs = net ( images ) The outputs are energies for the 10 classes. The higher the energy for a class, the more the network thinks that the image is of the particular class. So, let\u2019s get the index of the highest energy: 1 2 3 4 _ , predicted = torch . max ( outputs , 1 ) print ( 'Predicted: ' , ' ' . join ( ' %5s ' % classes [ predicted [ j ]] for j in range ( 4 ))) The results seem pretty good. Let us look at how the network performs on the whole dataset. 1 2 3 4 5 6 7 8 9 10 11 12 correct = 0 total = 0 with torch . no_grad (): for data in testloader : images , labels = data outputs = net ( images ) _ , predicted = torch . max ( outputs . data , 1 ) total += labels . size ( 0 ) correct += ( predicted == labels ) . sum () . item () print ( 'Accuracy of the network on the 10000 test images: %d %% ' % ( 100 * correct / total )) That looks waaay better than chance, which is 10% accuracy (randomly picking a class out of 10 classes). Seems like the network learnt something. Hmmm, what are the classes that performed well, and the classes that did not perform well: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class_correct = list ( 0. for i in range ( 10 )) class_total = list ( 0. for i in range ( 10 )) with torch . no_grad (): for data in testloader : images , labels = data outputs = net ( images ) _ , predicted = torch . max ( outputs , 1 ) c = ( predicted == labels ) . squeeze () for i in range ( 4 ): label = labels [ i ] class_correct [ label ] += c [ i ] . item () class_total [ label ] += 1 for i in range ( 10 ): print ( 'Accuracy of %5s : %2d %% ' % ( classes [ i ], 100 * class_correct [ i ] / class_total [ i ])) Okay, so what next? How do we run these neural networks on the GPU?","title":"Training an image classifier"},{"location":"beginner/blitz/cifar10_tutorial/#training-on-gpu","text":"Just like how you transfer a Tensor onto the GPU, you transfer the neural net onto the GPU. Let\u2019s first define our device as the first visible cuda device if we have CUDA available: 1 2 3 4 5 device = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" ) # Assuming that we are on a CUDA machine, this should print a CUDA device: print ( device ) The rest of this section assumes that device is a CUDA device. Then these methods will recursively go over all modules and convert their parameters and buffers to CUDA tensors: .. code:: python 1 net.to(device) Remember that you will have to send the inputs and targets at every step to the GPU too: .. code:: python 1 inputs, labels = inputs.to(device), labels.to(device) Why dont I notice MASSIVE speedup compared to CPU? Because your network is realllly small. Exercise: Try increasing the width of your network (argument 2 of the first nn.Conv2d , and argument 1 of the second nn.Conv2d \u2013 they need to be the same number), see what kind of speedup you get. Goals achieved : Understanding PyTorch\u2019s Tensor library and neural networks at a high level. Train a small neural network to classify images","title":"Training on GPU"},{"location":"beginner/blitz/cifar10_tutorial/#training-on-multiple-gpus","text":"If you want to see even more MASSIVE speedup using all of your GPUs, please check out :doc: data_parallel_tutorial .","title":"Training on multiple GPUs"},{"location":"beginner/blitz/cifar10_tutorial/#where-do-i-go-next","text":":doc: Train neural nets to play video games </intermediate/reinforcement_q_learning> Train a state-of-the-art ResNet network on imagenet _ Train a face generator using Generative Adversarial Networks _ Train a word-level language model using Recurrent LSTM networks _ More examples _ More tutorials _ Discuss PyTorch on the Forums _ Chat with other users on Slack _ 1","title":"Where do I go next?"},{"location":"beginner/blitz/neural_networks_tutorial/","text":"1 % matplotlib inline \u795e\u7ecf\u7f51\u7edc(Neural Networks) \u53ef\u4ee5\u4f7f\u7528 torch.nn \u5305\u6784\u9020\u795e\u7ecf\u7f51\u7edc\u3002 \u73b0\u5728\u6211\u4eec\u5df2\u7ecf\u521d\u6b65\u4e86\u89e3\u4e86 autograd \uff0c nn \u4f9d\u9760 autograd \u5b9a\u4e49\u6a21\u578b\u4ee5\u53ca\u6c42\u5fae\u5206\u3002 \u4e00\u4e2a nn.Module \u5305\u542b\u591a\u4e2a\u5c42\uff0c\u4e00\u4e2a\u8fd4\u56de output \u7684 forward(input) \u65b9\u6cd5\u3002 \u4f8b\u5982\uff0c\u8fd9\u4e2a\u6570\u5b57\u56fe\u50cf\u5206\u7c7b\u7684\u7f51\u7edc\u56fe\uff1a convnet \u5b83\u662f\u4e00\u4e2a\u7b80\u5355\u7684\u524d\u9988\u7f51\u7edc\u3002\u5b83\u63a5\u53d7\u8f93\u5165\uff0c\u4e00\u4e2a\u63a5\u4e00\u4e2a\u5730\u901a\u8fc7\u51e0\u4e2a\u5c42\u8f93\u5165\uff0c\u7136\u540e\u6700\u7ec8\u7ed9\u51fa\u8f93\u51fa\u3002 \u795e\u7ecf\u7f51\u7edc\u7684\u5178\u578b\u8bad\u7ec3\u7a0b\u5e8f\u5982\u4e0b\uff1a \u5b9a\u4e49\u5177\u6709\u4e00\u4e9b\u53ef\u5b66\u4e60\u53c2\u6570\uff08\u6216\u6743\u91cd\uff09\u7684\u795e\u7ecf\u7f51\u7edc \u8fed\u4ee3\u8f93\u5165\u6570\u636e\u96c6 \u901a\u8fc7\u7f51\u7edc\u5904\u7406\u8f93\u5165 \u8ba1\u7b97\u635f\u5931\uff08\u8f93\u51fa\u8ddd\u79bb\u6b63\u786e\u591a\u8fdc\uff09 \u5c06\u6e10\u53d8\u4f20\u64ad\u56de\u7f51\u7edc\u53c2\u6570 \u66f4\u65b0\u7f51\u7edc\u6743\u91cd\uff0c\u901a\u5e38\u4f7f\u7528\u7b80\u5355\u7684\u66f4\u65b0\u89c4\u5219\uff1a weight = weight - learning_rate * gradient \u5b9a\u4e49\u7f51\u7edc \u6211\u4eec\u6765\u5b9a\u4e49\u7f51\u7edc: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 import torch import torch.nn as nn import torch.nn.functional as F class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () # 1 input image channel, 6 output channels, 5x5 square convolution # kernel self . conv1 = nn . Conv2d ( 1 , 6 , 5 ) self . conv2 = nn . Conv2d ( 6 , 16 , 5 ) # an affine operation: y = Wx + b self . fc1 = nn . Linear ( 16 * 5 * 5 , 120 ) self . fc2 = nn . Linear ( 120 , 84 ) self . fc3 = nn . Linear ( 84 , 10 ) def forward ( self , x ): # Max pooling over a (2, 2) window x = F . max_pool2d ( F . relu ( self . conv1 ( x )), ( 2 , 2 )) # If the size is a square you can only specify a single number x = F . max_pool2d ( F . relu ( self . conv2 ( x )), 2 ) x = x . view ( - 1 , self . num_flat_features ( x )) x = F . relu ( self . fc1 ( x )) x = F . relu ( self . fc2 ( x )) x = self . fc3 ( x ) return x def num_flat_features ( self , x ): size = x . size ()[ 1 :] # all dimensions except the batch dimension num_features = 1 for s in size : num_features *= s return num_features net = Net () print ( net ) 1 2 3 4 5 6 7 Net( (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1)) (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) (fc1): Linear(in_features=400, out_features=120, bias=True) (fc2): Linear(in_features=120, out_features=84, bias=True) (fc3): Linear(in_features=84, out_features=10, bias=True) ) \u6211\u4eec\u53ea\u9700\u5b9a\u4e49 forward \u51fd\u6570\uff0c backward \u51fd\u6570\uff08\u68af\u5ea6\u5728\u8fd9\u91cc\u88ab\u8ba1\u7b97\uff09\u7531 autograd \u81ea\u52a8\u751f\u6210\u3002 \u5728 forward \u51fd\u6570\u4e2d\u53ef\u4ee5\u4f7f\u7528\u4efb\u4f55\u4e00\u79cd\u5f20\u91cf\u8fd0\u7b97\u3002 \u6a21\u578b\u7684\u53ef\u5b66\u4e60\u53c2\u6570\u7531 net.parameters() \u8fd4\u56de 1 2 3 params = list ( net . parameters ()) print ( len ( params )) print ( params [ 0 ] . size ()) # conv1's .weight 1 2 10 torch.Size([6, 1, 5, 5]) \u8ba9\u6211\u4eec\u5c1d\u8bd5\u4e00\u4e2a\u968f\u673a\u768432x32\u8f93\u5165\u3002\u6ce8\u610f\uff1a\u6b64\u7f51\u7edc\uff08LeNet\uff09\u7684\u9884\u671f\u8f93\u5165\u5927\u5c0f\u4e3a32x32\u3002\u8981\u5728MNIST\u6570\u636e\u96c6\u4e0a\u4f7f\u7528\u6b64\u7f51\u7edc\uff0c\u8bf7\u5c06\u6570\u636e\u96c6\u4e2d\u7684\u56fe\u50cf\u8c03\u6574\u4e3a32x32\u3002 1 2 3 input = torch . randn ( 1 , 1 , 32 , 32 ) out = net ( input ) print ( out ) 1 2 tensor([[-0.1283, -0.0358, -0.1374, 0.0241, 0.1193, -0.0086, 0.1422, -0.0922, -0.1091, 0.0755]], grad_fn=<AddmmBackward>) \u5c06\u6240\u6709\u53c2\u6570\u548c\u5e26\u6709\u968f\u673a\u68af\u5ea6\u7684\u53cd\u5411\u4f20\u64ad\u7684\u68af\u5ea6\u7f13\u51b2\u533a\u5f52\u96f6\uff1a 1 2 net . zero_grad () out . backward ( torch . randn ( 1 , 10 )) Note\uff1a torch.nn \u4ec5\u652f\u6301\u5c0f\u6279\u6b21\u3002\u6574\u4e2a torch.nn \u5305\u4ec5\u652f\u6301\u5c0f\u6279\u6b21\u7684\u6837\u672c\uff0c\u800c\u4e0d\u662f\u5355\u4e2a\u6837\u672c\u3002 \u4f8b\u5982\uff0c nn.Conv2d \u91c7\u7528 nSamples x nChannels x Height x Width 4\u7ef4\u5f20\u91cf\u3002 \u5982\u679c\u662f\u5355\u4e2a\u6837\u672c\uff0c\u8981\u7528 input.unsqueeze(0) \u628a\u5b83\u52a0\u5230\u4e00\u4e2a\u5047\u7684\u6279\u6b21\u7ef4\u5ea6\u3002 \u5728\u7ee7\u7eed\u4e4b\u524d\uff0c\u8ba9\u6211\u4eec\u56de\u987e\u4e00\u4e0b\u5230\u76ee\u524d\u4e3a\u6b62\u770b\u5230\u7684\u6240\u6709\u8bfe\u7a0b\u3002 \u6982\u62ec\uff1a - torch.Tensor - \u5b83\u662f\u652f\u6301\u50cf backward() \u8fd9\u79cdautograd\u8fd0\u7b97\u7684 \u591a\u7ef4\u6570\u7ec4 \uff0c\u8fd8\u80fd \u4fdd\u5b58 \u5f20\u91cf\u7684 \u68af\u5ea6 \u3002 - nn.Module - \u795e\u7ecf\u7f51\u7edc\u6a21\u5757\u3002\u63d0\u4f9b \u65b9\u4fbf\u7684\u53c2\u6570\u5c01\u88c5\u65b9\u5f0f \uff0c\u79fb\u81f3GPU\u3001\u5bfc\u51fa\u3001\u52a0\u8f7d\u7b49\u8f85\u52a9\u529f\u80fd\u3002 - nn.Parameter - \u4e00\u79cd\u5f20\u91cf\uff0c \u5f53\u8d4b\u503c\u7ed9 Module \u5bf9\u8c61\u7684\u5c5e\u6027\u65f6\uff0c\u5b83\u4f5c\u4e3a\u53c2\u6570\u88ab\u81ea\u52a8\u6ce8\u518c \u3002 - autograd.Function - \u5b9e\u73b0 autograde\u8fd0\u7b97\u7684 forward() \u548c backward() \u5b9a\u4e49 \u3002 \u6bcf\u6b21 Tensor \u8fd0\u7b97\u81f3\u5c11\u521b\u5efa\u4e00\u4e2a Function \u8282\u70b9\uff0c\u8be5\u8282\u70b9\u8fde\u63a5\u5230\u521b\u5efa Tensor \u7684 Function \u5bf9\u8c61\uff0c\u5e76 \u7f16\u7801\u5176\u5386\u53f2 \u3002 \u5728\u8fd9\u4e00\u70b9\u4e0a\uff0c\u6211\u4eec\u6db5\u76d6\u4e86\uff1a - \u5b9a\u4e49\u5ba1\u673a\u6784\u7f51\u7edcDefining a neural network - \u5904\u7406\u8f93\u5165\u8c03\u7528backward \u8fd8\u5269\u4e0b\uff1a - \u8ba1\u7b97\u635f\u5931 - \u66f4\u65b0\u7f51\u7edc\u6743\u91cd \u635f\u5931\u51fd\u6570 \u635f\u5931\u51fd\u6570\u91c7\u7528 output \uff0c target \u8f93\u5165\u5bf9\uff0c\u8ba1\u7b97\u8f93\u51fa\u4e0e\u76ee\u6807\u7684\u8ddd\u79bb\u4f30\u7b97\u503c\u3002 nn \u5305\u4e0b\u6709\u591a\u79cd\u4e0d\u540c\u7684 \u635f\u5931\u51fd\u6570 \u3002 \u6bd4\u5982 nn.MSELoss \u5c31\u662f\u4e00\u4e2a\u7b80\u5355\u7684\u635f\u5931\u51fd\u6570\uff0c\u5b83\u8ba1\u7b97\u8f93\u5165\u548c\u76ee\u6807\u4e4b\u95f4\u7684\u5747\u65b9\u8bef\u5dee\u3002 \u4f8b\u5982\uff1a 1 2 3 4 5 6 7 output = net ( input ) target = torch . randn ( 10 ) # a dummy target, for example target = target . view ( 1 , - 1 ) # make it the same shape as output criterion = nn . MSELoss () loss = criterion ( output , target ) print ( loss ) 1 tensor(1.0566, grad_fn=<MseLossBackward>) \u73b0\u5728\uff0c\u5982\u679c\u6309 loss \u7684\u53cd\u65b9\u5411\uff0c\u4f7f\u7528 .grad_fn \u5c5e\u6027\uff0c\u5c31\u53ef\u770b\u5230\u8fd9\u6837\u7684\u8ba1\u7b97\u56fe\uff1a 1 2 3 4 input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d -> view -> linear -> relu -> linear -> relu -> linear -> MSELoss -> loss \u6240\u4ee5\uff0c\u5f53\u6211\u4eec\u8c03\u7528 loss.backward() \uff0c\u5c31\u4f1a\u6c42\u6574\u4e2a\u56fe\u5173\u4e8e\u635f\u5931\u7684\u5fae\u5206\uff0c\u56fe\u4e2d\u6240\u6709\u5177\u6709 requires_grad=True \u7684 Tensor \u5bf9\u8c61\u7684 .grad \u5f20\u91cf\u5c5e\u6027\u90fd\u4f7f\u7528\u68af\u5ea6\u7d2f\u52a0\u3002 \u4e3a\u4e86\u8bf4\u660e\u8fd9\u4e00\u70b9\uff0c\u6211\u4eec\u8fdb\u884c\u51e0\u6b65\u53cd\u5411\uff1a 1 2 3 print ( loss . grad_fn ) # MSELoss print ( loss . grad_fn . next_functions [ 0 ][ 0 ]) # Linear print ( loss . grad_fn . next_functions [ 0 ][ 0 ] . next_functions [ 0 ][ 0 ]) # ReLU 1 2 3 <MseLossBackward object at 0x7fe026ecc278> <AddmmBackward object at 0x7fe026ecc320> <AccumulateGrad object at 0x7fe026ecc278> \u53cd\u5411\u4f20\u64ad \u8981\u53cd\u5411\u4f20\u64ad\u8bef\u5dee\uff0c\u6211\u4eec\u9501\u8981\u505a\u7684\u5c31\u662f loss.backward() \u3002 \u4e0d\u8fc7\u6211\u4eec\u9700\u8981\u6e05\u9664\u5df2\u6709\u7684\u68af\u5ea6\uff0c\u5426\u5219\u68af\u5ea6\u5c06\u88ab\u7d2f\u79ef\u5230\u5df2\u6709\u7684\u68af\u5ea6\u4e0a\u3002 \u73b0\u5728\u53ef\u4ee5\u8c03\u7528 loss.backward() \uff0c\u770b\u770b conv1 \u5728\u8c03\u7528\u4e4b\u524d\u548c\u4e4b\u540e\u548c\u504f\u5dee\u68af\u5ea6\u3002 1 2 3 4 5 6 7 8 9 net . zero_grad () # zeroes the gradient buffers of all parameters print ( 'conv1.bias.grad before backward' ) print ( net . conv1 . bias . grad ) loss . backward () print ( 'conv1.bias.grad after backward' ) print ( net . conv1 . bias . grad ) 1 2 3 4 conv1.bias.grad before backward tensor([0., 0., 0., 0., 0., 0.]) conv1.bias.grad after backward tensor([-0.0024, 0.0039, -0.0143, 0.0135, 0.0240, 0.0071]) \u5230\u76ee\u524d\u4f4d\u7f6e, \u6211\u4eec\u5df2\u7ecf\u770b\u5230\u4e86\u5982\u4f55\u4f7f\u7528\u635f\u5931\u51fd\u6570\u3002 \u5ef6\u540e\u9605\u8bfb\uff1a \u795e\u7ecf\u7f51\u7edc\u5305\u5177\u6709\u7531\u4e8e\u6784\u5efa\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u5404\u79cd\u6a21\u5757\u548c\u635f\u5931\u51fd\u6570\u3002\u5e26\u6709\u6587\u6863\u7684\u5b8c\u6574\u5217\u8868\u5728 https://pytorch.org/docs/nn \u8fd8\u5269\u4e0b\u4e00\u4e2a\u8981\u5b66\u4e60\u7684\u662f\uff1a \u66f4\u65b0\u7f51\u7edc\u7684\u6743\u91cd \u66f4\u65b0\u6743\u91cd \u968f\u673a\u68af\u5ea6\u4e0b\u964d\u662f(SGD)\u662f\u6700\u7b80\u5355\u7684\u66f4\u65b0\u89c4\u5219\uff1a 1 weight = weight - learning_rate * gradient \u53ef\u4ee5\u7528\u7b80\u5355\u7684Python\u4ee3\u7801\u5b9e\u73b0\u5b83\uff1a 1 2 3 learning_rate = 0.01 for f in net . parameters (): f . data . sub_ ( f . grad . data * learning_rate ) \u4e0d\u8fc7\uff0c\u5f53\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u65f6\uff0c\u8fd8\u9700\u8981\u4f7f\u7528\u5404\u79cd\u4e0d\u540c\u7684\u66f4\u65b0\u89c4\u5219\uff0c\u4f8b\u5982SGD\uff0cNesterov-SGD\uff0cAdam\uff0cRMSProp\u7b49\u3002 \u4e3a\u4e86\u5b9e\u73b0\u8fd9\u4e00\u70b9\uff0c\u6211\u4eec\u6784\u5efa\u4e86\u4e00\u4e2a\u5c0f\u5305\uff1a torch.optim \uff0c\u5b83\u5b9e\u73b0\u4e86\u6240\u6709\u8fd9\u4e9b\u65b9\u6cd5\u3002\u4f7f\u7528\u5b83\u975e\u5e38\u7b80\u5355\uff1a 1 2 3 4 5 6 7 8 9 10 11 import torch.optim as optim # create your optimizer optimizer = optim . SGD ( net . parameters (), lr = 0.01 ) # in your training loop: optimizer . zero_grad () # zero the gradient buffers output = net ( input ) loss = criterion ( output , target ) loss . backward () optimizer . step () # Does the update Note\uff1a \u89c2\u5bdf\u5982\u4f55\u4f7f\u7528 optimizer.zero_grad() \u624b\u52a8\u5c06\u68af\u5ea6\u7f13\u51b2\u533a\u8bbe\u7f6e\u4e3a\u96f6\u3002\u8fd9\u662f\u56e0\u4e3a\u68af\u5ea6\u7d2f\u79ef\u7684\uff0c\u53c2\u89c1 \u53cd\u5411\u4f20\u64ad \u90e8\u5206\u4e2d\u7684\u8bf4\u660e\u3002","title":"Neural networks tutorial"},{"location":"beginner/blitz/neural_networks_tutorial/#neural-networks","text":"\u53ef\u4ee5\u4f7f\u7528 torch.nn \u5305\u6784\u9020\u795e\u7ecf\u7f51\u7edc\u3002 \u73b0\u5728\u6211\u4eec\u5df2\u7ecf\u521d\u6b65\u4e86\u89e3\u4e86 autograd \uff0c nn \u4f9d\u9760 autograd \u5b9a\u4e49\u6a21\u578b\u4ee5\u53ca\u6c42\u5fae\u5206\u3002 \u4e00\u4e2a nn.Module \u5305\u542b\u591a\u4e2a\u5c42\uff0c\u4e00\u4e2a\u8fd4\u56de output \u7684 forward(input) \u65b9\u6cd5\u3002 \u4f8b\u5982\uff0c\u8fd9\u4e2a\u6570\u5b57\u56fe\u50cf\u5206\u7c7b\u7684\u7f51\u7edc\u56fe\uff1a convnet \u5b83\u662f\u4e00\u4e2a\u7b80\u5355\u7684\u524d\u9988\u7f51\u7edc\u3002\u5b83\u63a5\u53d7\u8f93\u5165\uff0c\u4e00\u4e2a\u63a5\u4e00\u4e2a\u5730\u901a\u8fc7\u51e0\u4e2a\u5c42\u8f93\u5165\uff0c\u7136\u540e\u6700\u7ec8\u7ed9\u51fa\u8f93\u51fa\u3002 \u795e\u7ecf\u7f51\u7edc\u7684\u5178\u578b\u8bad\u7ec3\u7a0b\u5e8f\u5982\u4e0b\uff1a \u5b9a\u4e49\u5177\u6709\u4e00\u4e9b\u53ef\u5b66\u4e60\u53c2\u6570\uff08\u6216\u6743\u91cd\uff09\u7684\u795e\u7ecf\u7f51\u7edc \u8fed\u4ee3\u8f93\u5165\u6570\u636e\u96c6 \u901a\u8fc7\u7f51\u7edc\u5904\u7406\u8f93\u5165 \u8ba1\u7b97\u635f\u5931\uff08\u8f93\u51fa\u8ddd\u79bb\u6b63\u786e\u591a\u8fdc\uff09 \u5c06\u6e10\u53d8\u4f20\u64ad\u56de\u7f51\u7edc\u53c2\u6570 \u66f4\u65b0\u7f51\u7edc\u6743\u91cd\uff0c\u901a\u5e38\u4f7f\u7528\u7b80\u5355\u7684\u66f4\u65b0\u89c4\u5219\uff1a weight = weight - learning_rate * gradient","title":"\u795e\u7ecf\u7f51\u7edc(Neural Networks)"},{"location":"beginner/blitz/neural_networks_tutorial/#_1","text":"\u6211\u4eec\u6765\u5b9a\u4e49\u7f51\u7edc: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 import torch import torch.nn as nn import torch.nn.functional as F class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () # 1 input image channel, 6 output channels, 5x5 square convolution # kernel self . conv1 = nn . Conv2d ( 1 , 6 , 5 ) self . conv2 = nn . Conv2d ( 6 , 16 , 5 ) # an affine operation: y = Wx + b self . fc1 = nn . Linear ( 16 * 5 * 5 , 120 ) self . fc2 = nn . Linear ( 120 , 84 ) self . fc3 = nn . Linear ( 84 , 10 ) def forward ( self , x ): # Max pooling over a (2, 2) window x = F . max_pool2d ( F . relu ( self . conv1 ( x )), ( 2 , 2 )) # If the size is a square you can only specify a single number x = F . max_pool2d ( F . relu ( self . conv2 ( x )), 2 ) x = x . view ( - 1 , self . num_flat_features ( x )) x = F . relu ( self . fc1 ( x )) x = F . relu ( self . fc2 ( x )) x = self . fc3 ( x ) return x def num_flat_features ( self , x ): size = x . size ()[ 1 :] # all dimensions except the batch dimension num_features = 1 for s in size : num_features *= s return num_features net = Net () print ( net ) 1 2 3 4 5 6 7 Net( (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1)) (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) (fc1): Linear(in_features=400, out_features=120, bias=True) (fc2): Linear(in_features=120, out_features=84, bias=True) (fc3): Linear(in_features=84, out_features=10, bias=True) ) \u6211\u4eec\u53ea\u9700\u5b9a\u4e49 forward \u51fd\u6570\uff0c backward \u51fd\u6570\uff08\u68af\u5ea6\u5728\u8fd9\u91cc\u88ab\u8ba1\u7b97\uff09\u7531 autograd \u81ea\u52a8\u751f\u6210\u3002 \u5728 forward \u51fd\u6570\u4e2d\u53ef\u4ee5\u4f7f\u7528\u4efb\u4f55\u4e00\u79cd\u5f20\u91cf\u8fd0\u7b97\u3002 \u6a21\u578b\u7684\u53ef\u5b66\u4e60\u53c2\u6570\u7531 net.parameters() \u8fd4\u56de 1 2 3 params = list ( net . parameters ()) print ( len ( params )) print ( params [ 0 ] . size ()) # conv1's .weight 1 2 10 torch.Size([6, 1, 5, 5]) \u8ba9\u6211\u4eec\u5c1d\u8bd5\u4e00\u4e2a\u968f\u673a\u768432x32\u8f93\u5165\u3002\u6ce8\u610f\uff1a\u6b64\u7f51\u7edc\uff08LeNet\uff09\u7684\u9884\u671f\u8f93\u5165\u5927\u5c0f\u4e3a32x32\u3002\u8981\u5728MNIST\u6570\u636e\u96c6\u4e0a\u4f7f\u7528\u6b64\u7f51\u7edc\uff0c\u8bf7\u5c06\u6570\u636e\u96c6\u4e2d\u7684\u56fe\u50cf\u8c03\u6574\u4e3a32x32\u3002 1 2 3 input = torch . randn ( 1 , 1 , 32 , 32 ) out = net ( input ) print ( out ) 1 2 tensor([[-0.1283, -0.0358, -0.1374, 0.0241, 0.1193, -0.0086, 0.1422, -0.0922, -0.1091, 0.0755]], grad_fn=<AddmmBackward>) \u5c06\u6240\u6709\u53c2\u6570\u548c\u5e26\u6709\u968f\u673a\u68af\u5ea6\u7684\u53cd\u5411\u4f20\u64ad\u7684\u68af\u5ea6\u7f13\u51b2\u533a\u5f52\u96f6\uff1a 1 2 net . zero_grad () out . backward ( torch . randn ( 1 , 10 )) Note\uff1a torch.nn \u4ec5\u652f\u6301\u5c0f\u6279\u6b21\u3002\u6574\u4e2a torch.nn \u5305\u4ec5\u652f\u6301\u5c0f\u6279\u6b21\u7684\u6837\u672c\uff0c\u800c\u4e0d\u662f\u5355\u4e2a\u6837\u672c\u3002 \u4f8b\u5982\uff0c nn.Conv2d \u91c7\u7528 nSamples x nChannels x Height x Width 4\u7ef4\u5f20\u91cf\u3002 \u5982\u679c\u662f\u5355\u4e2a\u6837\u672c\uff0c\u8981\u7528 input.unsqueeze(0) \u628a\u5b83\u52a0\u5230\u4e00\u4e2a\u5047\u7684\u6279\u6b21\u7ef4\u5ea6\u3002 \u5728\u7ee7\u7eed\u4e4b\u524d\uff0c\u8ba9\u6211\u4eec\u56de\u987e\u4e00\u4e0b\u5230\u76ee\u524d\u4e3a\u6b62\u770b\u5230\u7684\u6240\u6709\u8bfe\u7a0b\u3002 \u6982\u62ec\uff1a - torch.Tensor - \u5b83\u662f\u652f\u6301\u50cf backward() \u8fd9\u79cdautograd\u8fd0\u7b97\u7684 \u591a\u7ef4\u6570\u7ec4 \uff0c\u8fd8\u80fd \u4fdd\u5b58 \u5f20\u91cf\u7684 \u68af\u5ea6 \u3002 - nn.Module - \u795e\u7ecf\u7f51\u7edc\u6a21\u5757\u3002\u63d0\u4f9b \u65b9\u4fbf\u7684\u53c2\u6570\u5c01\u88c5\u65b9\u5f0f \uff0c\u79fb\u81f3GPU\u3001\u5bfc\u51fa\u3001\u52a0\u8f7d\u7b49\u8f85\u52a9\u529f\u80fd\u3002 - nn.Parameter - \u4e00\u79cd\u5f20\u91cf\uff0c \u5f53\u8d4b\u503c\u7ed9 Module \u5bf9\u8c61\u7684\u5c5e\u6027\u65f6\uff0c\u5b83\u4f5c\u4e3a\u53c2\u6570\u88ab\u81ea\u52a8\u6ce8\u518c \u3002 - autograd.Function - \u5b9e\u73b0 autograde\u8fd0\u7b97\u7684 forward() \u548c backward() \u5b9a\u4e49 \u3002 \u6bcf\u6b21 Tensor \u8fd0\u7b97\u81f3\u5c11\u521b\u5efa\u4e00\u4e2a Function \u8282\u70b9\uff0c\u8be5\u8282\u70b9\u8fde\u63a5\u5230\u521b\u5efa Tensor \u7684 Function \u5bf9\u8c61\uff0c\u5e76 \u7f16\u7801\u5176\u5386\u53f2 \u3002 \u5728\u8fd9\u4e00\u70b9\u4e0a\uff0c\u6211\u4eec\u6db5\u76d6\u4e86\uff1a - \u5b9a\u4e49\u5ba1\u673a\u6784\u7f51\u7edcDefining a neural network - \u5904\u7406\u8f93\u5165\u8c03\u7528backward \u8fd8\u5269\u4e0b\uff1a - \u8ba1\u7b97\u635f\u5931 - \u66f4\u65b0\u7f51\u7edc\u6743\u91cd","title":"\u5b9a\u4e49\u7f51\u7edc"},{"location":"beginner/blitz/neural_networks_tutorial/#_2","text":"\u635f\u5931\u51fd\u6570\u91c7\u7528 output \uff0c target \u8f93\u5165\u5bf9\uff0c\u8ba1\u7b97\u8f93\u51fa\u4e0e\u76ee\u6807\u7684\u8ddd\u79bb\u4f30\u7b97\u503c\u3002 nn \u5305\u4e0b\u6709\u591a\u79cd\u4e0d\u540c\u7684 \u635f\u5931\u51fd\u6570 \u3002 \u6bd4\u5982 nn.MSELoss \u5c31\u662f\u4e00\u4e2a\u7b80\u5355\u7684\u635f\u5931\u51fd\u6570\uff0c\u5b83\u8ba1\u7b97\u8f93\u5165\u548c\u76ee\u6807\u4e4b\u95f4\u7684\u5747\u65b9\u8bef\u5dee\u3002 \u4f8b\u5982\uff1a 1 2 3 4 5 6 7 output = net ( input ) target = torch . randn ( 10 ) # a dummy target, for example target = target . view ( 1 , - 1 ) # make it the same shape as output criterion = nn . MSELoss () loss = criterion ( output , target ) print ( loss ) 1 tensor(1.0566, grad_fn=<MseLossBackward>) \u73b0\u5728\uff0c\u5982\u679c\u6309 loss \u7684\u53cd\u65b9\u5411\uff0c\u4f7f\u7528 .grad_fn \u5c5e\u6027\uff0c\u5c31\u53ef\u770b\u5230\u8fd9\u6837\u7684\u8ba1\u7b97\u56fe\uff1a 1 2 3 4 input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d -> view -> linear -> relu -> linear -> relu -> linear -> MSELoss -> loss \u6240\u4ee5\uff0c\u5f53\u6211\u4eec\u8c03\u7528 loss.backward() \uff0c\u5c31\u4f1a\u6c42\u6574\u4e2a\u56fe\u5173\u4e8e\u635f\u5931\u7684\u5fae\u5206\uff0c\u56fe\u4e2d\u6240\u6709\u5177\u6709 requires_grad=True \u7684 Tensor \u5bf9\u8c61\u7684 .grad \u5f20\u91cf\u5c5e\u6027\u90fd\u4f7f\u7528\u68af\u5ea6\u7d2f\u52a0\u3002 \u4e3a\u4e86\u8bf4\u660e\u8fd9\u4e00\u70b9\uff0c\u6211\u4eec\u8fdb\u884c\u51e0\u6b65\u53cd\u5411\uff1a 1 2 3 print ( loss . grad_fn ) # MSELoss print ( loss . grad_fn . next_functions [ 0 ][ 0 ]) # Linear print ( loss . grad_fn . next_functions [ 0 ][ 0 ] . next_functions [ 0 ][ 0 ]) # ReLU 1 2 3 <MseLossBackward object at 0x7fe026ecc278> <AddmmBackward object at 0x7fe026ecc320> <AccumulateGrad object at 0x7fe026ecc278>","title":"\u635f\u5931\u51fd\u6570"},{"location":"beginner/blitz/neural_networks_tutorial/#_3","text":"\u8981\u53cd\u5411\u4f20\u64ad\u8bef\u5dee\uff0c\u6211\u4eec\u9501\u8981\u505a\u7684\u5c31\u662f loss.backward() \u3002 \u4e0d\u8fc7\u6211\u4eec\u9700\u8981\u6e05\u9664\u5df2\u6709\u7684\u68af\u5ea6\uff0c\u5426\u5219\u68af\u5ea6\u5c06\u88ab\u7d2f\u79ef\u5230\u5df2\u6709\u7684\u68af\u5ea6\u4e0a\u3002 \u73b0\u5728\u53ef\u4ee5\u8c03\u7528 loss.backward() \uff0c\u770b\u770b conv1 \u5728\u8c03\u7528\u4e4b\u524d\u548c\u4e4b\u540e\u548c\u504f\u5dee\u68af\u5ea6\u3002 1 2 3 4 5 6 7 8 9 net . zero_grad () # zeroes the gradient buffers of all parameters print ( 'conv1.bias.grad before backward' ) print ( net . conv1 . bias . grad ) loss . backward () print ( 'conv1.bias.grad after backward' ) print ( net . conv1 . bias . grad ) 1 2 3 4 conv1.bias.grad before backward tensor([0., 0., 0., 0., 0., 0.]) conv1.bias.grad after backward tensor([-0.0024, 0.0039, -0.0143, 0.0135, 0.0240, 0.0071]) \u5230\u76ee\u524d\u4f4d\u7f6e, \u6211\u4eec\u5df2\u7ecf\u770b\u5230\u4e86\u5982\u4f55\u4f7f\u7528\u635f\u5931\u51fd\u6570\u3002 \u5ef6\u540e\u9605\u8bfb\uff1a \u795e\u7ecf\u7f51\u7edc\u5305\u5177\u6709\u7531\u4e8e\u6784\u5efa\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u5404\u79cd\u6a21\u5757\u548c\u635f\u5931\u51fd\u6570\u3002\u5e26\u6709\u6587\u6863\u7684\u5b8c\u6574\u5217\u8868\u5728 https://pytorch.org/docs/nn \u8fd8\u5269\u4e0b\u4e00\u4e2a\u8981\u5b66\u4e60\u7684\u662f\uff1a \u66f4\u65b0\u7f51\u7edc\u7684\u6743\u91cd","title":"\u53cd\u5411\u4f20\u64ad"},{"location":"beginner/blitz/neural_networks_tutorial/#_4","text":"\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u662f(SGD)\u662f\u6700\u7b80\u5355\u7684\u66f4\u65b0\u89c4\u5219\uff1a 1 weight = weight - learning_rate * gradient \u53ef\u4ee5\u7528\u7b80\u5355\u7684Python\u4ee3\u7801\u5b9e\u73b0\u5b83\uff1a 1 2 3 learning_rate = 0.01 for f in net . parameters (): f . data . sub_ ( f . grad . data * learning_rate ) \u4e0d\u8fc7\uff0c\u5f53\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u65f6\uff0c\u8fd8\u9700\u8981\u4f7f\u7528\u5404\u79cd\u4e0d\u540c\u7684\u66f4\u65b0\u89c4\u5219\uff0c\u4f8b\u5982SGD\uff0cNesterov-SGD\uff0cAdam\uff0cRMSProp\u7b49\u3002 \u4e3a\u4e86\u5b9e\u73b0\u8fd9\u4e00\u70b9\uff0c\u6211\u4eec\u6784\u5efa\u4e86\u4e00\u4e2a\u5c0f\u5305\uff1a torch.optim \uff0c\u5b83\u5b9e\u73b0\u4e86\u6240\u6709\u8fd9\u4e9b\u65b9\u6cd5\u3002\u4f7f\u7528\u5b83\u975e\u5e38\u7b80\u5355\uff1a 1 2 3 4 5 6 7 8 9 10 11 import torch.optim as optim # create your optimizer optimizer = optim . SGD ( net . parameters (), lr = 0.01 ) # in your training loop: optimizer . zero_grad () # zero the gradient buffers output = net ( input ) loss = criterion ( output , target ) loss . backward () optimizer . step () # Does the update Note\uff1a \u89c2\u5bdf\u5982\u4f55\u4f7f\u7528 optimizer.zero_grad() \u624b\u52a8\u5c06\u68af\u5ea6\u7f13\u51b2\u533a\u8bbe\u7f6e\u4e3a\u96f6\u3002\u8fd9\u662f\u56e0\u4e3a\u68af\u5ea6\u7d2f\u79ef\u7684\uff0c\u53c2\u89c1 \u53cd\u5411\u4f20\u64ad \u90e8\u5206\u4e2d\u7684\u8bf4\u660e\u3002","title":"\u66f4\u65b0\u6743\u91cd"},{"location":"beginner/blitz/tensor_tutorial/","text":"1 % matplotlib inline \u4ec0\u4e48\u662f PyTorch? \u5b83\u662f\u4e00\u4e2a\u57fa\u4e8ePython\u7684\u79d1\u5b66\u8ba1\u7b97\u8f6f\u4ef6\u5305\uff0c\u9488\u5bf9\u4e24\u7ec4\u53d7\u4f17\uff1a NumPy \u7684\u66ff\u4ee3\u54c1\uff0c\u53ef\u4ee5\u4f7f\u7528 GPU \u7684\u5f3a\u5927\u529f\u80fd \u6df1\u5ea6\u5b66\u4e60\u7814\u7a76\u5e73\u53f0\uff0c\u63d0\u4f9b\u6700\u5927\u7684\u7075\u6d3b\u6027\u548c\u901f\u5ea6 \u5f00\u59cb \u5f20\u91cf(Tensor) Tensor(\u5f20\u91cf)\u7c7b\u4f3c\u4e8e NumPy \u7684 ndarrays(\u591a\u7ef4\u6570\u7ec4)\uff0c\u4e0d\u8fc7 Tensor \u53ef\u4ee5\u4f7f\u7528 GPU \u52a0\u901f\u8ba1\u7b97\u3002 1 2 from __future__ import print_function import torch \u6784\u9020\u4e00\u4e2a\u672a\u521d\u59cb\u5316\u76845x3\u77e9\u9635\uff1a 1 2 x = torch . empty ( 5 , 3 ) print ( x ) 1 2 3 4 5 tensor([[-1.2720e+08, 4.5715e-41, -1.2720e+08], [ 4.5715e-41, 0.0000e+00, 0.0000e+00], [ 0.0000e+00, 0.0000e+00, 3.5873e-43], [ 0.0000e+00, 1.7937e-43, 0.0000e+00], [ 0.0000e+00, 0.0000e+00, 0.0000e+00]]) \u6784\u9020\u4e00\u4e2a\u968f\u673a\u521d\u59cb\u5316\u7684\u77e9\u9635\uff1a 1 2 x = torch . rand ( 5 , 3 ) print ( x ) 1 2 3 4 5 tensor([[0.7537, 0.3162, 0.4814], [0.4303, 0.2807, 0.0952], [0.6169, 0.8890, 0.9761], [0.8800, 0.2198, 0.3990], [0.2434, 0.9329, 0.5439]]) \u6784\u9020\u4e00\u4e2a\u96f6\u586b\u5145\uff0c\u6570\u636e\u7c7b\u578b( dtype )\u4e3a\u957f\u6574\u5f62( long )\u7684\u77e9\u9635: 1 2 x = torch . zeros ( 5 , 3 , dtype = torch . long ) print ( x ) 1 2 3 4 5 tensor([[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]]) \u76f4\u63a5\u4ece\u6570\u636e\u6784\u9020 tensor: 1 2 x = torch . tensor ([ 5.5 , 3 ]) print ( x ) 1 tensor([5.5000, 3.0000]) \u6216\u8005\u5728\u5df2\u6709 tensor \u7684\u57fa\u7840\u4e0a\u521b\u5efa tensor\u3002 \u8fd9\u79cd\u65b9\u6cd5\u5c06\u91cd\u7528\u8f93\u5165 tensor \u7684\u5c5e\u6027\uff0c\u5982 dtype , \u9664\u975e\u63d0\u4f9b\u65b0\u7684\u503c 1 2 3 4 5 x = x . new_ones ( 5 , 3 , dtype = torch . double ) # new_* methods take in sizes print ( x ) x = torch . randn_like ( x , dtype = torch . float ) # override dtype! print ( x ) # result has the same size 1 2 3 4 5 6 7 8 9 10 tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]], dtype=torch.float64) tensor([[ 0.3971, -0.0788, -1.4905], [-0.1972, 2.7935, -1.8287], [-0.9228, 0.2789, -1.0781], [ 0.4243, -2.0406, -0.5721], [-0.8084, -0.3740, -0.5767]]) \u83b7\u53d6\u5176\u5927\u5c0f: 1 print ( x . size ()) 1 torch.Size([5, 3]) \u6ce8\u610f : torch.Size \u662f tuple(\u5143\u7ec4)\uff0c\u5b83\u652f\u6301\u6240\u6709 tuple \u64cd\u4f5c\u3002 \u8fd0\u7b97 \u8fd0\u7b97\u6709\u591a\u79cd\u8bed\u6cd5\u3002\u5728\u4e0b\u9762\u7684\u793a\u4f8b\u4e2d\uff0c\u6211\u4eec\u5c06\u770b\u4e00\u770b\u52a0\u6cd5\u8fd0\u7b97 \u52a0\u6cd5: \u8bed\u6cd5 1 1 2 y = torch . rand ( 5 , 3 ) print ( x + y ) 1 2 3 4 5 tensor([[ 1.0884, 0.3262, -0.6358], [-0.1748, 3.5457, -1.4837], [-0.3640, 0.7406, -0.4035], [ 1.2890, -1.2470, 0.2520], [ 0.1289, 0.4050, 0.0856]]) \u52a0\u6cd5: \u8bed\u6cd5 2 1 print ( torch . add ( x , y )) 1 2 3 4 5 tensor([[ 1.0884, 0.3262, -0.6358], [-0.1748, 3.5457, -1.4837], [-0.3640, 0.7406, -0.4035], [ 1.2890, -1.2470, 0.2520], [ 0.1289, 0.4050, 0.0856]]) \u52a0\u6cd5: \u5c06\u8f93\u51fa tensor \u4f5c\u4e3a\u53c2\u6570 1 2 3 result = torch . empty ( 5 , 3 ) torch . add ( x , y , out = result ) print ( result ) 1 2 3 4 5 tensor([[ 1.0884, 0.3262, -0.6358], [-0.1748, 3.5457, -1.4837], [-0.3640, 0.7406, -0.4035], [ 1.2890, -1.2470, 0.2520], [ 0.1289, 0.4050, 0.0856]]) \u52a0\u6cd5: \u539f\u4f4d\u4fee\u6539 1 2 3 # adds x to y y . add_ ( x ) print ( y ) 1 2 3 4 5 tensor([[ 1.0884, 0.3262, -0.6358], [-0.1748, 3.5457, -1.4837], [-0.3640, 0.7406, -0.4035], [ 1.2890, -1.2470, 0.2520], [ 0.1289, 0.4050, 0.0856]]) \u6ce8\u610f : \u4efb\u4f55\u539f\u4f4d\u4fee\u6539 tensor \u7684\u8fd0\u7b97\u65b9\u6cd5\u90fd\u662f\u4ee5 _ \u7ed3\u5c3e\u7684\u3002 \u4f8b\u5982\uff1a x.copy_(y) \uff0c x.t_() \uff0c\u4f1a\u6539\u53d8 x \u53ef\u4ee5\u4f7f\u7528\u7c7b\u4f3c NumPy \u7684\u7d22\u5f15\u8fd0\u7b97\uff01 1 print ( x [:, 1 ]) 1 tensor([-0.0788, 2.7935, 0.2789, -2.0406, -0.3740]) \u8c03\u6574\u5927\u5c0f\uff1a\u5982\u679c\u8981\u5bf9 tensor \u8c03\u6574\u5927\u5c0f/\u6539\u53d8\u5f62\u72b6\uff0c\u53ef\u4ee5\u4f7f\u7528 torch.view : 1 2 3 4 x = torch . randn ( 4 , 4 ) y = x . view ( 16 ) z = x . view ( - 1 , 8 ) # the size -1 is inferred from other dimensions print ( x . size (), y . size (), z . size ()) 1 torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8]) \u5bf9\u4e8e\u53ea\u6709\u4e00\u4e2a\u5143\u7d20\u7684 tensor\uff0c\u53ef\u4ee5\u7528 .item() \u5f97\u5230\u8fd9\u4e2a\u503c\u5bf9\u5e94\u7684 Python \u6570\u503c 1 2 3 x = torch . randn ( 1 ) print ( x ) print ( x . item ()) 1 2 tensor([-0.8057]) -0.8056557774543762 \u5ef6\u540e\u9605\u8bfb \uff1a 100+ Tensor \u8fd0\u7b97\uff0c\u5305\u62ec\uff1a\u79fb\u8c03\u3001\u7d22\u5f15\u3001\u5207\u7247\u3001\u6570\u5b66\u8fd0\u7b97\u3001\u7ebf\u6027\u4ee3\u6570\u3001\u968f\u673a\u6570\u7b49\uff0c\u53ef\u53c2\u8003 https://pytorch.org/docs/torch NumPy \u8f6c\u6362 \u5c06 Torch Tensor \u8f6c\u6362\u4e3a NumPy \u6570\u7ec4\uff08\u53cd\u4e4b\u4ea6\u7136\uff09\u662f\u4e00\u4ef6\u8f7b\u800c\u6613\u4e3e\u7684\u4e8b\u3002 Torch Tensor \u548c NumPy \u6570\u7ec4\u5171\u4eab\u5176\u5e95\u5c42\u5185\u5b58\u4f4d\u7f6e\uff0c\u66f4\u6539\u4e00\u4e2a\u4f1a\u5bfc\u81f4\u53e6\u4e00\u4e2a\u7684\u6539\u53d8\u3002 \u5c06 Torch Tensor \u8f6c\u6362\u4e3a NumPy \u6570\u7ec4 1 2 a = torch . ones ( 5 ) print ( a ) 1 tensor([1., 1., 1., 1., 1.]) 1 2 b = a . numpy () print ( b ) 1 [1. 1. 1. 1. 1.] \u4e86\u89e3numpy\u6570\u7ec4\u7684\u503c\u5982\u4f55\u53d8\u5316\u3002 1 2 3 a . add_ ( 1 ) print ( a ) print ( b ) 1 2 tensor([2., 2., 2., 2., 2.]) [2. 2. 2. 2. 2.] \u5c06 NumPy \u6570\u7ec4\u8f6c\u6362\u4e3a Torch Tensor \u4e86\u89e3\u66f4\u6539 NumPy \u6570\u7ec4\u5982\u4f55\u81ea\u52a8\u66f4\u6539 Torch Tensor 1 2 3 4 5 6 import numpy as np a = np . ones ( 5 ) b = torch . from_numpy ( a ) np . add ( a , 1 , out = a ) print ( a ) print ( b ) 1 2 [2. 2. 2. 2. 2.] tensor([2., 2., 2., 2., 2.], dtype = torch.float64) \u9664\u4e86 CharTensor \uff0c\u6240\u6709 CPU \u4e0a\u7684 Tensor \u90fd\u53ef\u4ee5\u548c Numpy \u4e92\u76f8\u8f6c\u6362\u3002 CUDA Tensors \u53ef\u4ee5\u4f7f\u7528 .to \u65b9\u6cd5\u79fb\u52a8 Tensors \u5230\u4efb\u4f55\u8bbe\u5907\u3002 1 2 3 4 5 6 7 8 9 # \u53ea\u6709 CUDA \u53ef\u7528\u65f6\uff0c\u624d\u8fd0\u884c\u8fd9\u4e2a cell # \u4f7f\u7528 ``torch.device`` \u5bf9\u8c61\u5c06 tensor \u79fb\u5165\u4ee5\u53ca\u79fb\u51fa GPU if torch . cuda . is_available (): device = torch . device ( \"cuda\" ) # CUDA \u8bbe\u5907\u5bf9\u8c61 y = torch . ones_like ( x , device = device ) # \u76f4\u63a5\u5728 GPU \u4e0a\u521b\u5efa tensor x = x . to ( device ) # \u6216\u8005\u7528 ``.to(\"cuda\")`` z = x + y print ( z ) print ( z . to ( \"cpu\" , torch . double )) # ``.to`` \u4e5f\u53ef\u4ee5\u540c\u65f6\u66f4\u6539 ``dtype``! 1 2 tensor([0.1943], device='cuda:0') tensor([0.1943], dtype=torch.float64)","title":"\u4ec0\u4e48\u662fPyTorch\uff1f"},{"location":"beginner/blitz/tensor_tutorial/#pytorch","text":"\u5b83\u662f\u4e00\u4e2a\u57fa\u4e8ePython\u7684\u79d1\u5b66\u8ba1\u7b97\u8f6f\u4ef6\u5305\uff0c\u9488\u5bf9\u4e24\u7ec4\u53d7\u4f17\uff1a NumPy \u7684\u66ff\u4ee3\u54c1\uff0c\u53ef\u4ee5\u4f7f\u7528 GPU \u7684\u5f3a\u5927\u529f\u80fd \u6df1\u5ea6\u5b66\u4e60\u7814\u7a76\u5e73\u53f0\uff0c\u63d0\u4f9b\u6700\u5927\u7684\u7075\u6d3b\u6027\u548c\u901f\u5ea6","title":"\u4ec0\u4e48\u662f PyTorch?"},{"location":"beginner/blitz/tensor_tutorial/#_1","text":"","title":"\u5f00\u59cb"},{"location":"beginner/blitz/tensor_tutorial/#tensor","text":"Tensor(\u5f20\u91cf)\u7c7b\u4f3c\u4e8e NumPy \u7684 ndarrays(\u591a\u7ef4\u6570\u7ec4)\uff0c\u4e0d\u8fc7 Tensor \u53ef\u4ee5\u4f7f\u7528 GPU \u52a0\u901f\u8ba1\u7b97\u3002 1 2 from __future__ import print_function import torch \u6784\u9020\u4e00\u4e2a\u672a\u521d\u59cb\u5316\u76845x3\u77e9\u9635\uff1a 1 2 x = torch . empty ( 5 , 3 ) print ( x ) 1 2 3 4 5 tensor([[-1.2720e+08, 4.5715e-41, -1.2720e+08], [ 4.5715e-41, 0.0000e+00, 0.0000e+00], [ 0.0000e+00, 0.0000e+00, 3.5873e-43], [ 0.0000e+00, 1.7937e-43, 0.0000e+00], [ 0.0000e+00, 0.0000e+00, 0.0000e+00]]) \u6784\u9020\u4e00\u4e2a\u968f\u673a\u521d\u59cb\u5316\u7684\u77e9\u9635\uff1a 1 2 x = torch . rand ( 5 , 3 ) print ( x ) 1 2 3 4 5 tensor([[0.7537, 0.3162, 0.4814], [0.4303, 0.2807, 0.0952], [0.6169, 0.8890, 0.9761], [0.8800, 0.2198, 0.3990], [0.2434, 0.9329, 0.5439]]) \u6784\u9020\u4e00\u4e2a\u96f6\u586b\u5145\uff0c\u6570\u636e\u7c7b\u578b( dtype )\u4e3a\u957f\u6574\u5f62( long )\u7684\u77e9\u9635: 1 2 x = torch . zeros ( 5 , 3 , dtype = torch . long ) print ( x ) 1 2 3 4 5 tensor([[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]]) \u76f4\u63a5\u4ece\u6570\u636e\u6784\u9020 tensor: 1 2 x = torch . tensor ([ 5.5 , 3 ]) print ( x ) 1 tensor([5.5000, 3.0000]) \u6216\u8005\u5728\u5df2\u6709 tensor \u7684\u57fa\u7840\u4e0a\u521b\u5efa tensor\u3002 \u8fd9\u79cd\u65b9\u6cd5\u5c06\u91cd\u7528\u8f93\u5165 tensor \u7684\u5c5e\u6027\uff0c\u5982 dtype , \u9664\u975e\u63d0\u4f9b\u65b0\u7684\u503c 1 2 3 4 5 x = x . new_ones ( 5 , 3 , dtype = torch . double ) # new_* methods take in sizes print ( x ) x = torch . randn_like ( x , dtype = torch . float ) # override dtype! print ( x ) # result has the same size 1 2 3 4 5 6 7 8 9 10 tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]], dtype=torch.float64) tensor([[ 0.3971, -0.0788, -1.4905], [-0.1972, 2.7935, -1.8287], [-0.9228, 0.2789, -1.0781], [ 0.4243, -2.0406, -0.5721], [-0.8084, -0.3740, -0.5767]]) \u83b7\u53d6\u5176\u5927\u5c0f: 1 print ( x . size ()) 1 torch.Size([5, 3]) \u6ce8\u610f : torch.Size \u662f tuple(\u5143\u7ec4)\uff0c\u5b83\u652f\u6301\u6240\u6709 tuple \u64cd\u4f5c\u3002","title":"\u5f20\u91cf(Tensor)"},{"location":"beginner/blitz/tensor_tutorial/#_2","text":"\u8fd0\u7b97\u6709\u591a\u79cd\u8bed\u6cd5\u3002\u5728\u4e0b\u9762\u7684\u793a\u4f8b\u4e2d\uff0c\u6211\u4eec\u5c06\u770b\u4e00\u770b\u52a0\u6cd5\u8fd0\u7b97 \u52a0\u6cd5: \u8bed\u6cd5 1 1 2 y = torch . rand ( 5 , 3 ) print ( x + y ) 1 2 3 4 5 tensor([[ 1.0884, 0.3262, -0.6358], [-0.1748, 3.5457, -1.4837], [-0.3640, 0.7406, -0.4035], [ 1.2890, -1.2470, 0.2520], [ 0.1289, 0.4050, 0.0856]]) \u52a0\u6cd5: \u8bed\u6cd5 2 1 print ( torch . add ( x , y )) 1 2 3 4 5 tensor([[ 1.0884, 0.3262, -0.6358], [-0.1748, 3.5457, -1.4837], [-0.3640, 0.7406, -0.4035], [ 1.2890, -1.2470, 0.2520], [ 0.1289, 0.4050, 0.0856]]) \u52a0\u6cd5: \u5c06\u8f93\u51fa tensor \u4f5c\u4e3a\u53c2\u6570 1 2 3 result = torch . empty ( 5 , 3 ) torch . add ( x , y , out = result ) print ( result ) 1 2 3 4 5 tensor([[ 1.0884, 0.3262, -0.6358], [-0.1748, 3.5457, -1.4837], [-0.3640, 0.7406, -0.4035], [ 1.2890, -1.2470, 0.2520], [ 0.1289, 0.4050, 0.0856]]) \u52a0\u6cd5: \u539f\u4f4d\u4fee\u6539 1 2 3 # adds x to y y . add_ ( x ) print ( y ) 1 2 3 4 5 tensor([[ 1.0884, 0.3262, -0.6358], [-0.1748, 3.5457, -1.4837], [-0.3640, 0.7406, -0.4035], [ 1.2890, -1.2470, 0.2520], [ 0.1289, 0.4050, 0.0856]]) \u6ce8\u610f : \u4efb\u4f55\u539f\u4f4d\u4fee\u6539 tensor \u7684\u8fd0\u7b97\u65b9\u6cd5\u90fd\u662f\u4ee5 _ \u7ed3\u5c3e\u7684\u3002 \u4f8b\u5982\uff1a x.copy_(y) \uff0c x.t_() \uff0c\u4f1a\u6539\u53d8 x \u53ef\u4ee5\u4f7f\u7528\u7c7b\u4f3c NumPy \u7684\u7d22\u5f15\u8fd0\u7b97\uff01 1 print ( x [:, 1 ]) 1 tensor([-0.0788, 2.7935, 0.2789, -2.0406, -0.3740]) \u8c03\u6574\u5927\u5c0f\uff1a\u5982\u679c\u8981\u5bf9 tensor \u8c03\u6574\u5927\u5c0f/\u6539\u53d8\u5f62\u72b6\uff0c\u53ef\u4ee5\u4f7f\u7528 torch.view : 1 2 3 4 x = torch . randn ( 4 , 4 ) y = x . view ( 16 ) z = x . view ( - 1 , 8 ) # the size -1 is inferred from other dimensions print ( x . size (), y . size (), z . size ()) 1 torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8]) \u5bf9\u4e8e\u53ea\u6709\u4e00\u4e2a\u5143\u7d20\u7684 tensor\uff0c\u53ef\u4ee5\u7528 .item() \u5f97\u5230\u8fd9\u4e2a\u503c\u5bf9\u5e94\u7684 Python \u6570\u503c 1 2 3 x = torch . randn ( 1 ) print ( x ) print ( x . item ()) 1 2 tensor([-0.8057]) -0.8056557774543762 \u5ef6\u540e\u9605\u8bfb \uff1a 100+ Tensor \u8fd0\u7b97\uff0c\u5305\u62ec\uff1a\u79fb\u8c03\u3001\u7d22\u5f15\u3001\u5207\u7247\u3001\u6570\u5b66\u8fd0\u7b97\u3001\u7ebf\u6027\u4ee3\u6570\u3001\u968f\u673a\u6570\u7b49\uff0c\u53ef\u53c2\u8003 https://pytorch.org/docs/torch","title":"\u8fd0\u7b97"},{"location":"beginner/blitz/tensor_tutorial/#numpy","text":"\u5c06 Torch Tensor \u8f6c\u6362\u4e3a NumPy \u6570\u7ec4\uff08\u53cd\u4e4b\u4ea6\u7136\uff09\u662f\u4e00\u4ef6\u8f7b\u800c\u6613\u4e3e\u7684\u4e8b\u3002 Torch Tensor \u548c NumPy \u6570\u7ec4\u5171\u4eab\u5176\u5e95\u5c42\u5185\u5b58\u4f4d\u7f6e\uff0c\u66f4\u6539\u4e00\u4e2a\u4f1a\u5bfc\u81f4\u53e6\u4e00\u4e2a\u7684\u6539\u53d8\u3002","title":"NumPy \u8f6c\u6362"},{"location":"beginner/blitz/tensor_tutorial/#torch-tensor-numpy","text":"1 2 a = torch . ones ( 5 ) print ( a ) 1 tensor([1., 1., 1., 1., 1.]) 1 2 b = a . numpy () print ( b ) 1 [1. 1. 1. 1. 1.] \u4e86\u89e3numpy\u6570\u7ec4\u7684\u503c\u5982\u4f55\u53d8\u5316\u3002 1 2 3 a . add_ ( 1 ) print ( a ) print ( b ) 1 2 tensor([2., 2., 2., 2., 2.]) [2. 2. 2. 2. 2.]","title":"\u5c06 Torch Tensor \u8f6c\u6362\u4e3a NumPy \u6570\u7ec4"},{"location":"beginner/blitz/tensor_tutorial/#numpy-torch-tensor","text":"\u4e86\u89e3\u66f4\u6539 NumPy \u6570\u7ec4\u5982\u4f55\u81ea\u52a8\u66f4\u6539 Torch Tensor 1 2 3 4 5 6 import numpy as np a = np . ones ( 5 ) b = torch . from_numpy ( a ) np . add ( a , 1 , out = a ) print ( a ) print ( b ) 1 2 [2. 2. 2. 2. 2.] tensor([2., 2., 2., 2., 2.], dtype = torch.float64) \u9664\u4e86 CharTensor \uff0c\u6240\u6709 CPU \u4e0a\u7684 Tensor \u90fd\u53ef\u4ee5\u548c Numpy \u4e92\u76f8\u8f6c\u6362\u3002","title":"\u5c06 NumPy \u6570\u7ec4\u8f6c\u6362\u4e3a Torch Tensor"},{"location":"beginner/blitz/tensor_tutorial/#cuda-tensors","text":"\u53ef\u4ee5\u4f7f\u7528 .to \u65b9\u6cd5\u79fb\u52a8 Tensors \u5230\u4efb\u4f55\u8bbe\u5907\u3002 1 2 3 4 5 6 7 8 9 # \u53ea\u6709 CUDA \u53ef\u7528\u65f6\uff0c\u624d\u8fd0\u884c\u8fd9\u4e2a cell # \u4f7f\u7528 ``torch.device`` \u5bf9\u8c61\u5c06 tensor \u79fb\u5165\u4ee5\u53ca\u79fb\u51fa GPU if torch . cuda . is_available (): device = torch . device ( \"cuda\" ) # CUDA \u8bbe\u5907\u5bf9\u8c61 y = torch . ones_like ( x , device = device ) # \u76f4\u63a5\u5728 GPU \u4e0a\u521b\u5efa tensor x = x . to ( device ) # \u6216\u8005\u7528 ``.to(\"cuda\")`` z = x + y print ( z ) print ( z . to ( \"cpu\" , torch . double )) # ``.to`` \u4e5f\u53ef\u4ee5\u540c\u65f6\u66f4\u6539 ``dtype``! 1 2 tensor([0.1943], device='cuda:0') tensor([0.1943], dtype=torch.float64)","title":"CUDA Tensors"}]}